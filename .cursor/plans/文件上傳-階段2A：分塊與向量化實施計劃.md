<!-- 7f8029d4-8f20-4d06-ae76-818cf9d11195 4b3501e5-ec5a-4bc8-8785-e5efadd911e8 -->
# 階段2A：分塊與向量化實施計劃

**當前時間**: 2025-12-06 12:14:09 +0800

## 1. 當前狀態確認

### 1.1 已完成基礎設施

- ✅ 文件上傳功能（階段1完成）
- ✅ ChromaDB 客戶端封裝 (`database/chromadb/client.py`)
- ✅ 文件分塊處理路由 (`genai/api/routers/chunk_processing.py`)
- ✅ 文件存儲服務 (`storage/file_storage.py`)
- ✅ 文件元數據服務 (`services/api/services/file_metadata_service.py`)
- ✅ Redis 進度追蹤機制
- ✅ 處理狀態API框架 (`api/routers/file_upload.py`)

### 1.2 待完成任務

- ⏸️ 文件上傳後自動觸發分塊處理
- ⏸️ 向量化服務（使用 Ollama 生成 embeddings）
- ⏸️ 向量存儲到 ChromaDB
- ⏸️ 處理狀態查詢完善（包含分塊和向量化狀態）
- ⏸️ 文件解析器集成（如果尚未遷移）

## 2. 實施任務分解

### 2.1 向量化服務實現（2-3天）

**文件位置**: `services/api/services/embedding_service.py` (新建)

**任務清單**:

1. 創建 EmbeddingService 類

   - 使用 Ollama 客戶端（localhost:11434）生成 embeddings
   - 支持批量向量化
   - 錯誤處理和重試機制
   - 緩存機制（可選）

2. 實現向量生成方法

   - `generate_embedding(text: str) -> List[float]`
   - `generate_embeddings_batch(texts: List[str]) -> List[List[float]]`
   - 使用 Ollama embeddings API

3. 配置管理

   - 從配置文件讀取 Ollama 地址和模型
   - 支持環境變數覆蓋

**依賴**:

- `llm/clients/base.py` 或直接使用 `ollama` 庫
- Ollama 服務運行在 localhost:11434

### 2.2 ChromaDB 向量存儲服務（2天）

**文件位置**: `services/api/services/vector_store_service.py` (新建)

**任務清單**:

1. 創建 VectorStoreService 類

   - 封裝 ChromaDB 操作
   - 使用現有的 `database/chromadb/client.py`

2. 實現向量存儲方法

   - `store_vectors(file_id: str, chunks: List[Dict], embeddings: List[List[float]]) -> bool`
   - 存儲元數據（file_id, chunk_index, chunk_text, metadata）
   - 創建或獲取 collection（按用戶或文件分組）

3. 實現向量查詢方法

   - `query_vectors(query_text: str, n_results: int, filter: Dict) -> List[Dict]`
   - 支持按 file_id 過濾

4. 錯誤處理和日誌

   - 連接失敗處理
   - 寫入失敗重試

### 2.3 文件解析器集成（1-2天）

**任務清單**:

1. 檢查並遷移文件解析器（如果需要）

   - 從 `backup/refactoring/services/api/processors/parsers/` 遷移
   - 或確認 `genai/api/routers/chunk_processing.py` 中使用的解析器可用

2. 支持的文件格式

   - PDF (`PdfParser`)
   - DOCX (`DocxParser`)
   - TXT (`TxtParser`)
   - MD (`MdParser`)
   - CSV, XLSX (如需要)

### 2.4 異步處理流程集成（2-3天）

**文件位置**: `api/routers/file_upload.py` (修改)

**任務清單**:

1. 創建異步處理函數

   - `process_file_chunking_and_vectorization(file_id: str, file_path: str, file_type: str)`
   - 調用分塊處理
   - 調用向量化服務
   - 調用向量存儲服務
   - 更新處理狀態到 Redis

2. 修改文件上傳完成邏輯

   - 在 `upload_files` 函數中，文件上傳成功後觸發異步處理
   - 使用 FastAPI `BackgroundTasks` 或異步任務隊列

3. 處理狀態更新

   - 分塊進度（0-50%）
   - 向量化進度（50-90%）
   - 存儲進度（90-100%）
   - 錯誤狀態記錄

### 2.5 處理狀態查詢完善（1天）

**文件位置**: `api/routers/file_upload.py` (修改 `get_processing_status`)

**任務清單**:

1. 實現狀態查詢邏輯

   - 從 Redis 讀取處理狀態
   - 從 ChromaDB 查詢向量存儲狀態
   - 返回詳細的處理進度和結果

2. 返回數據結構

   ```python
   {
       "file_id": str,
       "status": "pending|processing|completed|failed",
       "chunking": {
           "status": str,
           "progress": int,
           "chunk_count": int,
       },
       "vectorization": {
           "status": str,
           "progress": int,
           "vector_count": int,
       },
       "storage": {
           "status": str,
           "progress": int,
           "collection_name": str,
       }
   }
   ```

### 2.6 配置和環境變數（0.5天）

**文件位置**:

- `config/config.example.json` (修改)
- `.env.example` (修改)

**任務清單**:

1. 添加向量化配置

   - Ollama 地址和端口
   - Embedding 模型名稱
   - 批量大小

2. 添加 ChromaDB 配置

   - 連接模式（http/persistent）
   - 地址和端口
   - Collection 命名策略

## 3. 技術實現細節

### 3.1 向量化流程

```python
# services/api/services/embedding_service.py
class EmbeddingService:
    def __init__(self, ollama_url: str = "http://localhost:11434", model: str = "nomic-embed-text"):
        self.ollama_url = ollama_url
        self.model = model

    async def generate_embedding(self, text: str) -> List[float]:
        # 調用 Ollama embeddings API
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.ollama_url}/api/embeddings",
                json={"model": self.model, "prompt": text}
            )
            return response.json()["embedding"]
```

### 3.2 向量存儲流程

```python
# services/api/services/vector_store_service.py
class VectorStoreService:
    def __init__(self):
        from database.chromadb import ChromaDBClient
        self.client = ChromaDBClient()

    def store_vectors(self, file_id: str, chunks: List[Dict], embeddings: List[List[float]]):
        collection = self.client.get_or_create_collection(f"file_{file_id}")
        collection.add(
            embeddings=embeddings,
            documents=[chunk["text"] for chunk in chunks],
            metadatas=[{**chunk["metadata"], "file_id": file_id} for chunk in chunks],
            ids=[f"{file_id}_{i}" for i in range(len(chunks))]
        )
```

### 3.3 異步處理觸發

```python
# api/routers/file_upload.py
async def upload_files(...):
    # ... 文件上傳邏輯 ...

    # 文件上傳成功後，觸發異步處理
    background_tasks.add_task(
        process_file_chunking_and_vectorization,
        file_id=file_id,
        file_path=file_path,
        file_type=file_type,
        user_id=current_user.user_id
    )
```

## 4. 依賴關係

### 4.1 前置條件

- ✅ 階段1必須完成（文件上傳功能）
- ✅ ChromaDB 服務可用
- ✅ Ollama 服務運行在 localhost:11434
- ✅ Redis 可用（用於狀態追蹤）

### 4.2 後續任務

- 階段2B：知識圖譜提取（可與2A並行或後續實施）
- 階段3：整合測試

## 5. 驗收標準

### 5.1 功能驗收

- ✅ 文件上傳完成後自動觸發分塊處理
- ✅ 文本成功分塊（可配置分塊大小和策略）
- ✅ 分塊成功向量化（使用 Ollama）
- ✅ 向量成功存儲到 ChromaDB
- ✅ 處理狀態可查詢（包含進度和結果）
- ✅ 錯誤處理正確（失敗時記錄錯誤信息）

### 5.2 性能驗收

- 小文件（< 1MB）處理時間 < 30秒
- 中文件（1-10MB）處理時間 < 2分鐘
- 大文件（10-50MB）處理時間 < 10分鐘
- 批量向量化支持（提高效率）

### 5.3 可靠性驗收

- 處理失敗時有明確錯誤信息
- 支持重試機制
- 狀態持久化（Redis）
- 向量存儲成功後可查詢驗證

## 6. 文件更新清單

### 新建文件

- `services/api/services/embedding_service.py`
- `services/api/services/vector_store_service.py`

### 修改文件

- `api/routers/file_upload.py` - 添加異步處理觸發和狀態查詢
- `config/config.example.json` - 添加向量化和 ChromaDB 配置
- `.env.example` - 添加環境變數
- `docs/plans/rag-file-upload/file-upload-implement-plan.md` - 更新階段2A進度

### 可能需要遷移/檢查的文件

- `services/api/processors/parsers/` - 文件解析器（如果尚未遷移）

## 7. 風險與注意事項

### 7.1 技術風險

- Ollama 服務不可用時需要優雅降級
- ChromaDB 連接失敗處理
- 大文件處理可能超時（需要優化或分段處理）

### 7.2 性能風險

- 批量向量化需要控制並發，避免過載 Ollama
- ChromaDB 寫入性能需要測試

### 7.3 解決方案

- 實現重試機制和超時控制
- 添加處理隊列管理（如需要）
- 實現進度追蹤和可恢復性

### To-dos

- [ ] 創建向量化服務（EmbeddingService）：使用 Ollama 生成 embeddings，支持批量處理
- [ ] 創建向量存儲服務（VectorStoreService）：封裝 ChromaDB 操作，實現向量存儲和查詢
- [ ] 文件解析器集成：檢查並確保所有文件格式的解析器可用
- [ ] 異步處理流程集成：在文件上傳完成後自動觸發分塊和向量化處理
- [ ] 處理狀態查詢完善：實現詳細的處理狀態查詢API，包含分塊、向量化、存儲狀態
- [ ] 配置和環境變數：添加向量化和 ChromaDB 相關配置
- [ ] 更新計劃文件：標記階段2A為進行中並更新進度
