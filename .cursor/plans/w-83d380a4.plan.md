<!-- 83d380a4-6fbb-413e-95a9-9a585f5b49c1 319da35b-cf99-4b43-80a5-56f18ac13c89 -->
# WBS 1.5 落地規劃

依 `docs/AI-Box-架構規劃.md` 中 LLM MoE/本地 LLM 需求與 `docs/PROJECT_CONTROL_TABLE.md` 的進度紀錄，以下步驟將交付 WBS 1.5 的全部子項，並確保與既有 FastAPI/MCP/ChromaDB 元件對接。

## 步驟 1：Ollama 節點安裝與硬體驗證（1.5.1）

- 依照 `docs/plans/phase1/wbs-1.5-ollama-llm.md`，在既有的 `olm.k84.org` 節點上整理安裝/驗證腳本（例如 `infra/ollama/bootstrap.sh`、`infra/ollama/healthcheck.sh`），並補齊 README 的作業流程。
- 透過 `scripts/verify_env.sh` 擴充項目，記錄 GPU/CPU/RAM/磁碟檢查、Ollama 版本、`ollama list` 輸出，生成硬體檢查報告（`docs/deployment/ollama-health-report.md`）。
- 確保報告列出與 `docs/AI-Box-架構規劃.md` 中 64GB/多模型容量規劃相符的閾值與告警條件。

## 步驟 2：模型下載與版本控管（1.5.2）

- 依 `olm.k84.org` 連線設定新增 `config/config.json` 欄位（非敏感）、`.env` 中的憑證/端口，並與 `config/config.example.json` 同步。
- 編寫 `scripts/ollama_sync_models.py`：定義 baseline (`gpt-oss:20b`, `qwen3-coder:30b`) 與 fallback 模型清單、斷點續傳與雜湊校驗，支援排程執行。
- 在 `docs/deployment/ollama-deployment.md` 新增模型管理章節，記錄容量估算、拉取命令、失敗重試流程。

## 步驟 3：Ollama API 封裝（1.5.3）

- 在 `services/api` 內建立 `clients/ollama_client.py` 封裝 REST（`/api/generate`, `/api/chat`, `/api/embeddings`）與 gRPC (如使用 `ollama serve` gRPC)；加入逾時、重試、流式回呼、錯誤映射。
- 於 `services/api/routers` 新增 `llm.py`，提供推理/embedding 端點，並整合現有 `api_gateway/main.py` pipeline；同步補充 `api_gateway/models` 的 request/response schema（溫度、top_p、超時等）。
- 撰寫單元測試 `tests/api/test_ollama_api.py`，並在 `scripts/smoke_test.py` 新增對 `olm.k84.org` 的健康檢查與簡易推理測試。

## 步驟 4：Embedding 模型與 SDK 對接（1.5.4）

- 依 `docs/AI-Box-架構規劃.md` 的向量管線，擴充 `databases/chromadb/client.py` 與 `databases/chromadb/utils.py`，支援由 Ollama 生成的 embedding 請求，確保與 WBS 1.3 既有寫入/檢索測試兼容。
- 抽象出 `agent_process/retrieval/manager.py` 新的 `EmbeddingProvider` 介面，實作 Ollama provider，並在配置檔選擇（ChromaDB vs Ollama）以利後續 MoE。
- 以 `tests/api/test_chromadb_api.py`、`tests/mcp/test_tools.py` 補上 embedding 來源切換的測試用例。

## 步驟 5：LLM 負載均衡與壓測（1.5.5）

- 建立 `services/api/core/llm_router.py`，實作輪詢/加權輪詢/健康檢查路由策略（參考 `docs/AI-Box-架構規劃.md` 第 3.9 節），支援多個 Ollama 節點與外部 LLM fallback。
- 於 `agents/task_analyzer/llm_router.py` 或對應模組掛載上述策略，使 `PROJECT_CONTROL_TABLE.md` 中階段五的 MoE 要求可直接使用本地 LLM。
- 製作 `scripts/performance/ollama_benchmark.py`（基於現有性能腳本）測得 RPS/延遲/失敗率，並產出 `docs/performance/ollama-load-test.md`；報告需對照 WBS 1.5 的驗收門檻（延遲差異 <10%）。

## 測試與驗收

- 每個步驟完成後更新 `docs/PROJECT_CONTROL_TABLE.md` 對應欄位與日誌。
- 最終在 `olm.k84.org` 執行完整 smoke/性能測試，附上 `ollama list` 與健康檢查截圖或日誌，確保符合 WBS 1.5 驗收標準。

### To-dos

- [ ] 完成1.5.1節點安裝+硬體報告
- [ ] 建立模型下載與版本控管流程
- [ ] 封裝Ollama API並加上測試
- [ ] 與Chroma/Agent整合Ollama embedding
- [ ] 實作LLM負載均衡與壓測
