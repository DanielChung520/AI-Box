#!/usr/bin/env python3
"""
æ–‡æª”åŒæ­¥è…³æœ¬ V2
æ›´ç²¾ç¢ºçš„æ–‡æª”åˆ†é¡
"""

import json
import shutil
from datetime import datetime
from pathlib import Path

DOCS_DIR = Path("/Users/daniel/GitHub/AI-Box/docs")
DOCS_DOT_DIR = Path("/Users/daniel/GitHub/AI-Box/.docs")

# ç²¾ç¢ºçš„ç›®éŒ„æ˜ å°„ - æ ¹æ“šæ–‡ä»¶åé—œéµè©
DIRECTORY_MAP = {
    # ç³»çµ±æ¶æ§‹ç›¸é—œ - ä¿ç•™
    "ç³»çµ±æ¶æ§‹": "01-ç³»çµ±æ¶æ§‹",
    "æ¶æ§‹è¦æ ¼æ›¸": "01-ç³»çµ±æ¶æ§‹",
    "æ¶æ§‹è¨­è¨ˆ": "01-ç³»çµ±æ¶æ§‹",
    "AI-Box-Agent-æ¶æ§‹è¦æ ¼æ›¸": "01-ç³»çµ±æ¶æ§‹",
    "AI-Box èªç¾©èˆ‡ä»»å‹™å·¥ç¨‹-è¨­è¨ˆèªªæ˜æ›¸-v4": "01-ç³»çµ±æ¶æ§‹",
    "Agent_Orchestration_White_Paper": "01-ç³»çµ±æ¶æ§‹",
    # API æ–‡æª”
    "API": "02-APIæ–‡æª”",
    "-api.md": "02-APIæ–‡æª”",
    "document-editing-agent-v2-api": "02-APIæ–‡æª”",
    # é–‹ç™¼æŒ‡å— - åŒ…å«è¨ˆåŠƒã€æŒ‡å—ã€è¦ç¯„
    "é–‹ç™¼è¦ç¯„": "03-é–‹ç™¼æŒ‡å—",
    "é–‹ç™¼æŒ‡å—": "03-é–‹ç™¼æŒ‡å—",
    "è¨ˆåŠƒ": "03-é–‹ç™¼æŒ‡å—",
    "é‡æ§‹è¨ˆåŠƒ": "03-é–‹ç™¼æŒ‡å—",
    "å®æ–½æŠ¥å‘Š": "03-é–‹ç™¼æŒ‡å—",
    "å¯¦æ–½å ±å‘Š": "03-é–‹ç™¼æŒ‡å—",
    "å•é¡Œè¨ºæ–·": "03-é–‹ç™¼æŒ‡å—",
    "æ•…éšœæ’æŸ¥": "03-é–‹ç™¼æŒ‡å—",
    "ä¿®å¾©èªªæ˜": "03-é–‹ç™¼æŒ‡å—",
    "éŒ¯èª¤åˆ†æ": "03-é–‹ç™¼æŒ‡å—",
    "è¦ç¯„æŒ‡å—": "03-é–‹ç™¼æŒ‡å—",
    "é›†æˆæŒ‡å—": "03-é–‹ç™¼æŒ‡å—",
    "å¯¦ç¾ç¸½çµ": "03-é–‹ç™¼æŒ‡å—",
    "éƒ¨ç½²æŒ‡å—": "03-é–‹ç™¼æŒ‡å—",
    "è¨­ç½®æŒ‡å—": "03-é–‹ç™¼æŒ‡å—",
    "é…ç½®æŒ‡å—": "03-é–‹ç™¼æŒ‡å—",
    "æœ€ä½³å¯¦è¸": "03-é–‹ç™¼æŒ‡å—",
    "ä½¿ç”¨èªªæ˜": "03-é–‹ç™¼æŒ‡å—",
    "ä½¿ç”¨æŒ‡å—": "03-é–‹ç™¼æŒ‡å—",
    "æŸ¥è©¢èªªæ˜": "03-é–‹ç™¼æŒ‡å—",
    "è™•ç†ç¤ºä¾‹": "03-é–‹ç™¼æŒ‡å—",
    "CRUDç¤ºä¾‹": "03-é–‹ç™¼æŒ‡å—",
    "åˆå§‹åŒ–æŒ‡å—": "03-é–‹ç™¼æŒ‡å—",
    "é–‹ç™¼æŒ‡å—": "03-é–‹ç™¼æŒ‡å—",
    "LLMæ¨¡å‹åˆ—è¡¨": "03-é–‹ç™¼æŒ‡å—",
    "Gitåˆ†æ”¯ç­–ç•¥": "03-é–‹ç™¼æŒ‡å—",
    "GitHubè¨­ç½®æŒ‡å—": "03-é–‹ç™¼æŒ‡å—",
    "DevSecOpsé–‹ç™¼æŒ‡å—": "03-é–‹ç™¼æŒ‡å—",
    "æ··åˆç­–ç•¥": "03-é–‹ç™¼æŒ‡å—",
    "HybridRAG": "03-é–‹ç™¼æŒ‡å—",
    "GraphRAG": "03-é–‹ç™¼æŒ‡å—",
    "genai-pipeline": "03-é–‹ç™¼æŒ‡å—",
    "AAM": "03-é–‹ç™¼æŒ‡å—",
    # æ¸¬è©¦å ±å‘Š
    "æ¸¬è©¦å ±å‘Š": "05-æ¸¬è©¦å ±å‘Š",
    "æ¸¬è©¦è¨ˆåŠƒ": "05-æ¸¬è©¦å ±å‘Š",
    "æ¸¬è©¦æŒ‡å—": "05-æ¸¬è©¦å ±å‘Š",
    "æ¸¬è©¦èªªæ˜": "05-æ¸¬è©¦å ±å‘Š",
    "æ¸¬è©¦æ•¸æ“š": "05-æ¸¬è©¦å ±å‘Š",
    "æ¸¬è©¦åŠ‡æœ¬": "05-æ¸¬è©¦å ±å‘Š",
    "åŸ·è¡Œå ±å‘Š": "05-æ¸¬è©¦å ±å‘Š",
    "æ¸¬è©¦çµæœ": "05-æ¸¬è©¦å ±å‘Š",
    # é‹ç¶­æ–‡æª”
    "ç³»çµ±ç®¡ç†": "04-é‹ç¶­æ–‡æª”",
    "ç›£æ§": "04-é‹ç¶­æ–‡æª”",
    "é…ç½®å…ƒæ•¸æ“š": "04-é‹ç¶­æ–‡æª”",
    "ConfigMetadata": "04-é‹ç¶­æ–‡æª”",
    "æ¨¡å‹åƒæ•¸é…ç½®": "04-é‹ç¶­æ–‡æª”",
    # æ•¸æ“šåº«ç›¸é—œ
    "arangodb": "01-ç³»çµ±æ¶æ§‹",
    "ArangoDB": "01-ç³»çµ±æ¶æ§‹",
    "å­˜å„²æ¶æ§‹": "01-ç³»çµ±æ¶æ§‹",
    "data-structure": "01-ç³»çµ±æ¶æ§‹",
    "schema": "01-ç³»çµ±æ¶æ§‹",
    # MCP ç›¸é—œ
    "MCP": "03-é–‹ç™¼æŒ‡å—",
    "Cloudflare": "03-é–‹ç™¼æŒ‡å—",
    # é è¨­
    "æ ¸å¿ƒçµ„ä»¶": "01-ç³»çµ±æ¶æ§‹",
    "ç³»çµ±è¨­è¨ˆæ–‡æª”": "01-ç³»çµ±æ¶æ§‹",
}

EXCLUDE_PATTERNS = [
    "archive",
    "å‚™ä»½",
    "æ­·å²å ±å‘Š",
    "æ­·å²æ­¸æª”",
    "æ¸¬è©¦å ±å‘Š/æ­·å²å ±å‘Š",
    "æ¸¬è©¦å ±å‘Š/åŸ·è¡Œçµæœ",
]


def get_target_directory(doc_path, doc_name):
    """æ ¹æ“šæ–‡æª”è·¯å¾‘å’Œåç¨±æ±ºå®šç›®æ¨™ç›®éŒ„"""
    # å…ˆæª¢æŸ¥æ’é™¤æ¨¡å¼
    for pattern in EXCLUDE_PATTERNS:
        if pattern.lower() in doc_path.lower():
            return "06-æ­·å²æ­¸æª”"

    # æª¢æŸ¥æ–‡ä»¶åæ˜ å°„
    for key, target in DIRECTORY_MAP.items():
        if key.lower() in doc_name.lower() or key in doc_path:
            return target

    # æ ¹æ“šè·¯å¾‘åˆ¤æ–·
    if "APIæ–‡æª”" in doc_path:
        return "02-APIæ–‡æª”"
    if "æ¸¬è©¦å ±å‘Š" in doc_path:
        return "05-æ¸¬è©¦å ±å‘Š"
    if "ç³»çµ±ç®¡ç†" in doc_path:
        return "04-é‹ç¶­æ–‡æª”"
    if "å¼€å‘è¿›åº¦" in doc_path or "é–‹ç™¼éç¨‹" in doc_path:
        return "03-é–‹ç™¼æŒ‡å—"

    return "01-ç³»çµ±æ¶æ§‹"  # é è¨­


def sync_documents_v2():
    """åŒæ­¥æ–‡æª” V2"""
    inventory_file = DOCS_DOT_DIR / "document_inventory.json"
    with open(inventory_file, encoding="utf-8") as f:
        inventory = json.load(f)

    processed = set()
    synced = []
    skipped = []
    errors = []
    moved_to_archive = []

    for doc in inventory["all_documents"]:
        # è¨ˆç®—åŸºç¤åç¨±
        name = doc["name"]
        base = (
            name.replace("-v4.0", "").replace("-v3.0", "").replace("-v2.0", "").replace("-v1.0", "")
        )
        base = base.replace("-v4", "").replace("-v3", "").replace("-v2", "").replace("-v1", "")
        base = base.split(".")[0]

        if base in processed:
            continue
        processed.add(base)

        # æª¢æŸ¥æ˜¯å¦ç‚ºæœ€æ–°ç‰ˆæœ¬
        latest_info = inventory["latest_versions"].get(base)
        if not latest_info or latest_info["latest_path"] != doc["path"]:
            skipped.append(doc)
            continue

        # æ±ºå®šç›®æ¨™ç›®éŒ„
        target_dir_name = get_target_directory(doc["path"], doc["name"])
        target_dir = DOCS_DOT_DIR / target_dir_name

        # æ¸…ç†ç›®æ¨™ç›®éŒ„
        target_dir.mkdir(parents=True, exist_ok=True)
        for old_file in target_dir.glob(f"{base}*.md"):
            old_file.unlink()

        # è¤‡è£½
        try:
            src = DOCS_DIR / doc["path"]
            dst = target_dir / src.name
            shutil.copy2(src, dst)

            synced.append(
                {
                    "source": doc["path"],
                    "target": str(dst.relative_to(DOCS_DOT_DIR)),
                    "category": target_dir_name,
                }
            )

            if target_dir_name == "06-æ­·å²æ­¸æª”":
                moved_to_archive.append(doc)

        except Exception as e:
            errors.append({"doc": doc["path"], "error": str(e)})

    report = {
        "synced_at": datetime.now().isoformat(),
        "synced_count": len(synced),
        "skipped_count": len(skipped),
        "error_count": len(errors),
        "by_category": {},
        "moved_to_archive": len(moved_to_archive),
    }

    # çµ±è¨ˆåˆ†é¡
    for doc in synced:
        cat = doc["category"]
        report["by_category"][cat] = report["by_category"].get(cat, 0) + 1

    report_file = DOCS_DOT_DIR / "sync_report_v2.json"
    with open(report_file, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    return report


def main():
    print("=== æ–‡æª”åŒæ­¥ V2 - ç²¾ç¢ºåˆ†é¡ ===")
    report = sync_documents_v2()

    print("\nâœ… åŒæ­¥å®Œæˆ!")
    print(f"   å·²åŒæ­¥: {report['synced_count']} å€‹")
    print(f"   å·²è·³é: {report['skipped_count']} å€‹")
    print(f"   éŒ¯èª¤: {report['error_count']} å€‹")

    print("\nğŸ“Š åˆ†é¡çµ±è¨ˆ:")
    for cat, count in sorted(report["by_category"].items()):
        print(f"   {cat}: {count} å€‹")

    print(f"\nğŸ“„ å ±å‘Š: {report['synced_at']}")


if __name__ == "__main__":
    main()
