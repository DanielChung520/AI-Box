# ä»£ç¢¼åŠŸèƒ½èªªæ˜: æ¸…ç†æ¸¬è©¦æ•¸æ“šå’Œå­˜å„²
# å‰µå»ºæ—¥æœŸ: 2026-01-22
# å‰µå»ºäºº: Daniel Chung
# æœ€å¾Œä¿®æ”¹æ—¥æœŸ: 2026-01-27

"""æ¸…ç†æ¸¬è©¦æ•¸æ“šå’Œå­˜å„² - æ”¯æŒæŒ‰ task_id æ¸…ç†"""

import argparse
import os
from pathlib import Path

# å…ˆåŠ è¼‰ .env æ–‡ä»¶ï¼ˆåœ¨å°å…¥å…¶ä»–æ¨¡çµ„ä¹‹å‰ï¼‰
project_root = Path(__file__).parent.parent.parent
env_file = project_root / ".env"

if env_file.exists():
    from dotenv import load_dotenv

    load_dotenv(env_file, override=True)
    print(f"âœ… å·²åŠ è¼‰ .env æ–‡ä»¶: {env_file}")
else:
    print(f"âš ï¸  æœªæ‰¾åˆ° .env æ–‡ä»¶: {env_file}")

# SeaweedFS
import boto3
from botocore.config import Config
from botocore.exceptions import ClientError

# Qdrant
from qdrant_client import QdrantClient

# ArangoDB
from database.arangodb import ArangoDBClient

# é…ç½®
ARANGO_DB = os.getenv("ARANGO_DB", "ai_box_kg")
ARANGO_HOST = os.getenv("ARANGODB_HOST", "localhost")
ARANGO_PORT = int(os.getenv("ARANGODB_PORT", "8529"))
ARANGO_USER = os.getenv("ARANGODB_USERNAME", "root")
ARANGO_PASSWORD = os.getenv("ARANGODB_PASSWORD", "ai_box_arangodb_password")

QDRANT_HOST = os.getenv("QDRANT_HOST", "localhost")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", "6333"))

SEAWEEDFS_ENDPOINT = os.getenv("AI_BOX_SEAWEEDFS_S3_ENDPOINT", "http://localhost:8333")
SEAWEEDFS_BUCKET = os.getenv("SEAWEEDFS_BUCKET", "bucket-ai-box-assets")
SEAWEEDFS_ACCESS_KEY = os.getenv("AI_BOX_SEAWEEDFS_S3_ACCESS_KEY", "admin")
SEAWEEDFS_SECRET_KEY = os.getenv("AI_BOX_SEAWEEDFS_S3_SECRET_KEY", "admin123")

# å¾ endpoint è§£æ host å’Œ port
try:
    SEAWEEDFS_HOST = SEAWEEDFS_ENDPOINT.replace("http://", "").split(":")[0]
    SEAWEEDFS_PORT = int(SEAWEEDFS_ENDPOINT.replace("http://", "").split(":")[1])
except:
    SEAWEEDFS_HOST = "localhost"
    SEAWEEDFS_PORT = 8333


def cleanup_arangodb(task_ids: list = None):
    """æ¸…ç† ArangoDB é›†åˆ

    Args:
        task_ids: å¯é¸ï¼ŒæŒ‰ task_id æ¸…ç†ï¼ˆåªæ¸…ç†ç›¸é—œçš„ user_tasks å’Œ file_metadataï¼‰
                 å¦‚æœç‚º Noneï¼Œå‰‡æ¸…ç©ºæ‰€æœ‰é›†åˆ
    """
    print("ğŸ—‘ï¸  æ¸…ç† ArangoDB...")

    client = ArangoDBClient()
    db = client.db

    if db is None:
        print("  âŒ ç„¡æ³•é€£æ¥åˆ° ArangoDB")
        return False

    if task_ids:
        print(f"  æŒ‰ä»»å‹™æ¸…ç†: {len(task_ids)} å€‹ task_id")

    # å§‹çµ‚æ¸…ç† entities å’Œ relationsï¼ˆçŸ¥è­˜åœ–è­œæ•¸æ“šï¼‰
    collections_to_clear = ["entities", "relations"]

    # å¦‚æœæ²’æœ‰æŒ‡å®š task_idsï¼Œå‰‡æ¸…ç©ºæ‰€æœ‰é›†åˆ
    if not task_ids:
        collections_to_clear.extend(
            [
                "file_metadata",
                "user_tasks",
                "folder_metadata",
            ]
        )
        print("  æ¸…ç©ºæ¨¡å¼: å°‡æ¸…ç©ºæ‰€æœ‰é›†åˆ")
    else:
        # å¦‚æœæœ‰æŒ‡å®š task_idsï¼Œä¹Ÿè¦æ¸…ç† file_metadata å’Œ user_tasks
        collections_to_clear.extend(
            [
                "file_metadata",
                "user_tasks",
            ]
        )
        print("  æŒ‰ä»»å‹™æ¸…ç†æ¨¡å¼: å°‡æ¸…ç†ç›¸é—œé›†åˆ")

    for collection_name in collections_to_clear:
        try:
            if db.has_collection(collection_name):
                collection = db.collection(collection_name)

                if task_ids and collection_name in ["file_metadata", "user_tasks"]:
                    # æŒ‰ä»»å‹™æ¸…ç†æ¨¡å¼ï¼šåªåˆªé™¤ç›¸é—œçš„æ–‡æª”
                    query = f"FOR doc IN {collection_name} "
                    if collection_name == "user_tasks":
                        query += f"FILTER doc._key IN @task_ids RETURN doc"
                    elif collection_name == "file_metadata":
                        query += f"FILTER doc.task_id IN @task_ids RETURN doc"

                    cursor = db.aql.execute(query, bind_vars={"task_ids": task_ids})
                    deleted_count = 0

                    for doc in cursor:
                        try:
                            if isinstance(doc, dict) and "_key" in doc:
                                collection.delete(doc["_key"])
                                deleted_count += 1
                        except Exception as e:
                            print(f"    âŒ åˆªé™¤å¤±æ•—: {e}")

                    print(f"  âœ… {collection_name}: å·²åˆªé™¤ {deleted_count} å€‹ç›¸é—œæ–‡æª”")

                else:
                    # æ¸…ç©ºæ¨¡å¼ï¼šæ¸…ç©ºæ•´å€‹é›†åˆ
                    try:
                        collection.truncate()
                        print(f"  âœ… {collection_name}: å·²æ¸…ç©ºé›†åˆ")
                    except Exception:
                        # å¦‚æœ truncate å¤±æ•—ï¼Œå˜—è©¦éæ­·åˆªé™¤
                        try:
                            cursor = db.aql.execute(
                                f"FOR doc IN {collection_name} LIMIT 1000 RETURN doc"
                            )
                            count = 0
                            for doc in cursor:
                                try:
                                    # ç¢ºä¿ doc æ˜¯å­—å…¸ä¸¦åŒ…å« _key
                                    if isinstance(doc, dict) and "_key" in doc:
                                        collection.delete(doc["_key"])
                                        count += 1
                                    elif isinstance(doc, str):
                                        import json

                                        doc_dict = json.loads(doc)
                                        if "_key" in doc_dict:
                                            collection.delete(doc_dict["_key"])
                                            count += 1
                                except Exception:
                                    pass
                            print(f"  âœ… {collection_name}: å·²åˆªé™¤ {count} å€‹æ–‡æª”")
                        except Exception as e:
                            print(f"  âŒ {collection_name}: {e}")
            else:
                print(f"  âœ… {collection_name}: é›†åˆä¸å­˜åœ¨ï¼ˆè·³éï¼‰")
        except Exception as e:
            print(f"  âŒ {collection_name}: {e}")

    return True


def cleanup_qdrant(file_ids: list = None):
    """æ¸…ç† Qdrant collections

    Args:
        file_ids: å¯é¸ï¼ŒæŒ‰ file_id æ¸…ç†ï¼ˆåªåˆªé™¤ç›¸é—œçš„å‘é‡ï¼‰
                  å¦‚æœç‚º Noneï¼Œå‰‡åˆªé™¤æ‰€æœ‰ collections
    """
    print("\nğŸ—‘ï¸  æ¸…ç† Qdrant...")

    try:
        client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)

        if file_ids:
            print(f"  æŒ‰æ–‡ä»¶æ¸…ç†: {len(file_ids)} å€‹ file_id")

            # æŒ‰æ–‡ä»¶æ¸…ç†æ¨¡å¼ï¼šåˆªé™¤æŒ‡å®š file_id çš„å‘é‡
            collections = client.get_collections().collections
            deleted_count = 0

            for collection in collections:
                collection_name = collection.name
                if not collection_name.startswith("_"):
                    try:
                        # æŸ¥æ‰¾ä¸¦åˆªé™¤ç›¸é—œé»ï¼ˆé€šé payload.file_idï¼‰
                        client.delete(
                            collection_name=collection_name,
                            points_selector={
                                "must": [{"key": "file_id", "match": {"any": file_ids}}]
                            },
                        )
                        print(f"  âœ… {collection_name}: å·²åˆªé™¤ç›¸é—œå‘é‡")
                        deleted_count += 1
                    except Exception as e:
                        print(f"  âŒ {collection_name}: {e}")

            print(f"  âœ… Qdrant æ¸…ç†å®Œæˆï¼ˆ{deleted_count} å€‹ collectionsï¼‰")

        else:
            # æ¸…ç©ºæ¨¡å¼ï¼šåˆªé™¤æ‰€æœ‰ collections
            print("  æ¸…ç©ºæ¨¡å¼: å°‡åˆªé™¤æ‰€æœ‰ collections")

            collections = client.get_collections().collections

            for collection in collections:
                collection_name = collection.name

                # åˆªé™¤æ‰€æœ‰ collectionï¼ˆé™¤äº† system collectionsï¼‰
                if not collection_name.startswith("_"):
                    try:
                        client.delete_collection(collection_name)
                        print(f"  âœ… å·²åˆªé™¤ collection: {collection_name}")
                    except Exception as e:
                        print(f"  âŒ {collection_name}: {e}")

            print("  âœ… Qdrant æ¸…ç†å®Œæˆ")

        return True
    except Exception as e:
        print(f"  âŒ Qdrant é€£æ¥å¤±æ•—: {e}")
        return False


def cleanup_seaweedfs(task_ids: list = None):
    """æ¸…ç† SeaweedFS S3 buckets

    Args:
        task_ids: å¯é¸ï¼ŒæŒ‰ task_id æ¸…ç†ï¼ˆåªåˆªé™¤ tasks/<task_id> ç›®éŒ„ï¼‰
                  å¦‚æœç‚º Noneï¼Œå‰‡åˆªé™¤ bucket ä¸­æ‰€æœ‰æ–‡ä»¶
    """
    print("\nğŸ—‘ï¸  æ¸…ç† SeaweedFS S3...")

    try:
        # é€£æ¥ SeaweedFS S3
        session = boto3.Session()
        s3 = session.client(
            "s3",
            endpoint_url=f"http://{SEAWEEDFS_HOST}:{SEAWEEDFS_PORT}",
            aws_access_key_id=SEAWEEDFS_ACCESS_KEY,
            aws_secret_access_key=SEAWEEDFS_SECRET_KEY,
            config=Config(signature_version="s3v4"),
        )

        if task_ids:
            print(f"  æŒ‰ä»»å‹™æ¸…ç†: {len(task_ids)} å€‹ task_id")
            deleted_count = 0

            # æŒ‰ä»»å‹™æ¸…ç†æ¨¡å¼ï¼šåªåˆªé™¤ tasks/<task_id> ç›®éŒ„
            for task_id in task_ids:
                try:
                    prefix = f"tasks/{task_id}/"

                    # åˆ—å‡ºæ‰€æœ‰åŒ¹é…å‰ç¶´çš„å°è±¡
                    paginator = s3.get_paginator("list_objects_v2")

                    for page in paginator.paginate(Bucket=SEAWEEDFS_BUCKET, Prefix=prefix):
                        if "Contents" in page:
                            for obj in page["Contents"]:
                                try:
                                    s3.delete_object(Bucket=SEAWEEDFS_BUCKET, Key=obj["Key"])
                                    print(f"  ğŸ—‘ï¸  åˆªé™¤: {obj['Key']}")
                                    deleted_count += 1
                                except Exception:
                                    pass

                except ClientError as e:
                    if e.response["Error"]["Code"] in ["NoSuchBucket", "NoSuchKey"]:
                        pass
                    else:
                        print(f"  âŒ task_id {task_id}: {e}")

            print(f"  âœ… SeaweedFS S3 å·²æ¸…ç†ï¼ˆ{deleted_count} å€‹æ–‡ä»¶ï¼‰")

        else:
            # æ¸…ç©ºæ¨¡å¼ï¼šåˆªé™¤ bucket ä¸­æ‰€æœ‰æ–‡ä»¶
            print("  æ¸…ç©ºæ¨¡å¼: å°‡åˆªé™¤ bucket ä¸­æ‰€æœ‰æ–‡ä»¶")

            # åˆ—å‡ºä¸¦åˆªé™¤ bucket ä¸­çš„æ‰€æœ‰å°è±¡
            try:
                paginator = s3.get_paginator("list_objects_v2")

                for page in paginator.paginate(Bucket=SEAWEEDFS_BUCKET):
                    if "Contents" in page:
                        for obj in page["Contents"]:
                            try:
                                s3.delete_object(Bucket=SEAWEEDFS_BUCKET, Key=obj["Key"])
                                print(f"  ğŸ—‘ï¸  åˆªé™¤: {obj['Key']}")
                            except Exception:
                                pass

                print(f"  âœ… SeaweedFS S3 bucket ({SEAWEEDFS_BUCKET}) å·²æ¸…ç†")

            except ClientError as e:
                if e.response["Error"]["Code"] == "NoSuchBucket":
                    print(f"  âœ… Bucket ({SEAWEEDFS_BUCKET}) ä¸å­˜åœ¨")
                elif e.response["Error"]["Code"] == "NoSuchKey":
                    print(f"  âœ… Bucket ({SEAWEEDFS_BUCKET}) å·²æ˜¯ç©º")
                else:
                    raise

        return True
    except Exception as e:
        print(f"  âŒ SeaweedFS S3 éŒ¯èª¤: {e}")
        return False


def cleanup_local_files():
    """æ¸…ç†æœ¬åœ°æ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰"""
    print("\nğŸ—‘ï¸  æ¸…ç†æœ¬åœ°æ–‡ä»¶...")

    local_paths = [
        "data/tasks",
        "data/uploads",
    ]

    for path in local_paths:
        if os.path.exists(path):
            import shutil

            try:
                shutil.rmtree(path)
                print(f"  âœ… å·²åˆªé™¤: {path}")
            except Exception as e:
                print(f"  âŒ {path}: {e}")
        else:
            print(f"  âœ… {path}: ä¸å­˜åœ¨")


def main():
    """ä¸»å‡½æ•¸"""

    parser = argparse.ArgumentParser(description="AI-Box æ¸¬è©¦æ•¸æ“šæ¸…ç†å·¥å…·")
    parser.add_argument("--force", action="store_true", help="è·³éç¢ºèªç›´æ¥åŸ·è¡Œï¼ˆå±éšªï¼ï¼‰")
    parser.add_argument("--task-ids", nargs="+", help="æŒ‰ task_id æ¸…ç†ï¼ˆå¯é¸ï¼Œå¤šå€‹ task_idï¼‰")
    parser.add_argument("--file-ids", nargs="+", help="æŒ‰ file_id æ¸…ç†ï¼ˆå¯é¸ï¼Œå¤šå€‹ file_idï¼‰")
    args = parser.parse_args()

    print("=" * 60)
    print("AI-Box æ¸¬è©¦æ•¸æ“šæ¸…ç†å·¥å…·")
    print("=" * 60)

    # ç¢ºå®šæ¸…ç†æ¨¡å¼
    task_ids = args.task_ids if args.task_ids else None

    if not args.force:
        if task_ids:
            # æŒ‰ä»»å‹™æ¸…ç†æ¨¡å¼
            print(f"\nâš ï¸  è­¦å‘Šï¼šæ­¤æ“ä½œå°‡æ¸…é™¤ä»¥ä¸‹æ•¸æ“šï¼ˆæŒ‰ä»»å‹™æ¸…ç†ï¼‰:")
            print(f"  - ArangoDB: task_id åœ¨ {task_ids} ä¸­çš„ user_tasks å’Œ file_metadata")
            print(f"  - ArangoDB: æ‰€æœ‰ entities å’Œ relationsï¼ˆçŸ¥è­˜åœ–è­œï¼‰")
            print(f"  - Qdrant: file_id åœ¨ {args.file_ids if args.file_ids else 'ç›¸é—œ'} ä¸­çš„å‘é‡")
            print(f"  - SeaweedFS: tasks/<task_id> ç›®éŒ„ä¸­çš„æ‰€æœ‰æ–‡ä»¶")
        else:
            # æ¸…ç©ºæ¨¡å¼
            print("\nâš ï¸  è­¦å‘Šï¼šæ­¤æ“ä½œå°‡æ¸…é™¤ä»¥ä¸‹æ•¸æ“šï¼ˆæ¸…ç©ºæ¨¡å¼ï¼‰:")
            print("  - ArangoDB: file_metadata, entities, relations, user_tasks, folder_metadata")
            print("  - Qdrant: æ‰€æœ‰ collections")
            print("  - SeaweedFS S3: bucket-ai-box-assets ä¸­çš„æ‰€æœ‰æ–‡ä»¶")
            print("  - æœ¬åœ°æ–‡ä»¶: data/tasks, data/uploads")

        confirm = input("\nç¢ºå®šè¦ç¹¼çºŒå—ï¼Ÿ(è¼¸å…¥ DELETE ç¢ºèª): ")

        if confirm != "DELETE":
            print("\nâŒ å·²å–æ¶ˆ")
            return
    else:
        if task_ids:
            print("\nâš ï¸  å¼·åˆ¶æ¨¡å¼ï¼šæŒ‰ä»»å‹™æ¸…ç†")
        else:
            print("\nâš ï¸  å¼·åˆ¶æ¨¡å¼ï¼šæ¸…ç©ºæ‰€æœ‰æ•¸æ“š")

    print("\n" + "=" * 60)

    # åŸ·è¡Œæ¸…ç†
    cleanup_arangodb(task_ids=task_ids)
    cleanup_qdrant(file_ids=args.file_ids)
    cleanup_seaweedfs(task_ids=task_ids)
    cleanup_local_files()

    print("\n" + "=" * 60)
    print("âœ… æ•¸æ“šæ¸…ç†å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
