#!/usr/bin/env python3
# ä»£ç¢¼åŠŸèƒ½èªªæ˜: æ‰¹é‡è™•ç†ç³»çµ±è¨­è¨ˆæ–‡æª”ï¼Œé€²è¡ŒçŸ¥è­˜åœ–è­œæå–
# å‰µå»ºæ—¥æœŸ: 2025-12-31
# å‰µå»ºäºº: Daniel Chung
# æœ€å¾Œä¿®æ”¹æ—¥æœŸ: 2025-12-31

"""æ‰¹é‡ä¸Šå‚³ç³»çµ±è¨­è¨ˆæ–‡æª”ä¸¦é€²è¡ŒçŸ¥è­˜åœ–è­œæå–"""

import json
import sys
import time
from pathlib import Path
from typing import Any, Dict, List, Optional

import requests
from dotenv import load_dotenv

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent.resolve()
sys.path.insert(0, str(project_root))

# åŠ è¼‰ç’°å¢ƒè®Šæ•¸
load_dotenv(project_root / ".env")

from database.arangodb.client import ArangoDBClient

# API é…ç½®
API_BASE_URL = "http://localhost:8000/api/v1"
TEST_USERNAME = "test"
TEST_PASSWORD = "test"

# æ–‡æª”ç›®éŒ„
DOCS_DIR = project_root / "docs/ç³»ç»Ÿè®¾è®¡æ–‡æ¡£"

# é€²åº¦æ–‡ä»¶ï¼ˆç”¨æ–¼æ–·é»çºŒå‚³ï¼‰
PROGRESS_FILE = project_root / "scripts/kg_extract_progress.json"
RESULT_FILE = project_root / "scripts/kg_extract_all_results.json"


def get_auth_token() -> str:
    """ç²å– JWT èªè­‰ token"""
    print("ğŸ” ç™»éŒ„ç²å–èªè­‰ token...")
    response = requests.post(
        f"{API_BASE_URL}/auth/login",
        json={"username": TEST_USERNAME, "password": TEST_PASSWORD},
        timeout=10,
    )

    if response.status_code != 200:
        raise Exception(f"ç™»éŒ„å¤±æ•—: {response.status_code} - {response.text}")

    data = response.json()
    if not data.get("success"):
        raise Exception(f"ç™»éŒ„å¤±æ•—: {data.get('message', 'Unknown error')}")

    token = data["data"]["access_token"]
    print("âœ… ç™»éŒ„æˆåŠŸ")
    return token


def upload_file(file_path: Path, token: str) -> Optional[str]:
    """ä¸Šå‚³æ–‡ä»¶ä¸¦è¿”å› file_id"""
    try:
        with open(file_path, "rb") as f:
            files = {"files": (file_path.name, f, "text/markdown")}
            headers = {"Authorization": f"Bearer {token}"}

            response = requests.post(
                f"{API_BASE_URL}/files/upload",
                files=files,
                headers=headers,
                timeout=120,
            )

        if response.status_code != 200:
            raise Exception(f"HTTP {response.status_code}: {response.text}")

        data = response.json()
        if not data.get("success"):
            raise Exception(data.get("message", "Unknown error"))

        uploaded_files = data["data"]["uploaded"]
        if not uploaded_files:
            raise Exception("æœªè¿”å›æ–‡ä»¶ä¿¡æ¯")

        return uploaded_files[0]["file_id"]
    except Exception as e:
        print(f"      âŒ ä¸Šå‚³å¤±æ•—: {e}")
        return None


def wait_for_processing(file_id: str, token: str, timeout: int = 600) -> bool:
    """ç­‰å¾…æ–‡ä»¶è™•ç†å®Œæˆ"""
    start_time = time.time()
    headers = {"Authorization": f"Bearer {token}"}

    while True:
        elapsed = time.time() - start_time
        if elapsed > timeout:
            return False

        try:
            response = requests.get(
                f"{API_BASE_URL}/files/{file_id}/processing-status",
                headers=headers,
                timeout=10,
            )

            if response.status_code != 200:
                time.sleep(5)
                continue

            data = response.json()
            if not data.get("success"):
                time.sleep(5)
                continue

            status_data = data["data"]
            kg_status = status_data.get("kg_extraction", {})
            kg_status_value = kg_status.get("status", "")
            kg_progress = kg_status.get("progress", 0)

            if kg_status_value == "completed":
                return True
            elif kg_status_value == "failed":
                return False

            time.sleep(5)
        except Exception:
            time.sleep(5)


def verify_kg_extraction(file_id: str) -> Dict[str, Any]:
    """é©—è­‰çŸ¥è­˜åœ–è­œæå–çµæœ"""
    client = ArangoDBClient()
    db = client.db

    entities_col = db.collection("entities")
    entities = list(entities_col.find({"file_id": file_id}))

    relations_col = db.collection("relations")
    relations = list(relations_col.find({"file_id": file_id}))

    entity_types = {}
    for entity in entities:
        entity_type = entity.get("type", "UNKNOWN")
        entity_types[entity_type] = entity_types.get(entity_type, 0) + 1

    return {
        "file_id": file_id,
        "entities_count": len(entities),
        "relations_count": len(relations),
        "entity_types": entity_types,
    }


def load_progress() -> Dict[str, Any]:
    """åŠ è¼‰é€²åº¦æ–‡ä»¶"""
    if PROGRESS_FILE.exists():
        with open(PROGRESS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"processed": [], "failed": []}


def save_progress(progress: Dict[str, Any]) -> None:
    """ä¿å­˜é€²åº¦æ–‡ä»¶"""
    with open(PROGRESS_FILE, "w", encoding="utf-8") as f:
        json.dump(progress, f, ensure_ascii=False, indent=2)


def find_all_markdown_files() -> List[Path]:
    """æŸ¥æ‰¾æ‰€æœ‰ Markdown æ–‡ä»¶"""
    md_files = []
    for md_file in DOCS_DIR.rglob("*.md"):
        # æ’é™¤æŸäº›æ–‡ä»¶
        if md_file.name.startswith(".") or md_file.name.lower() == "readme.md":
            continue
        md_files.append(md_file)

    # æŒ‰æ–‡ä»¶å¤§å°æ’åºï¼ˆå¾å°åˆ°å¤§ï¼‰
    md_files.sort(key=lambda p: p.stat().st_size)
    return md_files


def main():
    """ä¸»å‡½æ•¸"""
    print("=" * 60)
    print("æ‰¹é‡è™•ç†ç³»çµ±è¨­è¨ˆæ–‡æª” - çŸ¥è­˜åœ–è­œæå–")
    print("=" * 60)

    # æŸ¥æ‰¾æ‰€æœ‰æ–‡ä»¶
    all_files = find_all_markdown_files()
    print(f"\nğŸ“ æ‰¾åˆ° {len(all_files)} å€‹ Markdown æ–‡ä»¶")

    # åŠ è¼‰é€²åº¦
    progress = load_progress()
    processed_file_ids = {item["file_path"] for item in progress.get("processed", [])}
    failed_files = {item["file_path"] for item in progress.get("failed", [])}

    # éæ¿¾å·²è™•ç†çš„æ–‡ä»¶
    remaining_files = [
        f
        for f in all_files
        if str(f.relative_to(project_root)) not in processed_file_ids
        and str(f.relative_to(project_root)) not in failed_files
    ]

    if not remaining_files:
        print("âœ… æ‰€æœ‰æ–‡ä»¶éƒ½å·²è™•ç†å®Œæˆï¼")
        return 0

    print(f"ğŸ“‹ å¾…è™•ç†æ–‡ä»¶: {len(remaining_files)} å€‹")
    print(f"   å·²è™•ç†: {len(processed_file_ids)} å€‹")
    print(f"   å¤±æ•—: {len(failed_files)} å€‹")

    # ç²å–èªè­‰ token
    try:
        token = get_auth_token()
    except Exception as e:
        print(f"âŒ ç„¡æ³•ç²å–èªè­‰ token: {e}")
        return 1

    # è™•ç†æ–‡ä»¶
    results = {
        "processed": progress.get("processed", []),
        "failed": progress.get("failed", []),
        "total": len(all_files),
    }

    success_count = 0
    fail_count = 0

    for i, file_path in enumerate(remaining_files, 1):
        file_relative = str(file_path.relative_to(project_root))
        print(f"\n[{i}/{len(remaining_files)}] è™•ç†: {file_path.name}")
        print(f"   è·¯å¾‘: {file_relative}")
        print(f"   å¤§å°: {file_path.stat().st_size / 1024:.2f} KB")

        try:
            # ä¸Šå‚³æ–‡ä»¶
            file_id = upload_file(file_path, token)
            if not file_id:
                results["failed"].append(
                    {
                        "file_path": file_relative,
                        "error": "ä¸Šå‚³å¤±æ•—",
                        "timestamp": time.time(),
                    }
                )
                fail_count += 1
                save_progress(results)
                continue

            print(f"   âœ… ä¸Šå‚³æˆåŠŸï¼Œfile_id: {file_id}")

            # ç­‰å¾…è™•ç†å®Œæˆ
            print("   â³ ç­‰å¾…è™•ç†å®Œæˆ...")
            if wait_for_processing(file_id, token, timeout=600):
                print("   âœ… è™•ç†å®Œæˆ")

                # é©—è­‰çµæœ
                verification = verify_kg_extraction(file_id)
                results["processed"].append(
                    {
                        "file_path": file_relative,
                        "file_id": file_id,
                        "entities_count": verification["entities_count"],
                        "relations_count": verification["relations_count"],
                        "entity_types": verification["entity_types"],
                        "timestamp": time.time(),
                    }
                )
                success_count += 1
            else:
                print("   âŒ è™•ç†è¶…æ™‚æˆ–å¤±æ•—")
                results["failed"].append(
                    {
                        "file_path": file_relative,
                        "file_id": file_id,
                        "error": "è™•ç†è¶…æ™‚æˆ–å¤±æ•—",
                        "timestamp": time.time(),
                    }
                )
                fail_count += 1

            # ä¿å­˜é€²åº¦
            save_progress(results)

        except Exception as e:
            print(f"   âŒ éŒ¯èª¤: {e}")
            results["failed"].append(
                {
                    "file_path": file_relative,
                    "error": str(e),
                    "timestamp": time.time(),
                }
            )
            fail_count += 1
            save_progress(results)

    # ä¿å­˜æœ€çµ‚çµæœ
    with open(RESULT_FILE, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    # è¼¸å‡ºç¸½çµ
    print("\n" + "=" * 60)
    print("è™•ç†å®Œæˆï¼")
    print("=" * 60)
    print(f"ç¸½æ–‡ä»¶æ•¸: {len(all_files)}")
    print(f"æˆåŠŸè™•ç†: {success_count + len(processed_file_ids)} å€‹")
    print(f"å¤±æ•—: {fail_count + len(failed_files)} å€‹")
    print(f"é€²åº¦æ–‡ä»¶: {PROGRESS_FILE}")
    print(f"çµæœæ–‡ä»¶: {RESULT_FILE}")
    print("=" * 60)

    return 0 if fail_count == 0 else 1


if __name__ == "__main__":
    sys.exit(main())
