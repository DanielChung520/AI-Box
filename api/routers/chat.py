"""
ä»£ç¢¼åŠŸèƒ½èªªæ˜: ç”¢å“ç´š Chat API è·¯ç”±ï¼ˆ/api/v1/chatï¼‰ï¼Œä¸²æ¥ MoE Auto/Manual/Favorite èˆ‡æœ€å°è§€æ¸¬æ¬„ä½
å‰µå»ºæ—¥æœŸ: 2025-12-13 17:28:02 (UTC+8)
å‰µå»ºäºº: Daniel Chung
æœ€å¾Œä¿®æ”¹æ—¥æœŸ: 2025-01-27
"""

from __future__ import annotations

import asyncio
import json
import os
import re
import time
import uuid
from datetime import datetime
from pathlib import Path
from threading import Lock
from typing import Any, AsyncGenerator, Dict, List, Optional

import structlog
from fastapi import APIRouter, BackgroundTasks, Depends, HTTPException, Request, status
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel, Field

from agents.task_analyzer.analyzer import TaskAnalyzer
from agents.task_analyzer.classifier import TaskClassifier
from agents.task_analyzer.models import LLMProvider, TaskAnalysisRequest
from api.core.response import APIResponse
from database.arangodb import ArangoDBClient
from genai.workflows.context.manager import ContextManager
from llm.moe.moe_manager import LLMMoEManager
from services.api.models.chat import ChatRequest, ChatResponse, ObservabilityInfo, RoutingInfo
from services.api.models.doc_edit_request import DocEditRequestRecord, DocEditStatus
from services.api.models.file_metadata import FileMetadataCreate
from services.api.models.genai_request import (
    GenAIChatRequestCreateResponse,
    GenAIChatRequestRecord,
    GenAIChatRequestStateResponse,
    GenAIRequestStatus,
)
from services.api.services.chat_memory_service import get_chat_memory_service
from services.api.services.data_consent_service import get_consent_service
from services.api.services.doc_edit_request_store_service import get_doc_edit_request_store_service
from services.api.services.doc_patch_service import detect_doc_format
from services.api.services.file_metadata_service import FileMetadataService
from services.api.services.file_permission_service import FilePermissionService
from services.api.services.genai_chat_request_store_service import (
    get_genai_chat_request_store_service,
)
from services.api.services.genai_config_resolver_service import get_genai_config_resolver_service
from services.api.services.genai_metrics_service import get_genai_metrics_service
from services.api.services.genai_model_registry_service import get_genai_model_registry_service
from services.api.services.genai_policy_gate_service import get_genai_policy_gate_service
from services.api.services.genai_trace_store_service import (
    GenAITraceEvent,
    get_genai_trace_store_service,
)
from storage.file_storage import FileStorage, create_storage_from_config
from system.infra.config.config import get_config_section
from system.security.dependencies import get_current_tenant_id, get_current_user
from system.security.models import Permission, User

logger = structlog.get_logger(__name__)

# å‘å¾Œå…¼å®¹ï¼šå¦‚æœ ConfigStoreService ä¸å¯ç”¨ï¼Œä½¿ç”¨èˆŠçš„é…ç½®æ–¹å¼
try:
    from services.api.services.config_store_service import ConfigStoreService

    _streaming_config_service: Optional[ConfigStoreService] = None

    def get_streaming_config_service() -> ConfigStoreService:
        """ç²å–é…ç½®å­˜å„²æœå‹™å¯¦ä¾‹ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰"""
        global _streaming_config_service
        if _streaming_config_service is None:
            _streaming_config_service = ConfigStoreService()
        return _streaming_config_service

    STREAMING_CONFIG_STORE_AVAILABLE = True
except ImportError:
    STREAMING_CONFIG_STORE_AVAILABLE = False
    logger.warning("ConfigStoreService ä¸å¯ç”¨ï¼Œæµå¼è¼¸å‡ºå°‡ä½¿ç”¨é»˜èª chunk_size=50")


def get_streaming_chunk_size() -> int:
    """
    ç²å–æµå¼è¼¸å‡ºåˆ†å¡Šå¤§å°ï¼ˆå¾ ArangoDB system_configs è®€å–ï¼‰

    Returns:
        æµå¼è¼¸å‡ºåˆ†å¡Šå¤§å°ï¼ˆå­—ç¬¦æ•¸ï¼‰ï¼Œé»˜èª 50
    """
    # å„ªå…ˆå¾ ArangoDB system_configs è®€å–
    if STREAMING_CONFIG_STORE_AVAILABLE:
        try:
            config_service = get_streaming_config_service()
            config = config_service.get_config("streaming", tenant_id=None)
            if config and config.config_data:
                chunk_size = config.config_data.get("chunk_size", 50)
                return int(chunk_size)
        except Exception as e:
            logger.warning(
                "failed_to_load_streaming_config_from_arangodb",
                error=str(e),
                message="å¾ ArangoDB è®€å–æµå¼è¼¸å‡ºé…ç½®å¤±æ•—ï¼Œä½¿ç”¨é»˜èªå€¼ 50",
            )

    # é»˜èªå€¼
    return 50


router = APIRouter(prefix="/chat", tags=["Chat"])

_moe_manager: Optional[LLMMoEManager] = None
_task_classifier: Optional[TaskClassifier] = None
_task_analyzer: Optional[TaskAnalyzer] = None
_context_manager: Optional[ContextManager] = None
_file_permission_service: Optional[FilePermissionService] = None
_storage: Optional[FileStorage] = None
_metadata_service: Optional[FileMetadataService] = None
_arango_client: Optional[ArangoDBClient] = None
_request_tasks: Dict[str, asyncio.Task[None]] = {}
_request_tasks_lock = Lock()

# hybrid MVPï¼šæ”¶è—æ¨¡å‹å…ˆä»¥ localStorage å¯ç”¨ç‚ºä¸»ï¼›å¾Œç«¯æä¾› Redis å„ªå…ˆã€fallback memory çš„åŒæ­¥æ¥å£
_favorite_models_by_user: Dict[str, List[str]] = {}


def get_moe_manager() -> LLMMoEManager:
    global _moe_manager
    if _moe_manager is None:
        _moe_manager = LLMMoEManager()
    return _moe_manager


def get_task_classifier() -> TaskClassifier:
    global _task_classifier
    if _task_classifier is None:
        _task_classifier = TaskClassifier()
    return _task_classifier


def get_task_analyzer() -> TaskAnalyzer:
    """è·å– Task Analyzer å•ä¾‹"""
    global _task_analyzer
    if _task_analyzer is None:
        _task_analyzer = TaskAnalyzer()
    return _task_analyzer


def get_context_manager() -> ContextManager:
    """
    Context å–®ä¾‹å…¥å£ï¼ˆG3ï¼‰ã€‚

    - recorder: Redis å„ªå…ˆã€memory fallbackï¼ˆç”± ContextRecorder å…§éƒ¨è™•ç†ï¼‰
    - window: ContextWindowï¼ˆç”± ContextManager å…§éƒ¨è™•ç†ï¼‰
    """
    global _context_manager
    if _context_manager is None:
        _context_manager = ContextManager()
    return _context_manager


def get_storage() -> FileStorage:
    global _storage
    if _storage is None:
        config = get_config_section("file_upload", default={}) or {}
        _storage = create_storage_from_config(config)
    return _storage


def get_metadata_service() -> FileMetadataService:
    global _metadata_service
    if _metadata_service is None:
        _metadata_service = FileMetadataService()
    return _metadata_service


def get_arango_client() -> ArangoDBClient:
    global _arango_client
    if _arango_client is None:
        _arango_client = ArangoDBClient()
    return _arango_client


def get_file_permission_service() -> FilePermissionService:
    global _file_permission_service
    if _file_permission_service is None:
        _file_permission_service = FilePermissionService()
    return _file_permission_service


_FOLDER_COLLECTION_NAME = "folder_metadata"


def _looks_like_create_file_intent(text: str) -> bool:
    """
    Chat è¼¸å…¥æ¡†ï¼šåˆ¤æ–·æ˜¯å¦æœ‰ã€Œæ–°å¢/è¼¸å‡ºæˆæª”æ¡ˆã€æ„åœ–ï¼ˆMVP ä»¥ heuristic ç‚ºä¸»ï¼‰ã€‚
    """
    t = (text or "").strip()
    if not t:
        return False

    # æ˜ç¢ºè¦æ±‚ï¼šæ–°å¢æª”æ¡ˆ / å»ºç«‹æª”æ¡ˆ / ç”¢ç”Ÿæª”æ¡ˆ / å¦å­˜ç­‰
    keywords = [
        "æ–°å¢æª”æ¡ˆ",
        "å»ºç«‹æª”æ¡ˆ",
        "ç”¢ç”Ÿæª”æ¡ˆ",
        "ç”Ÿæˆæª”æ¡ˆ",
        "ç”Ÿæˆæ–‡ä»¶",  # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - æ·»åŠ ã€Œç”Ÿæˆæ–‡ä»¶ã€é—œéµè©
        "å¹«æˆ‘ç”Ÿæˆæ–‡ä»¶",  # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - æ·»åŠ ã€Œå¹«æˆ‘ç”Ÿæˆæ–‡ä»¶ã€é—œéµè©
        "å¹«æˆ‘ç”Ÿæˆæª”æ¡ˆ",  # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - æ·»åŠ ã€Œå¹«æˆ‘ç”Ÿæˆæª”æ¡ˆã€é—œéµè©
        "è¼¸å‡ºæˆæª”æ¡ˆ",
        "è¼¸å‡ºæˆæ–‡ä»¶",
        "å¯«æˆæª”æ¡ˆ",
        "å¯«æˆæ–‡ä»¶",
        "ä¿å­˜æˆ",
        "å­˜æˆ",
        "å¦å­˜",
        "åšæˆä¸€ä»½æ–‡ä»¶",
        "åšæˆä¸€ä»½æª”æ¡ˆ",
        "åšæˆæ–‡ä»¶",
        "åšæˆæª”æ¡ˆ",
        "åšæˆä¸€ä»½",
        "è£½ä½œæˆæ–‡ä»¶",
        "è£½ä½œæˆæª”æ¡ˆ",
        "è£½ä½œæ–‡ä»¶",
        "è£½ä½œæª”æ¡ˆ",
    ]
    if any(k in t for k in keywords):
        return True

    # éš±å«æ„åœ–ï¼šæ•´ç†ä»¥ä¸Šå°è©±ï¼ˆé€šå¸¸æ˜¯è¦ç”Ÿæˆæ–‡ä»¶ï¼‰
    implicit = [
        "å¹«æˆ‘æ•´ç†ä»¥ä¸Šå°è©±",
        "æ•´ç†ä»¥ä¸Šå°è©±",
        "æ•´ç†é€™æ®µå°è©±",
        "æ•´ç†å°è©±",
        "æ•´ç†æˆæ–‡ä»¶",
        "æ•´ç†æˆæª”æ¡ˆ",
    ]
    if any(k in t for k in implicit):
        return True

    # å‡ºç¾æ˜ç¢ºæª”åï¼ˆå«å‰¯æª”åï¼‰ä¹Ÿè¦–ç‚ºå»ºæª”æ„åœ–
    if re.search(r"[A-Za-z0-9_\-\u4e00-\u9fff/]+\.(md|txt|json)\b", t):
        return True

    return False


def _parse_target_path(text: str) -> tuple[Optional[str], Optional[str]]:
    """
    å¾ user text å˜—è©¦è§£æå‡º "dir/file.ext"ï¼›åªæ”¯æ´ md/txt/jsonã€‚
    å›å‚³ (folder_path, filename)ï¼›folder_path ä»¥ "a/b" å½¢å¼ï¼ˆä¸å«æœ«å°¾ /ï¼‰ã€‚
    """
    t = (text or "").strip()
    matches = re.findall(
        r"([A-Za-z0-9_\-\u4e00-\u9fff/]+\.(?:md|txt|json))\b",
        t,
    )
    if matches:
        raw_path = matches[-1].lstrip("/").strip()
        parts = [p for p in raw_path.split("/") if p]
        if not parts:
            return None, None
        if len(parts) == 1:
            return None, parts[0]
        return "/".join(parts[:-1]), parts[-1]

    # åªæœ‰æŒ‡å®šç›®éŒ„ä½†æœªæŒ‡å®šæª”åï¼ˆä¾‹å¦‚ï¼šæ”¾åˆ° docs ç›®éŒ„ï¼‰
    m = re.search(r"åœ¨\s*([A-Za-z0-9_\-\u4e00-\u9fff/]+)\s*ç›®éŒ„", t)
    if m:
        folder = m.group(1).strip().strip("/").strip()
        return folder or None, None

    return None, None


def _default_filename_for_intent(text: str) -> str:
    """
    æ ¹æ“šç”¨æˆ¶æ„åœ–ç”Ÿæˆé»˜èªæ–‡ä»¶å

    ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - å¢å¼·æ–‡ä»¶åç”Ÿæˆé‚è¼¯ï¼Œæ”¯æŒæ›´å¤šæ„åœ–è­˜åˆ¥
    """
    t = (text or "").strip()

    # æª¢æŸ¥æ˜¯å¦åŒ…å«ç‰¹å®šä¸»é¡Œï¼ˆå¦‚ "Data Agent"ï¼‰
    import re

    # å„ªå…ˆåŒ¹é… "ä¸»é¡Œï¼šXXX" æˆ– "ä¸»é¡Œ: XXX" æ¨¡å¼
    topic_pattern = r"ä¸»é¡Œ[ï¼š:]\s*([A-Za-z0-9_\-\u4e00-\u9fff\s]+?)(?:\s|ï¼Œ|,|$)"
    topic_match = re.search(topic_pattern, t, re.IGNORECASE)
    if topic_match:
        topic = topic_match.group(1).strip()
        # æ¸…ç†ä¸»é¡Œåç¨±ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™å­—æ¯ã€æ•¸å­—ã€ä¸­æ–‡ã€é€£å­—ç¬¦å’Œä¸‹åŠƒç·š
        topic_clean = re.sub(r"[^\w\-\u4e00-\u9fff]", "_", topic)
        # é™åˆ¶é•·åº¦
        if len(topic_clean) > 50:
            topic_clean = topic_clean[:50]
        if topic_clean:
            return f"{topic_clean}.md"

    # åŒ¹é… "ç”¢ç”ŸXXXæ–‡ä»¶"ã€"ç”ŸæˆXXXæ–‡ä»¶"ã€"å‰µå»ºXXXæ–‡ä»¶" ç­‰æ¨¡å¼
    pattern = r"(?:ç”¢ç”Ÿ|ç”Ÿæˆ|å‰µå»º|å»ºç«‹|è£½ä½œ|åšæˆ|å¯«æˆ|è¼¸å‡ºæˆ|æ•´ç†æˆ)\s*([A-Za-z0-9_\-\u4e00-\u9fff\s]+?)\s*(?:æ–‡ä»¶|æª”æ¡ˆ|æ–‡æª”|document)"
    match = re.search(pattern, t, re.IGNORECASE)
    if match:
        topic = match.group(1).strip()
        # æ¸…ç†ä¸»é¡Œåç¨±ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™å­—æ¯ã€æ•¸å­—ã€ä¸­æ–‡ã€é€£å­—ç¬¦å’Œä¸‹åŠƒç·š
        topic_clean = re.sub(r"[^\w\-\u4e00-\u9fff]", "_", topic)
        # é™åˆ¶é•·åº¦
        if len(topic_clean) > 50:
            topic_clean = topic_clean[:50]
        return f"{topic_clean}.md"

    # åŸæœ‰é‚è¼¯
    if "æ•´ç†" in t and "å°è©±" in t:
        return "conversation-summary.md"

    return "ai-output.md"


def _file_type_for_filename(filename: str) -> str:
    ext = Path(filename).suffix.lower()
    if ext == ".md":
        return "text/markdown"
    if ext == ".txt":
        return "text/plain"
    if ext == ".json":
        return "application/json"
    return "text/plain"


def _looks_like_edit_file_intent(text: str) -> bool:
    """
    æª¢æ¸¬æ˜¯å¦ç‚ºç·¨è¼¯æª”æ¡ˆæ„åœ–ã€‚
    æ¨¡å¼ï¼š
    - "å¹«æˆ‘ä¿®æ”¹ @xxx.md"
    - "åœ¨ @xxx.md ä¸­å¢åŠ "
    - "ç·¨è¼¯ @xxx.md"
    - "æ›´æ–° @xxx.md"
    - "å¹«æˆ‘åœ¨ @xxx.md å¢åŠ ä¸€äº›æ–‡å­—"
    """
    t = (text or "").strip()
    if not t:
        return False

    # æª¢æ¸¬ @filename æ¨¡å¼
    if re.search(r"@[A-Za-z0-9_\-\u4e00-\u9fff/]+\.(md|txt|json)\b", t):
        # é…åˆç·¨è¼¯é—œéµè©
        edit_keywords = [
            "ä¿®æ”¹",
            "ç·¨è¼¯",
            "æ›´æ–°",
            "å¢åŠ ",
            "æ·»åŠ ",
            "åˆªé™¤",
            "ç§»é™¤",
            "å¹«æˆ‘",
            "è«‹",
            "åœ¨",
            "ä¸­",
            "è£¡",
        ]
        if any(k in t for k in edit_keywords):
            return True

    return False


def _parse_file_reference(text: str) -> Optional[str]:
    """
    å¾æ–‡æœ¬ä¸­æå–æª”æ¡ˆå¼•ç”¨ï¼ˆ@filenameï¼‰ã€‚
    è¿”å›æª”åï¼ˆä¸å« @ ç¬¦è™Ÿï¼‰ã€‚
    """
    t = (text or "").strip()
    # åŒ¹é… @filename.ext æ¨¡å¼
    match = re.search(r"@([A-Za-z0-9_\-\u4e00-\u9fff/]+\.(?:md|txt|json))\b", t)
    if match:
        return match.group(1)
    return None


def _find_file_by_name(
    *,
    filename: str,
    task_id: str,
    user_id: str,
) -> Optional[Dict[str, Any]]:
    """
    æ ¹æ“šæª”åæŸ¥æ‰¾æª”æ¡ˆï¼ˆå¾Œç«¯æ­£å¼æª”æ¡ˆï¼‰ã€‚
    è¿”å›æª”æ¡ˆå…ƒæ•¸æ“šï¼ŒåŒ…å« file_idã€‚
    """
    metadata_service = get_metadata_service()
    # æŸ¥è©¢è©² task ä¸‹çš„æª”æ¡ˆ
    files = metadata_service.list(
        task_id=task_id,
        user_id=user_id,
        limit=100,
    )
    # æŸ¥æ‰¾åŒ¹é…çš„æª”åï¼ˆç²¾ç¢ºåŒ¹é…ï¼‰
    for file_meta in files:
        if file_meta.filename == filename:
            return {
                "file_id": file_meta.file_id,
                "filename": file_meta.filename,
                "is_draft": False,
            }
    return None


def _try_edit_file_from_chat_output(
    *,
    user_text: str,
    assistant_text: str,
    task_id: Optional[str],
    current_user: User,
    tenant_id: str,
) -> Optional[Dict[str, Any]]:
    """
    è‹¥ user_text å‘ˆç¾ç·¨è¼¯æª”æ¡ˆæ„åœ–ï¼Œå‰µå»ºç·¨è¼¯è«‹æ±‚ä¸¦è¿”å›é è¦½ã€‚

    æµç¨‹ï¼š
    1. æª¢æ¸¬ç·¨è¼¯æ„åœ–
    2. è§£ææª”æ¡ˆå¼•ç”¨
    3. æŸ¥æ‰¾æª”æ¡ˆï¼ˆå¾Œç«¯ï¼‰
    4. å‰µå»ºç·¨è¼¯è«‹æ±‚ï¼ˆèª¿ç”¨ docs_editing APIï¼‰
    5. è¿”å›é è¦½å’Œ request_id
    """
    if not task_id:
        return None
    if not _looks_like_edit_file_intent(user_text):
        return None

    filename = _parse_file_reference(user_text)
    if not filename:
        return None

    # æŸ¥æ‰¾æª”æ¡ˆï¼ˆåªæŸ¥æ‰¾å¾Œç«¯æ­£å¼æª”æ¡ˆï¼Œè‰ç¨¿æª”ç”±å‰ç«¯è™•ç†ï¼‰
    file_info = _find_file_by_name(
        filename=filename,
        task_id=task_id,
        user_id=current_user.user_id,
    )
    if not file_info:
        # æª”æ¡ˆä¸å­˜åœ¨ï¼Œè¿”å› Noneï¼ˆå‰ç«¯å¯ä»¥è™•ç†è‰ç¨¿æª”ï¼‰
        return None

    # æ¬Šé™æª¢æŸ¥
    perm = get_file_permission_service()
    try:
        perm.check_file_access(
            user=current_user,
            file_id=file_info["file_id"],
            required_permission=Permission.FILE_UPDATE.value,
        )
    except Exception as exc:  # noqa: BLE001
        logger.warning(
            "genai_chat_file_edit_permission_denied",
            error=str(exc),
            file_id=file_info["file_id"],
            user_id=current_user.user_id,
        )
        return None

    # ç²å–æª”æ¡ˆå…ƒæ•¸æ“š
    metadata_service = get_metadata_service()
    file_meta = metadata_service.get(file_info["file_id"])
    if file_meta is None:
        return None

    # æª¢æ¸¬æ–‡ä»¶æ ¼å¼
    doc_format = detect_doc_format(filename=file_meta.filename, file_type=file_meta.file_type)
    if doc_format not in {"md", "txt", "json"}:
        return None

    # ç²å–ç•¶å‰ç‰ˆæœ¬
    from api.routers.docs_editing import _get_doc_version

    current_version = _get_doc_version(file_meta.custom_metadata)

    # å‰µå»ºç·¨è¼¯è«‹æ±‚
    # ä½¿ç”¨ assistant_text ä½œç‚ºç·¨è¼¯æŒ‡ä»¤ï¼ˆç°¡åŒ–è™•ç†ï¼šå°‡ AI å›å¾©ä½œç‚ºã€Œæ›¿æ›æ•´å€‹æª”æ¡ˆã€çš„æŒ‡ä»¤ï¼‰
    # å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œå¯ä»¥è®“ LLM ç”Ÿæˆæ›´ç²¾ç¢ºçš„ç·¨è¼¯æŒ‡ä»¤
    instruction = f"æ ¹æ“šä»¥ä¸‹å…§å®¹æ›´æ–°æª”æ¡ˆï¼š\n\n{assistant_text}"

    request_id = str(uuid.uuid4())
    record = DocEditRequestRecord(
        request_id=request_id,
        tenant_id=tenant_id,
        user_id=current_user.user_id,
        file_id=file_info["file_id"],
        task_id=task_id,
        doc_format=doc_format,  # type: ignore[arg-type]
        instruction=instruction,
        base_version=int(current_version),
        status=DocEditStatus.queued,
    )

    store = get_doc_edit_request_store_service()
    store.create(record)

    # å•Ÿå‹•é è¦½ä»»å‹™ï¼ˆä½¿ç”¨ asyncio.create_taskï¼‰
    try:
        from api.routers.docs_editing import _run_preview_request

        loop = asyncio.get_event_loop()
        if loop.is_running():
            task = asyncio.create_task(_run_preview_request(request_id=request_id))
            # è¨»å†Šä»»å‹™ï¼ˆå¦‚æœéœ€è¦è¿½è¹¤ï¼‰
            from api.routers.docs_editing import _register_request_task

            _register_request_task(request_id=request_id, task=task)
        else:
            # å¦‚æœæ²’æœ‰é‹è¡Œä¸­çš„ loopï¼Œä½¿ç”¨ run_until_completeï¼ˆä¸æ‡‰è©²ç™¼ç”Ÿï¼‰
            logger.warning(
                "genai_chat_file_edit_no_event_loop",
                request_id=request_id,
                file_id=file_info["file_id"],
            )
    except Exception as exc:  # noqa: BLE001
        logger.warning(
            "genai_chat_file_edit_start_preview_failed",
            error=str(exc),
            request_id=request_id,
            file_id=file_info["file_id"],
        )

    return {
        "type": "file_edited",
        "file_id": file_info["file_id"],
        "filename": filename,
        "request_id": request_id,
        "task_id": task_id,
        "is_draft": False,
    }


def _ensure_folder_path(
    *,
    task_id: str,
    user_id: str,
    folder_path: str,
) -> Optional[str]:
    """
    ç¢ºä¿ folder_pathï¼ˆä¾‹å¦‚ a/b/cï¼‰å­˜åœ¨æ–¼ folder_metadataã€‚
    å›å‚³æœ€æ·±å±¤ folder_idï¼ˆç”¨æ–¼ file_metadata.folder_idï¼‰ã€‚

    æ³¨æ„ï¼šfolder_metadata æ˜¯ UI/æŸ¥è©¢ç”¨çš„ã€Œé‚è¼¯è³‡æ–™å¤¾ã€ï¼Œæª”æ¡ˆå¯¦é«”ä»åœ¨ task workspace æ ¹ç›®éŒ„ã€‚
    """
    folder_path = (folder_path or "").strip().strip("/")
    if not folder_path:
        return None

    client = get_arango_client()
    if client.db is None or client.db.aql is None:
        return None

    # ç¢ºä¿é›†åˆå­˜åœ¨
    if not client.db.has_collection(_FOLDER_COLLECTION_NAME):
        client.db.create_collection(_FOLDER_COLLECTION_NAME)
        col = client.db.collection(_FOLDER_COLLECTION_NAME)
        col.add_index({"type": "persistent", "fields": ["task_id"]})
        col.add_index({"type": "persistent", "fields": ["user_id"]})

    parent_task_id: str = f"{task_id}_workspace"
    folder_id: Optional[str] = None

    for seg in [p for p in folder_path.split("/") if p]:
        # æŸ¥è©¢æ˜¯å¦å·²å­˜åœ¨åŒåè³‡æ–™å¤¾ï¼ˆåŒä¸€ parent ä¸‹ï¼‰
        query = f"""
            FOR folder IN {_FOLDER_COLLECTION_NAME}
                FILTER folder.task_id == @task_id
                FILTER folder.user_id == @user_id
                FILTER folder.parent_task_id == @parent_task_id
                FILTER folder.folder_name == @folder_name
                LIMIT 1
                RETURN folder
        """
        cursor = client.db.aql.execute(
            query,
            bind_vars={
                "task_id": task_id,
                "user_id": user_id,
                "parent_task_id": parent_task_id,
                "folder_name": seg,
            },
        )
        existing = next(cursor, None) if cursor else None  # type: ignore[arg-type]  # cursor å¯èƒ½ç‚º None
        if existing and isinstance(existing, dict) and existing.get("_key"):
            folder_id = str(existing["_key"])
            parent_task_id = folder_id
            continue

        # å»ºç«‹æ–°è³‡æ–™å¤¾
        new_id = str(uuid.uuid4())
        now_iso = datetime.utcnow().isoformat()
        doc = {
            "_key": new_id,
            "task_id": task_id,
            "folder_name": seg,
            "user_id": user_id,
            "parent_task_id": parent_task_id,
            "created_at": now_iso,
            "updated_at": now_iso,
        }
        client.db.collection(_FOLDER_COLLECTION_NAME).insert(doc)
        folder_id = new_id
        parent_task_id = new_id

    return folder_id


def _try_create_file_from_chat_output(
    *,
    user_text: str,
    assistant_text: str,
    task_id: Optional[str],
    current_user: User,
    force_create: bool = False,
) -> Optional[Dict[str, Any]]:
    """
    è‹¥ user_text å‘ˆç¾å»ºæª”æ„åœ–ï¼Œå°‡ assistant_text å¯«å…¥ task workspaceï¼ˆé è¨­æ ¹ç›®éŒ„ï¼‰ã€‚
    è‹¥æŒ‡å®šç›®éŒ„ï¼ˆå¦‚ docs/a.mdï¼‰ï¼Œå‰‡å»ºç«‹å°æ‡‰é‚è¼¯è³‡æ–™å¤¾ï¼ˆfolder_metadataï¼‰ä¸¦å°‡ file_metadata.folder_id æŒ‡å‘è©²è³‡æ–™å¤¾ã€‚

    Args:
        user_text: ç”¨æˆ¶è¼¸å…¥æ–‡æœ¬
        assistant_text: AI ç”Ÿæˆçš„æ–‡æœ¬å…§å®¹
        task_id: ä»»å‹™ ID
        current_user: ç•¶å‰ç”¨æˆ¶
        force_create: å¦‚æœç‚º Trueï¼Œå¼·åˆ¶å‰µå»ºæ–‡ä»¶ï¼ˆä¸ä¾è³´é—œéµè©åŒ¹é…ï¼‰ï¼Œç”¨æ–¼ Task Analyzer è­˜åˆ¥å‡ºçš„æ–‡æª”å‰µå»ºæ„åœ–
    """
    # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - æ·»åŠ è©³ç´°æ—¥èªŒè¿½è¹¤æ–‡ä»¶å‰µå»ºæµç¨‹
    logger.info(
        "try_create_file_start",
        task_id=task_id,
        user_id=current_user.user_id if current_user else None,
        user_text=user_text[:200],
        assistant_text_length=len(assistant_text),
        force_create=force_create,
    )

    if not task_id:
        logger.warning(
            "try_create_file_no_task_id",
            user_text=user_text[:200],
            note="task_id is None, cannot create file",
        )
        return None

    # å¦‚æœ force_create=Trueï¼Œè·³éé—œéµè©åŒ¹é…ï¼ˆç”¨æ–¼ Task Analyzer èªç¾©åˆ†æè­˜åˆ¥çš„æ„åœ–ï¼‰
    if not force_create:
        if not _looks_like_create_file_intent(user_text):
            logger.info(
                "try_create_file_no_intent_match",
                task_id=task_id,
                user_text=user_text[:200],
                note="does not look like create file intent",
            )
            return None

    folder_path, filename = _parse_target_path(user_text)
    logger.info(
        "try_create_file_parsed_path",
        task_id=task_id,
        folder_path=folder_path,
        filename=filename,
        user_text=user_text[:200],
    )

    if not filename:
        filename = _default_filename_for_intent(user_text)
        logger.info(
            "try_create_file_using_default_filename",
            task_id=task_id,
            default_filename=filename,
            user_text=user_text[:200],
        )

    # åªå…è¨± md/txt/json
    ext = Path(filename).suffix.lower()
    logger.info(
        "try_create_file_checking_extension",
        task_id=task_id,
        filename=filename,
        extension=ext,
    )

    if ext not in (".md", ".txt", ".json"):
        logger.warning(
            "try_create_file_invalid_extension",
            task_id=task_id,
            filename=filename,
            extension=ext,
            note="only .md, .txt, .json are allowed",
        )
        return None

    # æ¬Šé™ï¼šéœ€è¦èƒ½åœ¨ task ä¸‹æ–°å¢/æ›´æ–°æª”æ¡ˆ
    try:
        perm = get_file_permission_service()
        perm.check_task_file_access(
            user=current_user,
            task_id=task_id,
            required_permission=Permission.FILE_UPDATE.value,
        )
        perm.check_upload_permission(user=current_user)
        logger.info(
            "try_create_file_permission_check_passed",
            task_id=task_id,
            filename=filename,
        )
    except Exception as perm_error:
        logger.error(
            "try_create_file_permission_check_failed",
            task_id=task_id,
            filename=filename,
            error=str(perm_error),
            exc_info=True,
        )
        return None

    folder_id = None
    if folder_path:
        try:
            folder_id = _ensure_folder_path(
                task_id=task_id,
                user_id=current_user.user_id,
                folder_path=folder_path,
            )
            logger.info(
                "try_create_file_folder_ensured",
                task_id=task_id,
                folder_path=folder_path,
                folder_id=folder_id,
            )
        except Exception as folder_error:
            logger.error(
                "try_create_file_folder_creation_failed",
                task_id=task_id,
                folder_path=folder_path,
                error=str(folder_error),
                exc_info=True,
            )
            return None

    try:
        content_bytes = (assistant_text or "").rstrip("\n").encode("utf-8") + b"\n"
        storage = get_storage()
        file_id, storage_path = storage.save_file(
            file_content=content_bytes,
            filename=filename,
            task_id=task_id,
        )
        logger.info(
            "try_create_file_storage_saved",
            task_id=task_id,
            filename=filename,
            file_id=file_id,
            storage_path=storage_path,
            content_size=len(content_bytes),
        )
    except Exception as storage_error:
        logger.error(
            "try_create_file_storage_save_failed",
            task_id=task_id,
            filename=filename,
            error=str(storage_error),
            exc_info=True,
        )
        return None

    try:
        metadata_service = get_metadata_service()
        metadata_service.create(
            FileMetadataCreate(
                file_id=file_id,
                filename=filename,
                file_type=_file_type_for_filename(filename),
                file_size=len(content_bytes),
                processing_status=None,  # type: ignore[call-arg]  # æ‰€æœ‰åƒæ•¸éƒ½æ˜¯ Optional
                chunk_count=None,  # type: ignore[call-arg]
                vector_count=None,  # type: ignore[call-arg]
                kg_status=None,  # type: ignore[call-arg]
                user_id=current_user.user_id,
                task_id=task_id,
                folder_id=folder_id,
                storage_path=storage_path,
                tags=["genai", "chat"],
                description="Created from chat intent",
                status="generated",
            )
        )
        logger.info(
            "try_create_file_metadata_created",
            task_id=task_id,
            filename=filename,
            file_id=file_id,
        )
    except Exception as metadata_error:
        logger.error(
            "try_create_file_metadata_creation_failed",
            task_id=task_id,
            filename=filename,
            file_id=file_id,
            error=str(metadata_error),
            exc_info=True,
        )
        # å³ä½¿ metadata å‰µå»ºå¤±æ•—ï¼Œä¹Ÿè¿”å›æ–‡ä»¶å‰µå»ºçµæœï¼ˆå› ç‚ºæ–‡ä»¶å·²ç¶“ä¿å­˜ï¼‰
        # ä½†è¨˜éŒ„éŒ¯èª¤ä»¥ä¾¿å¾ŒçºŒä¿®å¾©

    result = {
        "type": "file_created",
        "file_id": file_id,
        "filename": filename,
        "task_id": task_id,
        "folder_id": folder_id,
        "folder_path": folder_path,
    }

    logger.info(
        "try_create_file_success",
        task_id=task_id,
        filename=filename,
        file_id=file_id,
        result=result,
    )

    return result


def _record_if_changed(
    *,
    context_manager: ContextManager,
    session_id: str,
    role: str,
    content: str,
    agent_name: Optional[str] = None,
    metadata: Optional[Dict[str, Any]] = None,
) -> bool:
    """
    é˜²æ­¢å‰ç«¯é‡é€ history é€ æˆé‡è¤‡è¨˜éŒ„ï¼š
    è‹¥æœ€å¾Œä¸€ç­†ï¼ˆrole, contentï¼‰ç›¸åŒï¼Œå‰‡è·³éå¯«å…¥ã€‚
    """
    normalized_content = str(content or "").strip()
    if not normalized_content:
        return False

    try:
        last_messages = context_manager.get_messages(session_id=session_id, limit=1)
        if last_messages:
            last = last_messages[-1]
            if str(last.role) == role and str(last.content).strip() == normalized_content:
                return False
    except Exception:  # noqa: BLE001
        # å–æœ€å¾Œæ¶ˆæ¯å¤±æ•—æ™‚ä¸é˜»æ“‹å¯«å…¥
        pass

    return context_manager.record_message(
        session_id=session_id,
        role=role,
        content=normalized_content,
        agent_name=agent_name,
        metadata=metadata,
    )


def _infer_provider_from_model_id(model_id: str) -> LLMProvider:
    """ä»¥ç´„å®šå„ªå…ˆçš„ heuristic æ¨å° providerï¼ˆMVPï¼‰ã€‚"""
    m = model_id.lower()

    # å…·å‚™ ollama å¸¸è¦‹æ¨™è¨˜ï¼ˆæœ¬åœ°æ¨¡å‹æˆ–å¸¶ tagï¼‰
    if ":" in m or m in {"llama2", "gpt-oss:20b", "qwen3-coder:30b"}:
        return LLMProvider.OLLAMA

    if m.startswith("gpt-") or m.startswith("openai") or "gpt" in m:
        return LLMProvider.CHATGPT
    if m.startswith("gemini"):
        return LLMProvider.GEMINI
    if m.startswith("grok"):
        return LLMProvider.GROK
    if m.startswith("qwen"):
        # qwen-turbo / qwen-plus ç­‰é›²ç«¯ provider
        return LLMProvider.QWEN

    # fallbackï¼šç›¡é‡ä¸é˜»æ“‹ï¼ˆé è¨­æœ¬åœ°ï¼‰
    return LLMProvider.OLLAMA


def _extract_content(result: Dict[str, Any]) -> str:
    return str(result.get("content") or result.get("message") or result.get("text") or "")


def _register_request_task(*, request_id: str, task: asyncio.Task[None]) -> None:
    with _request_tasks_lock:
        _request_tasks[request_id] = task


def _pop_request_task(*, request_id: str) -> Optional[asyncio.Task[None]]:
    with _request_tasks_lock:
        return _request_tasks.pop(request_id, None)


def _get_request_task(*, request_id: str) -> Optional[asyncio.Task[None]]:
    with _request_tasks_lock:
        return _request_tasks.get(request_id)


async def _process_chat_request(
    *,
    request_body: ChatRequest,
    request_id: str,
    tenant_id: str,
    current_user: User,
) -> ChatResponse:
    """
    å¯é‡ç”¨çš„ chat pipelineï¼ˆåŒæ­¥å…¥å£ / éåŒæ­¥ request å…¥å£å…±ç”¨ï¼‰ã€‚

    æ³¨æ„ï¼šæ­¤å‡½æ•¸æœƒæ²¿ç”¨ç¾æœ‰çš„å¯è§€æ¸¬æ€§ï¼ˆtrace/metricsï¼‰èˆ‡è¨˜æ†¶/ä¸Šä¸‹æ–‡æµç¨‹ã€‚
    """
    moe = get_moe_manager()
    classifier = get_task_classifier()
    context_manager = get_context_manager()
    memory_service = get_chat_memory_service()
    trace_store = get_genai_trace_store_service()
    metrics = get_genai_metrics_service()
    config_resolver = get_genai_config_resolver_service()
    policy_gate = config_resolver.get_effective_policy_gate(
        tenant_id=tenant_id,
        user_id=current_user.user_id,
    )
    file_permission_service = get_file_permission_service()

    session_id = request_body.session_id or str(uuid.uuid4())
    task_id = request_body.task_id

    messages = [m.model_dump() for m in request_body.messages]
    model_selector = request_body.model_selector

    routing: Dict[str, Any] = {}
    observability = ObservabilityInfo(
        request_id=request_id,
        session_id=session_id,
        task_id=task_id,
        token_input=None,  # type: ignore[call-arg]  # token_input æœ‰é»˜èªå€¼
    )

    start_time = time.perf_counter()

    # G5ï¼šå…¥å£äº‹ä»¶ï¼ˆlog + traceï¼‰
    logger.info(
        "genai_chat_request_received",
        request_id=request_id,
        session_id=session_id,
        task_id=task_id,
        user_id=current_user.user_id,
        model_selector_mode=model_selector.mode,
        model_id=model_selector.model_id,
    )
    trace_store.add_event(
        GenAITraceEvent(
            event="chat.request_received",
            request_id=request_id,
            session_id=session_id,
            task_id=task_id,
            user_id=current_user.user_id,
            status="ok",
        )
    )

    # å–æœ€å¾Œä¸€å‰‡ user messageï¼ˆè‹¥æ‰¾ä¸åˆ°å°±å–æœ€å¾Œä¸€å‰‡ï¼‰
    user_messages = [m for m in messages if m.get("role") == "user"]
    last_user_text = (str(user_messages[-1].get("content", "")) if user_messages else "").strip()
    if not last_user_text and messages:
        last_user_text = str(messages[-1].get("content", "")).strip()

    # G3ï¼šè¨˜éŒ„ user messageï¼ˆé¿å…é‡è¤‡å¯«å…¥ï¼‰
    _record_if_changed(
        context_manager=context_manager,
        session_id=session_id,
        role="user",
        content=last_user_text,
        metadata={
            "user_id": current_user.user_id,
            "session_id": session_id,
            "task_id": task_id,
            "request_id": request_id,
        },
    )

    # ============================================
    # é›†æˆ Task Analyzerï¼ˆ4 å±‚æ¸è¿›å¼è·¯ç”±æ¶æ„ï¼‰
    # ============================================
    task_analyzer_result = None
    try:
        # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - æ·»åŠ èª¿è©¦æ—¥èªŒç¢ºèªä»£ç¢¼åŸ·è¡Œè·¯å¾‘
        import sys

        sys.stderr.write(
            f"\n[task_analyzer] ğŸ” é–‹å§‹èª¿ç”¨ Task Analyzer (éæµå¼)ï¼Œç”¨æˆ¶æŸ¥è©¢: {last_user_text[:100]}...\n"
        )
        sys.stderr.flush()

        task_analyzer = get_task_analyzer()
        # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - å°‡ allowed_tools å‚³éçµ¦ Task Analyzerï¼Œè®“ Capability Matcher å„ªå…ˆè€ƒæ…®å•Ÿç”¨çš„å·¥å…·
        # æ³¨æ„ï¼šallowed_tools éœ€è¦å¾ request_body ä¸­ç²å–
        allowed_tools_for_analyzer = request_body.allowed_tools or []
        # ä¿®æ”¹æ™‚é–“ï¼š2026-01-27 - å¦‚æœç”¨æˆ¶æ˜ç¢ºé¸æ“‡äº† agent_idï¼Œå„ªå…ˆä½¿ç”¨ç”¨æˆ¶é¸æ“‡çš„ Agent
        user_selected_agent_id = request_body.agent_id
        analysis_result = await task_analyzer.analyze(
            TaskAnalysisRequest(
                task=last_user_text,
                context={
                    "user_id": current_user.user_id,
                    "session_id": session_id,
                    "task_id": task_id,
                    "request_id": request_id,
                    "allowed_tools": allowed_tools_for_analyzer,  # âœ… å‚³é allowed_tools
                    "agent_id": user_selected_agent_id,  # âœ… å‚³éç”¨æˆ¶é¸æ“‡çš„ agent_id
                },
                user_id=current_user.user_id,
                session_id=session_id,
                specified_agent_id=user_selected_agent_id,  # âœ… è¨­ç½® specified_agent_idï¼Œè®“ Task Analyzer å„ªå…ˆä½¿ç”¨ç”¨æˆ¶é¸æ“‡çš„ Agent
            )
        )
        task_analyzer_result = analysis_result

        # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - æ·»åŠ è©³ç´°çš„ Console Log è¼¸å‡º Task Analyzer åˆ†æçµæœ
        # ä½¿ç”¨ sys.stderr ç¢ºä¿è¼¸å‡ºåˆ°æ§åˆ¶å°ï¼ˆä¸è¢«é‡å®šå‘ï¼‰
        import sys

        log_lines = []
        log_lines.append("\n" + "=" * 80)
        log_lines.append("[task_analyzer] Task Analyzer åˆ†æçµæœ")
        log_lines.append("=" * 80)
        log_lines.append(f"[task_analyzer] ç”¨æˆ¶æŸ¥è©¢: {last_user_text}")
        log_lines.append(f"[task_analyzer] Request ID: {request_id}")
        log_lines.append(f"[task_analyzer] Task ID: {task_id}")
        log_lines.append(f"[task_analyzer] Session ID: {session_id}")
        log_lines.append(f"[task_analyzer] Allowed Tools: {allowed_tools_for_analyzer}")
        # ä¿®æ”¹æ™‚é–“ï¼š2026-01-27 - è¨˜éŒ„ç”¨æˆ¶é¸æ“‡çš„ agent_id
        if user_selected_agent_id:
            log_lines.append(f"[task_analyzer] ç”¨æˆ¶é¸æ“‡çš„ Agent ID: {user_selected_agent_id}")
            log_lines.append("[task_analyzer] âš ï¸  ç”¨æˆ¶æ˜ç¢ºé¸æ“‡äº† Agentï¼Œå°‡å„ªå…ˆä½¿ç”¨ç”¨æˆ¶é¸æ“‡çš„ Agent")

        if task_analyzer_result:
            # Router Decision ä¿¡æ¯
            router_decision = (
                task_analyzer_result.router_decision
                if hasattr(task_analyzer_result, "router_decision")
                else None
            )
            if router_decision:
                log_lines.append("\n[task_analyzer] Router Decision:")
                log_lines.append(f"  - Intent Type: {router_decision.intent_type}")
                log_lines.append(f"  - Complexity: {router_decision.complexity}")
                log_lines.append(f"  - Needs Agent: {router_decision.needs_agent}")
                log_lines.append(f"  - Needs Tools: {router_decision.needs_tools}")
                log_lines.append(
                    f"  - Determinism Required: {router_decision.determinism_required}"
                )
                log_lines.append(f"  - Risk Level: {router_decision.risk_level}")
                log_lines.append(f"  - Confidence: {router_decision.confidence}")

            # Decision Result ä¿¡æ¯
            decision_result = (
                task_analyzer_result.decision_result
                if hasattr(task_analyzer_result, "decision_result")
                else None
            )
            if decision_result:
                log_lines.append("\n[task_analyzer] Decision Result:")
                log_lines.append(f"  - Chosen Agent: {decision_result.chosen_agent}")
                log_lines.append(f"  - Chosen Tools: {decision_result.chosen_tools}")
                log_lines.append(f"  - Chosen Model: {decision_result.chosen_model}")
                log_lines.append(f"  - Score: {decision_result.score}")
                log_lines.append(f"  - Reasoning: {decision_result.reasoning}")
                log_lines.append(f"  - Fallback Used: {decision_result.fallback_used}")

            # Analysis Details
            analysis_details = (
                task_analyzer_result.analysis_details
                if hasattr(task_analyzer_result, "analysis_details")
                else {}
            )
            if analysis_details:
                log_lines.append("\n[task_analyzer] Analysis Details:")
                log_lines.append(f"  - Layer: {analysis_details.get('layer', 'N/A')}")
                log_lines.append(
                    f"  - Direct Answer: {analysis_details.get('direct_answer', False)}"
                )
                if analysis_details.get("direct_answer"):
                    log_lines.append(
                        f"  - Response: {str(analysis_details.get('response', ''))[:200]}..."
                    )

            # ç‰¹åˆ¥æ¨™è¨»æ–‡ä»¶å‰µå»ºç›¸é—œçš„åˆ¤æ–·
            decision_result = (
                task_analyzer_result.decision_result
                if hasattr(task_analyzer_result, "decision_result")
                else None
            )
            if decision_result and decision_result.chosen_tools:
                has_doc_editing = (
                    "document_editing" in decision_result.chosen_tools
                    or "file_editing" in decision_result.chosen_tools
                )
                log_lines.append("\n[task_analyzer] ğŸ“ æ–‡ä»¶å‰µå»ºåˆ¤æ–·:")
                log_lines.append(f"  - Document Editing Tool Selected: {has_doc_editing}")
                if has_doc_editing:
                    log_lines.append("  - âœ… ç³»çµ±å°‡å˜—è©¦å‰µå»ºæ–‡ä»¶")
                else:
                    log_lines.append("  - âš ï¸  æœªé¸æ“‡ document_editing å·¥å…·ï¼Œå°‡ä½¿ç”¨é—œéµè©åŒ¹é…ä½œç‚º fallback")
        else:
            log_lines.append("\n[task_analyzer] âš ï¸  Task Analyzer çµæœç‚º None")

        log_lines.append("=" * 80 + "\n")

        # è¼¸å‡ºåˆ° stderrï¼ˆç¢ºä¿é¡¯ç¤ºåœ¨æ§åˆ¶å°ï¼‰
        for line in log_lines:
            sys.stderr.write(line + "\n")
            sys.stderr.flush()

        # æ£€æŸ¥æ˜¯å¦æ˜¯ Layer 1 ç›´æ¥ç­”æ¡ˆ
        if analysis_result.analysis_details.get("direct_answer"):
            logger.info(
                "task_analyzer_layer1_direct_answer",
                request_id=request_id,
                user_text=last_user_text[:200],
                layer=analysis_result.analysis_details.get("layer"),
                model=analysis_result.analysis_details.get("model"),
            )

            # è·å–ç›´æ¥ç­”æ¡ˆå†…å®¹
            response_content = analysis_result.analysis_details.get("response", "")
            if response_content:
                # æ„å»ºå“åº”
                from services.api.models.chat import ChatResponse

                response = ChatResponse(
                    content=response_content,
                    request_id=request_id,
                    session_id=session_id,
                    task_id=task_id,
                    routing=RoutingInfo(
                        provider=(
                            analysis_result.llm_provider.value
                            if hasattr(analysis_result.llm_provider, "value")
                            else str(analysis_result.llm_provider)
                        ),
                        model=analysis_result.analysis_details.get("model", "unknown"),
                        task_classification="direct_answer",
                    ),
                    observability=observability,
                )
                return response
    except Exception as analyzer_error:
        # Task Analyzer å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œè®°å½•æ—¥å¿—åç»§ç»­
        import sys

        sys.stderr.write(f"\n[task_analyzer] âŒ Task Analyzer åŸ·è¡Œå¤±æ•— (éæµå¼): {str(analyzer_error)}\n")
        sys.stderr.flush()
        logger.warning(
            "task_analyzer_failed",
            request_id=request_id,
            error=str(analyzer_error),
            exc_info=True,
        )

    # G3ï¼šç”¨ windowed history ä½œç‚º MoE çš„ messagesï¼ˆä¸¦ä¿ç•™å‰ç«¯æä¾›çš„ system messageï¼‰
    system_messages = [m for m in messages if m.get("role") == "system"]
    windowed_history = context_manager.get_context_with_window(session_id=session_id)
    observability.context_message_count = len(windowed_history)

    # G6ï¼šé™„ä»¶ file_id æ¬Šé™æª¢æŸ¥ï¼ˆé¿å…é€é RAG è®€åˆ°ä¸å±¬æ–¼è‡ªå·±çš„æ–‡ä»¶ï¼‰
    if request_body.attachments:
        for att in request_body.attachments:
            file_permission_service.check_file_access(
                user=current_user,
                file_id=att.file_id,
                required_permission=Permission.FILE_READ.value,
            )

    # G6ï¼šData consent gateï¼ˆAI_PROCESSINGï¼‰- æœªåŒæ„å‰‡ä¸æª¢ç´¢/ä¸æ³¨å…¥/ä¸å¯«å…¥
    has_ai_consent = False
    try:
        from services.api.models.data_consent import ConsentType

        consent_service = get_consent_service()
        has_ai_consent = consent_service.check_consent(
            current_user.user_id, ConsentType.AI_PROCESSING
        )
    except Exception as exc:  # noqa: BLE001
        logger.warning(
            "genai_consent_check_failed",
            error=str(exc),
            request_id=request_id,
            user_id=current_user.user_id,
        )
        has_ai_consent = False

    if has_ai_consent:
        memory_result = await memory_service.retrieve_for_prompt(
            user_id=current_user.user_id,
            session_id=session_id,
            task_id=task_id,
            request_id=request_id,
            query=last_user_text,
            attachments=request_body.attachments,
            user=current_user,  # ä¿®æ”¹æ™‚é–“ï¼š2026-01-02 - å‚³é user å°è±¡ç”¨æ–¼æ¬Šé™æª¢æŸ¥
        )
        observability.memory_hit_count = memory_result.memory_hit_count
        observability.memory_sources = memory_result.memory_sources
        observability.retrieval_latency_ms = memory_result.retrieval_latency_ms
    else:
        from services.api.services.chat_memory_service import MemoryRetrievalResult

        memory_result = MemoryRetrievalResult(
            injection_messages=[],
            memory_hit_count=0,
            memory_sources=[],
            retrieval_latency_ms=0.0,
        )
        observability.memory_hit_count = 0
        observability.memory_sources = []
        observability.retrieval_latency_ms = 0.0

    trace_store.add_event(
        GenAITraceEvent(
            event="chat.memory_retrieved",
            request_id=request_id,
            session_id=session_id,
            task_id=task_id,
            user_id=current_user.user_id,
            memory_hit_count=observability.memory_hit_count,
            memory_sources=observability.memory_sources,
            retrieval_latency_ms=observability.retrieval_latency_ms,
            status="ok",
        )
    )

    # ä¿®æ”¹æ™‚é–“ï¼š2026-01-27 - å¦‚æœé¸æ“‡äº† Agentï¼Œå…ˆèª¿ç”¨ Agent çš„å·¥å…·ç²å–çµæœ
    agent_tool_results = []
    if task_analyzer_result and task_analyzer_result.decision_result:
        chosen_agent_id = task_analyzer_result.decision_result.chosen_agent
        if chosen_agent_id:
            try:
                from agents.services.registry.registry import get_agent_registry
                from mcp.client.client import MCPClient

                registry = get_agent_registry()
                agent_info = registry.get_agent_info(chosen_agent_id)

                if agent_info and agent_info.status.value == "online":
                    logger.info(
                        "agent_selected_for_execution",
                        request_id=request_id,
                        agent_id=chosen_agent_id,
                        agent_name=agent_info.name,
                        capabilities=agent_info.capabilities,
                    )

                    # å¦‚æœ Agent ä½¿ç”¨ MCP å”è­°ï¼Œèª¿ç”¨ Agent çš„å·¥å…·
                    if agent_info.endpoints and agent_info.endpoints.mcp:
                        mcp_endpoint = agent_info.endpoints.mcp
                        logger.info(
                            "calling_agent_mcp_tools",
                            request_id=request_id,
                            agent_id=chosen_agent_id,
                            mcp_endpoint=mcp_endpoint,
                            user_query=last_user_text[:200],
                        )

                        # æ ¹æ“šç”¨æˆ¶æŸ¥è©¢é¸æ“‡åˆé©çš„å·¥å…·
                        # ä¾‹å¦‚ï¼šå¦‚æœæŸ¥è©¢åŒ…å«ã€Œæ–™è™Ÿã€ï¼Œä½¿ç”¨ warehouse_query_part
                        # å¦‚æœæŸ¥è©¢åŒ…å«ã€Œåˆ—å‡ºã€ï¼Œä½¿ç”¨ warehouse_execute_task
                        tool_name = None

                        # å„ªå…ˆåŒ¹é…ï¼šæ ¹æ“šæŸ¥è©¢å…§å®¹é¸æ“‡æœ€åˆé©çš„å·¥å…·
                        query_lower = last_user_text.lower()
                        if "æ–™è™Ÿ" in last_user_text or "æ–™" in last_user_text or "part" in query_lower:
                            # æŸ¥æ‰¾ warehouse_query_part æˆ–é¡ä¼¼çš„æŸ¥è©¢å·¥å…·
                            for cap in agent_info.capabilities:
                                cap_lower = cap.lower()
                                if "query_part" in cap_lower or (
                                    "query" in cap_lower and "part" in cap_lower
                                ):
                                    tool_name = cap
                                    break
                            # å¦‚æœæ²’æ‰¾åˆ°ï¼Œå˜—è©¦å…¶ä»–æŸ¥è©¢å·¥å…·
                            if not tool_name:
                                for cap in agent_info.capabilities:
                                    if "query" in cap.lower():
                                        tool_name = cap
                                        break
                        elif (
                            "åˆ—å‡º" in last_user_text or "å‰" in last_user_text or "list" in query_lower
                        ):
                            # æŸ¥æ‰¾ warehouse_execute_task æˆ–é¡ä¼¼çš„åŸ·è¡Œå·¥å…·
                            for cap in agent_info.capabilities:
                                cap_lower = cap.lower()
                                if "execute" in cap_lower or "task" in cap_lower:
                                    tool_name = cap
                                    break

                        # å¦‚æœæ²’æœ‰æ‰¾åˆ°ç‰¹å®šå·¥å…·ï¼Œä½¿ç”¨ç¬¬ä¸€å€‹å¯ç”¨çš„å·¥å…·
                        if not tool_name and agent_info.capabilities:
                            tool_name = agent_info.capabilities[0]
                            logger.info(
                                "using_first_available_agent_tool",
                                request_id=request_id,
                                agent_id=chosen_agent_id,
                                tool_name=tool_name,
                                all_capabilities=agent_info.capabilities,
                            )

                        if tool_name:
                            try:
                                # é€šé MCP Gateway èª¿ç”¨å·¥å…·
                                gateway_endpoint = os.getenv(
                                    "MCP_GATEWAY_ENDPOINT", "https://mcp.k84.org"
                                )
                                mcp_client = MCPClient(endpoint=gateway_endpoint, timeout=30.0)
                                await mcp_client.initialize()

                                # æ§‹å»ºå·¥å…·åƒæ•¸ï¼ˆæ ¹æ“šç”¨æˆ¶æŸ¥è©¢ï¼‰
                                tool_arguments = {
                                    "query": last_user_text,
                                    "task": last_user_text,
                                }

                                # èª¿ç”¨å·¥å…·
                                tool_result = await mcp_client.call_tool(
                                    name=tool_name,
                                    arguments=tool_arguments,
                                )

                                await mcp_client.close()

                                # å°‡å·¥å…·çµæœæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
                                if tool_result:
                                    # å°‡å·¥å…·çµæœæ ¼å¼åŒ–ç‚ºæ¶ˆæ¯ï¼Œæ³¨å…¥åˆ° LLM ä¸Šä¸‹æ–‡
                                    tool_result_text = str(
                                        tool_result.get("text", tool_result)
                                        if isinstance(tool_result, dict)
                                        else tool_result
                                    )
                                    agent_result_message = {
                                        "role": "system",
                                        "content": f"Agent '{agent_info.name}' åŸ·è¡Œå·¥å…· '{tool_name}' çš„çµæœï¼š\n{tool_result_text}",
                                    }
                                    # å°‡ Agent å·¥å…·çµæœæ¶ˆæ¯æ·»åŠ åˆ°åˆ—è¡¨ä¸­ï¼Œç¨å¾Œæ’å…¥åˆ° messages_for_llm
                                    agent_tool_results.append(
                                        {
                                            "tool_name": tool_name,
                                            "result": tool_result,
                                            "message": agent_result_message,
                                        }
                                    )

                                    logger.info(
                                        "agent_tool_executed",
                                        request_id=request_id,
                                        agent_id=chosen_agent_id,
                                        tool_name=tool_name,
                                        result_length=len(tool_result_text),
                                    )
                            except Exception as agent_error:
                                logger.error(
                                    "agent_tool_execution_failed",
                                    request_id=request_id,
                                    agent_id=chosen_agent_id,
                                    tool_name=tool_name,
                                    error=str(agent_error),
                                    exc_info=True,
                                )
                                # Agent å·¥å…·åŸ·è¡Œå¤±æ•—ä¸å½±éŸ¿ä¸»æµç¨‹ï¼Œç¹¼çºŒåŸ·è¡Œ
            except Exception as agent_registry_error:
                logger.warning(
                    "agent_registry_lookup_failed",
                    request_id=request_id,
                    error=str(agent_registry_error),
                    exc_info=True,
                )
                # Agent æŸ¥æ‰¾å¤±æ•—ä¸å½±éŸ¿ä¸»æµç¨‹ï¼Œç¹¼çºŒåŸ·è¡Œ

    base_system = system_messages[:1] if system_messages else []
    messages_for_llm = base_system + memory_result.injection_messages + windowed_history

    # å°‡ Agent å·¥å…·çµæœæ¶ˆæ¯æ’å…¥åˆ° messages_for_llm é–‹é ­ï¼ˆå„ªå…ˆç´šæœ€é«˜ï¼‰
    for tool_result_item in agent_tool_results:
        if "message" in tool_result_item:
            messages_for_llm.insert(0, tool_result_item["message"])

    # å‘¼å« MoE
    llm_call_start = time.perf_counter()
    if model_selector.mode == "auto":
        allowed_providers = policy_gate.get_allowed_providers()

        # ç²å–ç”¨æˆ¶çš„æ”¶è—æ¨¡å‹åˆ—è¡¨ï¼ˆç”¨æ–¼ Auto æ¨¡å¼å„ªå…ˆé¸æ“‡ï¼‰
        favorite_model_ids: List[str] = []
        try:
            from services.api.services.user_preference_service import get_user_preference_service

            preference_service = get_user_preference_service()
            favorite_model_ids = preference_service.get_favorite_models(
                user_id=current_user.user_id
            )
        except Exception as exc:  # noqa: BLE001
            logger.debug(f"Failed to get favorite models for user {current_user.user_id}: {exc}")
            # fallback åˆ°å…§å­˜ç·©å­˜
            favorite_model_ids = _favorite_models_by_user.get(current_user.user_id, [])

        llm_api_keys = config_resolver.resolve_api_keys_map(
            tenant_id=tenant_id,
            user_id=current_user.user_id,
            providers=allowed_providers,
        )
        task_classification = classifier.classify(
            last_user_text,
            context={
                "user_id": current_user.user_id,
                "session_id": session_id,
                "task_id": task_id,
            },
        )

        result = await moe.chat(
            messages_for_llm,
            task_classification=task_classification,
            context={
                "user_id": current_user.user_id,
                "tenant_id": tenant_id,
                "session_id": session_id,
                "task_id": task_id,
                "allowed_providers": allowed_providers,
                "llm_api_keys": llm_api_keys,
                "favorite_models": favorite_model_ids,  # å‚³éæ”¶è—æ¨¡å‹åˆ—è¡¨
            },
        )
    else:
        selected_model_id = model_selector.model_id or ""
        provider = _infer_provider_from_model_id(selected_model_id)
        if not policy_gate.is_model_allowed(provider.value, selected_model_id):
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail={
                    "message": "Model is not allowed by policy",
                    "error_code": "MODEL_NOT_ALLOWED",
                    "provider": provider.value,
                    "model_id": selected_model_id,
                },
            )
        llm_api_keys = config_resolver.resolve_api_keys_map(
            tenant_id=tenant_id,
            user_id=current_user.user_id,
            providers=[provider.value],
        )
        result = await moe.chat(
            messages_for_llm,
            provider=provider,
            model=selected_model_id,
            context={
                "user_id": current_user.user_id,
                "tenant_id": tenant_id,
                "session_id": session_id,
                "task_id": task_id,
                "llm_api_keys": llm_api_keys,
            },
        )

    llm_latency_ms = (time.perf_counter() - llm_call_start) * 1000.0
    total_latency_ms = (time.perf_counter() - start_time) * 1000.0

    content = _extract_content(result)
    routing = (result.get("_routing") if isinstance(result, dict) else None) or {}
    routing_info = RoutingInfo(
        provider=str(routing.get("provider") or "unknown"),
        model=routing.get("model"),
        strategy=str(routing.get("strategy") or "unknown"),
        latency_ms=routing.get("latency_ms"),
        failover_used=bool(routing.get("failover_used") or False),
        fallback_provider=routing.get("fallback_provider"),
    )

    trace_store.add_event(
        GenAITraceEvent(
            event="chat.llm_completed",
            request_id=request_id,
            session_id=session_id,
            task_id=task_id,
            user_id=current_user.user_id,
            provider=routing_info.provider,
            model=routing_info.model,
            strategy=routing_info.strategy,
            failover_used=routing_info.failover_used,
            fallback_provider=routing_info.fallback_provider,
            llm_latency_ms=llm_latency_ms,
            status="ok",
        )
    )

    # G3ï¼šè¨˜éŒ„ assistant messageï¼ˆé¿å…é‡è¤‡å¯«å…¥ï¼‰
    _record_if_changed(
        context_manager=context_manager,
        session_id=session_id,
        role="assistant",
        content=content,
        metadata={
            "user_id": current_user.user_id,
            "session_id": session_id,
            "task_id": task_id,
            "request_id": request_id,
            "routing": routing,
        },
    )

    if has_ai_consent:
        await memory_service.write_from_turn(
            user_id=current_user.user_id,
            session_id=session_id,
            task_id=task_id,
            request_id=request_id,
            user_text=last_user_text,
            assistant_text=content,
        )

    actions: Optional[List[Dict[str, Any]]] = None
    try:
        # å„ªå…ˆå˜—è©¦ç·¨è¼¯æª”æ¡ˆï¼ˆå¦‚æœæª¢æ¸¬åˆ°ç·¨è¼¯æ„åœ–ï¼‰
        edit_action = _try_edit_file_from_chat_output(
            user_text=last_user_text,
            assistant_text=content,
            task_id=task_id,
            current_user=current_user,
            tenant_id=tenant_id,
        )
        if edit_action:
            actions = [edit_action]
        else:
            # å¦‚æœæ²’æœ‰ç·¨è¼¯æ„åœ–ï¼Œå˜—è©¦å‰µå»ºæª”æ¡ˆ
            # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - å¦‚æœ Task Analyzer é¸æ“‡äº† document_editing å·¥å…·ï¼Œå¼·åˆ¶å‰µå»ºæ–‡ä»¶
            force_create = False
            if task_analyzer_result:
                decision_result = task_analyzer_result.decision_result
                if (
                    decision_result
                    and decision_result.chosen_tools
                    and (
                        "document_editing" in decision_result.chosen_tools
                        or "file_editing" in decision_result.chosen_tools
                    )
                ):
                    force_create = True
                    logger.info(
                        "force_create_file_based_on_task_analyzer",
                        request_id=request_id,
                        chosen_tools=decision_result.chosen_tools,
                        note="Task Analyzer identified document creation intent via semantic analysis",
                    )

            create_action = _try_create_file_from_chat_output(
                user_text=last_user_text,
                assistant_text=content,
                task_id=task_id,
                current_user=current_user,
                force_create=force_create,
            )
            if create_action:
                actions = [create_action]
    except Exception as exc:  # noqa: BLE001
        logger.warning(
            "genai_chat_file_action_failed",
            error=str(exc),
            request_id=request_id,
            session_id=session_id,
            task_id=task_id,
            user_id=current_user.user_id,
        )

    response = ChatResponse(
        content=content,
        session_id=session_id,
        task_id=task_id,
        routing=routing_info,
        observability=observability,
        actions=actions,
    )

    final_event = GenAITraceEvent(
        event="chat.response_sent",
        request_id=request_id,
        session_id=session_id,
        task_id=task_id,
        user_id=current_user.user_id,
        provider=routing_info.provider,
        model=routing_info.model,
        strategy=routing_info.strategy,
        failover_used=routing_info.failover_used,
        fallback_provider=routing_info.fallback_provider,
        memory_hit_count=observability.memory_hit_count,
        memory_sources=observability.memory_sources,
        retrieval_latency_ms=observability.retrieval_latency_ms,
        context_message_count=observability.context_message_count,
        total_latency_ms=total_latency_ms,
        llm_latency_ms=llm_latency_ms,
        status="ok",
    )
    trace_store.add_event(final_event)
    metrics.record_final_event(final_event)

    logger.info(
        "genai_chat_response_sent",
        request_id=request_id,
        session_id=session_id,
        task_id=task_id,
        user_id=current_user.user_id,
        provider=routing_info.provider,
        model=routing_info.model,
        strategy=routing_info.strategy,
        failover_used=routing_info.failover_used,
        fallback_provider=routing_info.fallback_provider,
        memory_hit_count=observability.memory_hit_count,
        memory_sources=observability.memory_sources,
        retrieval_latency_ms=observability.retrieval_latency_ms,
        context_message_count=observability.context_message_count,
        total_latency_ms=total_latency_ms,
        llm_latency_ms=llm_latency_ms,
    )

    return response


@router.post("/stream", status_code=status.HTTP_200_OK)
async def chat_product_stream(
    request_body: ChatRequest,
    request: Request,
    tenant_id: str = Depends(get_current_tenant_id),
    current_user: User = Depends(get_current_user),
) -> StreamingResponse:
    """
    ç”¢å“ç´š Chat æµå¼å…¥å£ï¼šè¿”å› SSE æ ¼å¼çš„æµå¼éŸ¿æ‡‰ã€‚

    - Autoï¼šTaskClassifier â†’ task_classification â†’ é¸æ“‡ provider â†’ èª¿ç”¨å®¢æˆ¶ç«¯ stream
    - Manual/Favoriteï¼šä»¥ model_id æ¨å° providerï¼Œä¸¦åš provider/model override
    """
    import time

    stream_start_time = time.time()

    moe = get_moe_manager()
    classifier = get_task_classifier()
    context_manager = get_context_manager()
    memory_service = get_chat_memory_service()
    policy_gate = get_genai_policy_gate_service()
    config_resolver = get_genai_config_resolver_service()

    session_id = request_body.session_id or str(uuid.uuid4())
    task_id = request_body.task_id
    request_id = getattr(request.state, "request_id", None) or str(uuid.uuid4())

    messages = [m.model_dump() for m in request_body.messages]
    model_selector = request_body.model_selector
    last_user_text = messages[-1].get("content", "") if messages else ""

    # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - åœ¨å…¥å£è™•æ·»åŠ è©³ç´°æ—¥èªŒï¼Œä½¿ç”¨æ¨™æº– logging ç¢ºä¿æ—¥èªŒè¢«è¨˜éŒ„
    import logging

    std_logger = logging.getLogger("api.routers.chat")
    std_logger.info(
        f"[{request_id}] chat_product_stream START - task_id={task_id}, user_id={current_user.user_id}, "
        f"user_text={last_user_text[:100]}, session_id={session_id}"
    )

    # è¨˜éŒ„å·¥å…·ä¿¡æ¯
    allowed_tools = request_body.allowed_tools or []

    # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - æ–‡ä»¶ç·¨è¼¯æ™‚è‡ªå‹•æ·»åŠ  datetime å·¥å…·
    # å¦‚æœ Assistant æ”¯æŒæ–‡ä»¶ç·¨è¼¯ï¼ˆdocument_editingï¼‰ï¼Œè‡ªå‹•æ·»åŠ  datetime å·¥å…·ç”¨æ–¼è¨˜éŒ„æ™‚é–“æˆ³
    if "document_editing" in allowed_tools or "file_editing" in allowed_tools:
        if "datetime" not in allowed_tools:
            allowed_tools.append("datetime")
            logger.info(
                "auto_added_datetime_tool_for_file_editing",
                request_id=request_id,
                allowed_tools=allowed_tools,
            )

    # æ·»åŠ è¯¦ç»†çš„å·¥å…·æ—¥å¿—
    logger.info(
        "chat_request_tools_received",
        request_id=request_id,
        allowed_tools=allowed_tools,
        has_web_search="web_search" in allowed_tools,
        allowed_tools_count=len(allowed_tools),
    )
    logger.info(
        "chat_request_tools",
        request_id=request_id,
        session_id=session_id,
        task_id=task_id,
        allowed_tools=allowed_tools,
        has_web_search="web_search" in allowed_tools,
    )

    async def generate_stream() -> AsyncGenerator[str, None]:
        """ç”Ÿæˆ SSE æ ¼å¼çš„æµå¼æ•¸æ“š"""
        try:
            # å–æœ€å¾Œä¸€å‰‡ user message
            user_messages = [m for m in messages if m.get("role") == "user"]
            last_user_text = str(user_messages[-1].get("content", "")) if user_messages else ""
            if not last_user_text and messages:
                last_user_text = str(messages[-1].get("content", ""))

            # è¨˜éŒ„ user message
            _record_if_changed(
                context_manager=context_manager,
                session_id=session_id,
                role="user",
                content=last_user_text,
                metadata={
                    "user_id": current_user.user_id,
                    "session_id": session_id,
                    "task_id": task_id,
                    "request_id": request_id,
                },
            )

            # ============================================
            # å¿«é€Ÿè·¯å¾„ï¼šç›´æ¥æ£€æµ‹æ—¶é—´æŸ¥è¯¢å¹¶æ‰§è¡Œ DateTimeToolï¼ˆç»•è¿‡ Task Analyzerï¼‰
            # ============================================
            time_keywords = ["æ™‚é–“", "æ™‚åˆ»", "ç¾åœ¨å¹¾é»", "ç¾åœ¨æ™‚é–“", "current time", "what time"]
            last_user_text_lower = last_user_text.lower().strip()
            is_time_query = any(keyword in last_user_text_lower for keyword in time_keywords)

            if is_time_query:
                logger.info(
                    "quick_path_datetime_query",
                    request_id=request_id,
                    user_text=last_user_text[:200],
                )
                try:
                    from tools.time import DateTimeInput, DateTimeTool

                    datetime_tool = DateTimeTool()
                    datetime_input = DateTimeInput(
                        tenant_id=(
                            current_user.tenant_id if hasattr(current_user, "tenant_id") else None
                        ),
                        user_id=current_user.user_id,
                    )
                    tool_result = await datetime_tool.execute(datetime_input)

                    # æ ¼å¼åŒ–æ—¶é—´ç»“æœ
                    time_response = f"ç¾åœ¨çš„æ™‚é–“æ˜¯ï¼š{tool_result.datetime}"
                    if hasattr(tool_result, "timezone"):
                        time_response += f"ï¼ˆæ™‚å€ï¼š{tool_result.timezone}ï¼‰"

                    logger.info(
                        "quick_path_datetime_success",
                        request_id=request_id,
                        datetime=tool_result.datetime,
                    )

                    # è¿”å› SSE æ ¼å¼çš„æµå¼å“åº”
                    yield f"data: {json.dumps({'type': 'start', 'data': {'request_id': request_id, 'session_id': session_id}})}\n\n"
                    yield f"data: {json.dumps({'type': 'content', 'data': {'chunk': time_response}})}\n\n"
                    yield f"data: {json.dumps({'type': 'done', 'data': {}})}\n\n"
                    return
                except Exception as e:
                    logger.error(
                        "quick_path_datetime_failed",
                        request_id=request_id,
                        error=str(e),
                        exc_info=True,
                    )
                    # å¦‚æœå¿«é€Ÿè·¯å¾„å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ Task Analyzer æµç¨‹

            # ============================================
            # é›†æˆ Task Analyzerï¼ˆ4 å±‚æ¸è¿›å¼è·¯ç”±æ¶æ„ï¼‰
            # ============================================
            task_analyzer_result = None
            try:
                # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - æ·»åŠ èª¿è©¦æ—¥èªŒç¢ºèªä»£ç¢¼åŸ·è¡Œè·¯å¾‘
                import sys

                sys.stderr.write(
                    f"\n[task_analyzer] ğŸ” é–‹å§‹èª¿ç”¨ Task Analyzerï¼Œç”¨æˆ¶æŸ¥è©¢: {last_user_text[:100]}...\n"
                )
                sys.stderr.flush()

                task_analyzer = get_task_analyzer()
                # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - å°‡ allowed_tools å‚³éçµ¦ Task Analyzerï¼Œè®“ Capability Matcher å„ªå…ˆè€ƒæ…®å•Ÿç”¨çš„å·¥å…·
                analysis_result = await task_analyzer.analyze(
                    TaskAnalysisRequest(
                        task=last_user_text,
                        context={
                            "user_id": current_user.user_id,
                            "session_id": session_id,
                            "task_id": task_id,
                            "request_id": request_id,
                            "allowed_tools": allowed_tools,  # âœ… å‚³é allowed_tools
                        },
                        user_id=current_user.user_id,
                        session_id=session_id,
                    )
                )
                task_analyzer_result = analysis_result

                # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - æ·»åŠ è©³ç´°çš„ Console Log è¼¸å‡º Task Analyzer åˆ†æçµæœ
                # ä½¿ç”¨ sys.stderr ç¢ºä¿è¼¸å‡ºåˆ°æ§åˆ¶å°ï¼ˆä¸è¢«é‡å®šå‘ï¼‰

                log_lines = []
                log_lines.append("\n" + "=" * 80)
                log_lines.append("[task_analyzer] Task Analyzer åˆ†æçµæœ (æµå¼)")
                log_lines.append("=" * 80)
                log_lines.append(f"[task_analyzer] ç”¨æˆ¶æŸ¥è©¢: {last_user_text}")
                log_lines.append(f"[task_analyzer] Request ID: {request_id}")
                log_lines.append(f"[task_analyzer] Task ID: {task_id}")
                log_lines.append(f"[task_analyzer] Session ID: {session_id}")
                log_lines.append(f"[task_analyzer] Allowed Tools: {allowed_tools}")

                if task_analyzer_result:
                    # Router Decision ä¿¡æ¯
                    router_decision = (
                        task_analyzer_result.router_decision
                        if hasattr(task_analyzer_result, "router_decision")
                        else None
                    )
                    if router_decision:
                        log_lines.append("\n[task_analyzer] Router Decision:")
                        log_lines.append(f"  - Intent Type: {router_decision.intent_type}")
                        log_lines.append(f"  - Complexity: {router_decision.complexity}")
                        log_lines.append(f"  - Needs Agent: {router_decision.needs_agent}")
                        log_lines.append(f"  - Needs Tools: {router_decision.needs_tools}")
                        log_lines.append(
                            f"  - Determinism Required: {router_decision.determinism_required}"
                        )
                        log_lines.append(f"  - Risk Level: {router_decision.risk_level}")
                        log_lines.append(f"  - Confidence: {router_decision.confidence}")

                    # Decision Result ä¿¡æ¯
                    decision_result = (
                        task_analyzer_result.decision_result
                        if hasattr(task_analyzer_result, "decision_result")
                        else None
                    )
                    if decision_result:
                        log_lines.append("\n[task_analyzer] Decision Result:")
                        log_lines.append(f"  - Chosen Agent: {decision_result.chosen_agent}")
                        log_lines.append(f"  - Chosen Tools: {decision_result.chosen_tools}")
                        log_lines.append(f"  - Chosen Model: {decision_result.chosen_model}")
                        log_lines.append(f"  - Score: {decision_result.score}")
                        log_lines.append(f"  - Reasoning: {decision_result.reasoning}")
                        log_lines.append(f"  - Fallback Used: {decision_result.fallback_used}")

                    # Analysis Details
                    analysis_details = (
                        task_analyzer_result.analysis_details
                        if hasattr(task_analyzer_result, "analysis_details")
                        else {}
                    )
                    if analysis_details:
                        log_lines.append("\n[task_analyzer] Analysis Details:")
                        log_lines.append(f"  - Layer: {analysis_details.get('layer', 'N/A')}")
                        log_lines.append(
                            f"  - Direct Answer: {analysis_details.get('direct_answer', False)}"
                        )
                        if analysis_details.get("direct_answer"):
                            log_lines.append(
                                f"  - Response: {str(analysis_details.get('response', ''))[:200]}..."
                            )

                    # ç‰¹åˆ¥æ¨™è¨»æ–‡ä»¶å‰µå»ºç›¸é—œçš„åˆ¤æ–·
                    if decision_result and decision_result.chosen_tools:
                        has_doc_editing = (
                            "document_editing" in decision_result.chosen_tools
                            or "file_editing" in decision_result.chosen_tools
                        )
                        log_lines.append("\n[task_analyzer] ğŸ“ æ–‡ä»¶å‰µå»ºåˆ¤æ–·:")
                        log_lines.append(f"  - Document Editing Tool Selected: {has_doc_editing}")
                        if has_doc_editing:
                            log_lines.append("  - âœ… ç³»çµ±å°‡å˜—è©¦å‰µå»ºæ–‡ä»¶")
                        else:
                            log_lines.append("  - âš ï¸  æœªé¸æ“‡ document_editing å·¥å…·ï¼Œå°‡ä½¿ç”¨é—œéµè©åŒ¹é…ä½œç‚º fallback")
                else:
                    log_lines.append("\n[task_analyzer] âš ï¸  Task Analyzer çµæœç‚º None")

                log_lines.append("=" * 80 + "\n")

                # è¼¸å‡ºåˆ° stderrï¼ˆç¢ºä¿é¡¯ç¤ºåœ¨æ§åˆ¶å°ï¼‰
                for line in log_lines:
                    sys.stderr.write(line + "\n")
                    sys.stderr.flush()

                # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - æ·»åŠ è©³ç´°æ—¥èªŒè¿½è¹¤ Task Analyzer çµæœ
                logger.info(
                    "task_analyzer_result_assigned",
                    request_id=request_id,
                    has_task_analyzer_result=task_analyzer_result is not None,
                    has_decision_result=(
                        task_analyzer_result.decision_result is not None
                        if task_analyzer_result
                        else False
                    ),
                    chosen_tools=(
                        task_analyzer_result.decision_result.chosen_tools
                        if task_analyzer_result and task_analyzer_result.decision_result
                        else None
                    ),
                    router_needs_tools=(
                        task_analyzer_result.router_decision.needs_tools
                        if task_analyzer_result and task_analyzer_result.router_decision
                        else None
                    ),
                    router_intent_type=(
                        task_analyzer_result.router_decision.intent_type
                        if task_analyzer_result and task_analyzer_result.router_decision
                        else None
                    ),
                    router_confidence=(
                        task_analyzer_result.router_decision.confidence
                        if task_analyzer_result and task_analyzer_result.router_decision
                        else None
                    ),
                    user_text=last_user_text[:200],
                    note="Task Analyzer result - check if document_editing tool was selected",
                )

                # æ£€æŸ¥æ˜¯å¦æ˜¯ Layer 1 ç›´æ¥ç­”æ¡ˆ
                if analysis_result.analysis_details.get("direct_answer"):
                    logger.info(
                        "task_analyzer_layer1_direct_answer",
                        request_id=request_id,
                        user_text=last_user_text[:200],
                        layer=analysis_result.analysis_details.get("layer"),
                        model=analysis_result.analysis_details.get("model"),
                    )

                    # è·å–ç›´æ¥ç­”æ¡ˆå†…å®¹
                    response_content = analysis_result.analysis_details.get("response", "")
                    if response_content:
                        # è¿”å› SSE æ ¼å¼çš„æµå¼å“åº”
                        yield f"data: {json.dumps({'type': 'start', 'data': {'request_id': request_id, 'session_id': session_id}})}\n\n"

                        # æµå¼è¾“å‡ºï¼ˆä» ArangoDB system_configs è¯»å–é…ç½®ï¼‰
                        chunk_size = get_streaming_chunk_size()
                        for i in range(0, len(response_content), chunk_size):
                            chunk = response_content[i : i + chunk_size]
                            yield f"data: {json.dumps({'type': 'content', 'data': {'chunk': chunk}})}\n\n"
                            # æ·»åŠ å°å»¶è¿Ÿä»¥æ¨¡æ‹Ÿæµå¼è¾“å‡º
                            await asyncio.sleep(0.01)

                        # å‘é€å®Œæˆæ ‡è®°
                        yield f"data: {json.dumps({'type': 'done', 'data': {}})}\n\n"
                        return
            except Exception as analyzer_error:
                # Task Analyzer å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œè®°å½•æ—¥å¿—åç»§ç»­
                import sys

                sys.stderr.write(f"\n[task_analyzer] âŒ Task Analyzer åŸ·è¡Œå¤±æ•—: {str(analyzer_error)}\n")
                sys.stderr.flush()
                logger.warning(
                    "task_analyzer_failed",
                    request_id=request_id,
                    error=str(analyzer_error),
                    exc_info=True,
                )

            # G3ï¼šç”¨ windowed history ä½œç‚º MoE çš„ messagesï¼ˆä¸¦ä¿ç•™å‰ç«¯æä¾›çš„ system messageï¼‰
            system_messages = [m for m in messages if m.get("role") == "system"]
            windowed_history = context_manager.get_context_with_window(session_id=session_id)

            # ============================================
            # WebSearch Fallback é€»è¾‘ï¼šå¦‚æœ Task Analyzer éœ€è¦å·¥å…·ä½†æ²¡æœ‰åŒ¹é…çš„å·¥å…·ï¼Œfallback åˆ° WebSearch
            # ============================================
            should_trigger_web_search = False
            task_analyzer_has_chosen_tools = False

            if task_analyzer_result:
                # æ£€æŸ¥ Task Analyzer æ˜¯å¦å·²ç»é€‰æ‹©äº†å·¥å…·
                decision_result = task_analyzer_result.decision_result
                router_decision = task_analyzer_result.router_decision

                logger.info(
                    "task_analyzer_result_check",
                    request_id=request_id,
                    has_decision_result=decision_result is not None,
                    has_router_decision=router_decision is not None,
                    chosen_tools=decision_result.chosen_tools if decision_result else None,
                    chosen_tools_len=(
                        len(decision_result.chosen_tools)
                        if decision_result and decision_result.chosen_tools
                        else 0
                    ),
                )

                if (
                    decision_result
                    and decision_result.chosen_tools
                    and len(decision_result.chosen_tools) > 0
                ):
                    # Task Analyzer å·²ç»é€‰æ‹©äº†å·¥å…·ï¼Œåº”è¯¥ä¼˜å…ˆä½¿ç”¨è¿™äº›å·¥å…·
                    task_analyzer_has_chosen_tools = True
                    logger.info(
                        "task_analyzer_has_chosen_tools",
                        request_id=request_id,
                        user_text=last_user_text[:200],
                        chosen_tools=decision_result.chosen_tools,
                    )

                    # æ‰§è¡Œ Task Analyzer é€‰æ‹©çš„å·¥å…·
                    try:
                        from tools import get_tool_registry
                        from tools.time import DateTimeInput, DateTimeTool
                        from tools.web_search import WebSearchInput, WebSearchTool

                        tool_registry = get_tool_registry()
                        tool_results = []

                        for tool_name in decision_result.chosen_tools:
                            tool = tool_registry.get_tool(tool_name)
                            if not tool:
                                logger.warning(
                                    "tool_not_found_in_registry",
                                    request_id=request_id,
                                    tool_name=tool_name,
                                )
                                continue

                            logger.info(
                                "executing_task_analyzer_tool",
                                request_id=request_id,
                                tool_name=tool_name,
                                user_text=last_user_text[:200],
                            )

                            # æ ¹æ®å·¥å…·ç±»å‹æ‰§è¡Œå·¥å…·
                            if tool_name == "datetime":
                                # æ‰§è¡Œ DateTimeTool
                                datetime_tool = DateTimeTool()
                                datetime_input = DateTimeInput(
                                    tenant_id=(
                                        current_user.tenant_id
                                        if hasattr(current_user, "tenant_id")
                                        else None
                                    ),
                                    user_id=current_user.user_id,
                                )
                                tool_result = await datetime_tool.execute(datetime_input)
                                tool_results.append(
                                    {
                                        "tool_name": tool_name,
                                        "result": (
                                            tool_result.model_dump()
                                            if hasattr(tool_result, "model_dump")
                                            else str(tool_result)
                                        ),
                                    }
                                )

                                # æ ¼å¼åŒ–æ—¶é—´ç»“æœç”¨äºè¿”å›ç»™ç”¨æˆ·
                                if hasattr(tool_result, "datetime"):
                                    time_response = f"ç¾åœ¨çš„æ™‚é–“æ˜¯ï¼š{tool_result.datetime}"
                                    if hasattr(tool_result, "timezone"):
                                        time_response += f"ï¼ˆæ™‚å€ï¼š{tool_result.timezone}ï¼‰"

                                    # è¿”å› SSE æ ¼å¼çš„æµå¼å“åº”
                                    yield f"data: {json.dumps({'type': 'start', 'data': {'request_id': request_id, 'session_id': session_id}})}\n\n"
                                    yield f"data: {json.dumps({'type': 'content', 'data': {'chunk': time_response}})}\n\n"
                                    yield f"data: {json.dumps({'type': 'done', 'data': {}})}\n\n"
                                    return
                            elif tool_name == "web_search":
                                # WebSearchTool ä¼šåœ¨åé¢çš„ä»£ç ä¸­å¤„ç†
                                should_trigger_web_search = True
                            elif tool_name in ["document_editing", "file_editing"]:
                                # document_editing å·¥å…·ï¼šTask Analyzer é€šéèªç¾©åˆ†æè­˜åˆ¥å‡ºéœ€è¦æ–‡æª”ç·¨è¼¯å·¥å…·
                                # æ³¨æ„ï¼šé€™è£¡ä¸ä¾è³´é—œéµè©åŒ¹é…ï¼Œè€Œæ˜¯ä¾è³´ Task Analyzer çš„èªç¾©åˆ†æçµæœ
                                logger.info(
                                    "document_editing_tool_selected_by_task_analyzer",
                                    request_id=request_id,
                                    user_text=last_user_text[:200],
                                    note="Task Analyzer identified document editing intent via semantic analysis",
                                )
                                # document_editing å·¥å…·çš„åŸ·è¡Œæœƒåœ¨ AI å›å¾©ç”Ÿæˆå¾Œï¼Œé€šé _try_create_file_from_chat_output è™•ç†
                                # é€™è£¡åªè¨˜éŒ„æ—¥å¿—ï¼Œå¯¦éš›çš„æ–‡æª”ç”Ÿæˆæœƒåœ¨ System Prompt å¢å¼·å¾Œç”± AI å®Œæˆ
                            else:
                                # å…¶ä»–å·¥å…·ï¼šå°è¯•é€šç”¨æ‰§è¡Œæ–¹å¼
                                logger.warning(
                                    "unknown_tool_type",
                                    request_id=request_id,
                                    tool_name=tool_name,
                                )

                        if tool_results:
                            logger.info(
                                "task_analyzer_tools_executed",
                                request_id=request_id,
                                tool_results_count=len(tool_results),
                            )
                    except Exception as tool_error:
                        logger.error(
                            "task_analyzer_tool_execution_failed",
                            request_id=request_id,
                            error=str(tool_error),
                            exc_info=True,
                        )
                        # å·¥å…·æ‰§è¡Œå¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œ
                elif (
                    router_decision
                    and router_decision.needs_tools
                    and decision_result
                    and (not decision_result.chosen_tools or len(decision_result.chosen_tools) == 0)
                ):
                    # éœ€è¦å·¥å…·ä½†æ²¡æœ‰åŒ¹é…çš„å·¥å…·ï¼Œå¦‚æœæœ‰ web_search æƒé™ï¼Œåˆ™ fallback åˆ° WebSearch
                    if "web_search" in allowed_tools:
                        logger.info(
                            "task_analyzer_web_search_fallback",
                            request_id=request_id,
                            user_text=last_user_text[:200],
                            reason="needs_tools_but_no_matching_tools",
                        )
                        should_trigger_web_search = True

            # å·¥å…·è°ƒç”¨ï¼šå¦‚æœå¯ç”¨äº† web_search ä¸”ï¼ˆæ¶ˆæ¯ä¸­åŒ…å«æœç´¢æ„å›¾ æˆ– Task Analyzer å»ºè®® fallback åˆ° WebSearchï¼‰ï¼Œç›´æ¥è°ƒç”¨å·¥å…·
            # ä½†æ˜¯ï¼Œå¦‚æœ Task Analyzer å·²ç»é€‰æ‹©äº†å·¥å…·ï¼Œåº”è¯¥ä¼˜å…ˆä½¿ç”¨ Task Analyzer çš„é€‰æ‹©ï¼Œè€Œä¸æ˜¯æ‰§è¡Œå…³é”®è¯åŒ¹é…
            logger.info(
                "web_search_check",
                request_id=request_id,
                allowed_tools=allowed_tools,
                has_web_search="web_search" in (allowed_tools or []),
                user_text=last_user_text[:200],
                task_analyzer_has_chosen_tools=task_analyzer_has_chosen_tools,
            )

            # æ·»åŠ  print è°ƒè¯•è¾“å‡º
            print(
                f"\n[DEBUG] web_search_check: allowed_tools={allowed_tools}, has_web_search={'web_search' in (allowed_tools or [])}, task_analyzer_has_chosen_tools={task_analyzer_has_chosen_tools}"
            )

            # å¦‚æœ Task Analyzer å·²ç»é€‰æ‹©äº†å·¥å…·ï¼Œè·³è¿‡å…³é”®è¯åŒ¹é…ï¼Œä¼˜å…ˆä½¿ç”¨ Task Analyzer çš„é€‰æ‹©
            # ä½†æ˜¯ï¼Œå¦‚æœ Task Analyzer é€‰æ‹©çš„æ˜¯ web_searchï¼Œåˆ™å…è®¸æ‰§è¡Œ web_search
            if (
                (not task_analyzer_has_chosen_tools or should_trigger_web_search)
                and allowed_tools
                and "web_search" in allowed_tools
            ):
                # æ£€æµ‹æ˜¯å¦éœ€è¦æœç´¢ï¼ˆç®€å•çš„å…³é”®è¯æ£€æµ‹ï¼‰
                # æ‰©å±•å…³é”®è¯åˆ—è¡¨ï¼ŒåŒ…æ‹¬æ›´å¤šæœç´¢æ„å›¾
                # æ³¨æ„ï¼šä»å…³é”®è¯åˆ—è¡¨ä¸­ç§»é™¤äº†"æ™‚é–“"å’Œ"æ™‚åˆ»"ï¼Œå› ä¸ºæ—¶é—´æŸ¥è¯¢åº”è¯¥ä½¿ç”¨ DateTimeTool
                search_keywords = [
                    "ä¸Šç¶²",
                    "æŸ¥è©¢",
                    "æœç´¢",
                    "æœå°‹",
                    "ç¾åœ¨",
                    # "æ™‚é–“",  # ç§»é™¤ï¼šåº”è¯¥ä½¿ç”¨ DateTimeTool
                    # "æ™‚åˆ»",  # ç§»é™¤ï¼šåº”è¯¥ä½¿ç”¨ DateTimeTool
                    "æœ€æ–°",
                    "ç•¶å‰",
                    "http",
                    "https",
                    "www.",
                    ".com",
                    ".net",
                    ".org",  # URL å…³é”®è¯
                    "ç¶²ç«™",
                    "ç¶²é ",
                    "é€£çµ",
                    "éˆæ¥",
                    "ç¶²å€",  # ç½‘ç«™ç›¸å…³
                    "æŸ¥æ‰¾",
                    "æ‰¾",
                    "æœ",
                    "æŸ¥",  # æœç´¢ç›¸å…³
                    "è‚¡åƒ¹",  # è‚¡ä»·æŸ¥è¯¢
                    "è‚¡ç¥¨",  # è‚¡ç¥¨æŸ¥è¯¢
                    "å¤©æ°£",  # å¤©æ°”æŸ¥è¯¢
                    "åŒ¯ç‡",  # æ±‡ç‡æŸ¥è¯¢
                    "stock price",  # è‚¡ä»·æŸ¥è¯¢ï¼ˆè‹±æ–‡ï¼‰
                    "weather",  # å¤©æ°”æŸ¥è¯¢ï¼ˆè‹±æ–‡ï¼‰
                    "exchange rate",  # æ±‡ç‡æŸ¥è¯¢ï¼ˆè‹±æ–‡ï¼‰
                ]
                needs_search = any(keyword in last_user_text for keyword in search_keywords)
                matched_keywords = [kw for kw in search_keywords if kw in last_user_text]

                logger.info(
                    "web_search_intent_check",
                    request_id=request_id,
                    needs_search=needs_search,
                    matched_keywords=matched_keywords,
                    user_text=last_user_text[:200],
                    search_keywords_count=len(search_keywords),
                )

                # æ·»åŠ  print è°ƒè¯•è¾“å‡º
                print(
                    f"[DEBUG] web_search_intent_check: needs_search={needs_search}, matched_keywords={matched_keywords}"
                )

                if needs_search or should_trigger_web_search:
                    try:
                        # ç›´æ¥å¯¼å…¥ web_search æ¨¡å—ï¼Œé¿å…è§¦å‘ tools/__init__.py ä¸­çš„å…¶ä»–å¯¼å…¥
                        from tools.web_search.web_search_tool import WebSearchInput, WebSearchTool

                        logger.info(
                            "web_search_triggered",
                            request_id=request_id,
                            query=last_user_text,
                        )

                        # æ·»åŠ  print è°ƒè¯•è¾“å‡º
                        print(f"[DEBUG] web_search_triggered: query={last_user_text[:100]}")

                        # è°ƒç”¨ web_search å·¥å…·
                        search_tool = WebSearchTool()
                        search_input = WebSearchInput(query=last_user_text, num=5)
                        search_result = await search_tool.execute(search_input)

                        # æ·»åŠ  print è°ƒè¯•è¾“å‡º
                        print(
                            f"[DEBUG] web_search_result: status={search_result.status}, results_count={len(search_result.results) if search_result.results else 0}"
                        )

                        # å°†æœç´¢ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
                        logger.info(
                            "web_search_result",
                            request_id=request_id,
                            status=search_result.status,
                            results_count=(
                                len(search_result.results) if search_result.results else 0
                            ),
                            provider=search_result.provider,
                        )

                        if search_result.status == "success" and search_result.results:
                            search_summary = "\n\n=== ğŸ” ç¶²çµ¡æœç´¢çµæœï¼ˆä¾†è‡ªçœŸå¯¦æœç´¢ï¼‰ ===\n"
                            search_summary += f"æœç´¢æä¾›å•†: {search_result.provider}\n"
                            search_summary += f"çµæœæ•¸é‡: {len(search_result.results)}\n"
                            search_summary += "---\n"
                            logger.debug(
                                "web_search_formatting_results",
                                request_id=request_id,
                                results_type=type(search_result.results).__name__,
                                results_count=len(search_result.results),
                            )

                            for i, result in enumerate(search_result.results[:3], 1):
                                # å¤„ç†ä¸åŒçš„ç»“æœæ ¼å¼ï¼ˆå¯èƒ½æ˜¯ dict æˆ–å¯¹è±¡ï¼‰
                                try:
                                    if isinstance(result, dict):
                                        title = result.get("title", "ç„¡æ¨™é¡Œ")
                                        snippet = result.get("snippet", "ç„¡æ‘˜è¦")
                                        link = result.get("link", "ç„¡éˆæ¥")
                                    elif hasattr(result, "model_dump"):
                                        # å¦‚æœæ˜¯ Pydantic æ¨¡å‹ï¼ˆSearchResultï¼‰ï¼Œä½¿ç”¨ model_dump
                                        result_dict = result.model_dump()
                                        title = result_dict.get("title", "ç„¡æ¨™é¡Œ")
                                        snippet = result_dict.get("snippet", "ç„¡æ‘˜è¦")
                                        link = result_dict.get("link", "ç„¡éˆæ¥")
                                    elif hasattr(result, "to_dict"):
                                        # å¦‚æœæ˜¯ SearchResultItem å¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—å…¸
                                        result_dict = result.to_dict()
                                        title = result_dict.get("title", "ç„¡æ¨™é¡Œ")
                                        snippet = result_dict.get("snippet", "ç„¡æ‘˜è¦")
                                        link = result_dict.get("link", "ç„¡éˆæ¥")
                                    else:
                                        # å¦‚æœæ˜¯å¯¹è±¡ï¼Œå°è¯•ç›´æ¥è®¿é—®å±æ€§ï¼ˆPydantic æ¨¡å‹æ”¯æŒå±æ€§è®¿é—®ï¼‰
                                        title = getattr(result, "title", "ç„¡æ¨™é¡Œ") or "ç„¡æ¨™é¡Œ"
                                        snippet = getattr(result, "snippet", "ç„¡æ‘˜è¦") or "ç„¡æ‘˜è¦"
                                        link = getattr(result, "link", "ç„¡éˆæ¥") or "ç„¡éˆæ¥"

                                    search_summary += f"\nã€æœç´¢çµæœ {i}ã€‘\n"
                                    search_summary += f"æ¨™é¡Œ: {title}\n"
                                    search_summary += f"æ‘˜è¦: {snippet}\n"
                                    search_summary += f"ä¾†æºéˆæ¥: {link}\n"
                                except Exception as format_error:
                                    logger.warning(
                                        "web_search_result_format_error",
                                        request_id=request_id,
                                        result_index=i,
                                        error=str(format_error),
                                        result_type=type(result).__name__,
                                        result_repr=str(result)[:200],
                                    )
                                    # å¦‚æœæ ¼å¼åŒ–å¤±è´¥ï¼Œè‡³å°‘æ·»åŠ åŸºæœ¬ä¿¡æ¯
                                    search_summary += (
                                        f"{i}. æœç´¢çµæœ {i} (æ ¼å¼åŒ–å¤±æ•—: {str(format_error)[:50]})\n\n"
                                    )

                            logger.info(
                                "web_search_summary_created",
                                request_id=request_id,
                                summary_length=len(search_summary),
                                summary_preview=search_summary[:500],  # è®°å½•å‰500å­—ç¬¦
                            )

                            # æ·»åŠ  print è°ƒè¯•è¾“å‡º
                            print(
                                f"[DEBUG] web_search_summary_created: length={len(search_summary)}"
                            )
                            print(f"[DEBUG] search_summary_preview:\n{search_summary[:500]}")

                            # æ›´æ–°æœ€å¾Œä¸€æ¢ç”¨æˆ¶æ¶ˆæ¯ï¼Œæ·»åŠ æœç´¢çµæœ
                            # åœ¨æœç´¢çµæœå‰æ·»åŠ æ˜ç¡®çš„æç¤ºï¼Œè®©AIçŸ¥é“è¿™æ˜¯çœŸå®æœç´¢ç»“æœ
                            search_summary_with_note = (
                                "\n\nã€é‡è¦æç¤ºï¼šä»¥ä¸‹æ˜¯çœŸå¯¦çš„ç¶²çµ¡æœç´¢çµæœï¼Œè«‹åŸºæ–¼é€™äº›çµæœå›ç­”å•é¡Œã€‚"
                                "å¦‚æœæœç´¢çµæœä¸­æ²’æœ‰ç›¸é—œä¿¡æ¯ï¼Œè«‹æ˜ç¢ºèªªæ˜ï¼Œä¸è¦ç·¨é€ å…§å®¹ã€‚ã€‘\n" + search_summary
                            )

                            if windowed_history:
                                windowed_history[-1]["content"] = (
                                    windowed_history[-1].get("content", "")
                                    + search_summary_with_note
                                )
                            else:
                                # å¦‚æœæ²’æœ‰æ­·å²æ¶ˆæ¯ï¼Œå‰µå»ºä¸€æ¢åŒ…å«æœç´¢çµæœçš„æ¶ˆæ¯
                                windowed_history.append(
                                    {
                                        "role": "user",
                                        "content": last_user_text + search_summary_with_note,
                                    }
                                )

                            logger.info(
                                "web_search_completed",
                                request_id=request_id,
                                results_count=len(search_result.results),
                            )
                        else:
                            logger.warning(
                                "web_search_failed",
                                request_id=request_id,
                                status=search_result.status,
                            )
                    except Exception as tool_error:
                        logger.error(
                            "web_search_error",
                            request_id=request_id,
                            error=str(tool_error),
                            exc_info=True,
                        )
                        # å·¥å…·èª¿ç”¨å¤±æ•—ä¸å½±éŸ¿æ­£å¸¸æµç¨‹ï¼Œç¹¼çºŒåŸ·è¡Œ

            # G6ï¼šData consent gateï¼ˆAI_PROCESSINGï¼‰- æœªåŒæ„å‰‡ä¸æª¢ç´¢/ä¸æ³¨å…¥/ä¸å¯«å…¥
            has_ai_consent = False
            try:
                from services.api.models.data_consent import ConsentType

                consent_service = get_consent_service()
                has_ai_consent = consent_service.check_consent(
                    current_user.user_id, ConsentType.AI_PROCESSING
                )
            except Exception as exc:  # noqa: BLE001
                logger.debug(
                    "Failed to check AI consent, assuming no consent", error=str(exc), exc_info=True
                )
                has_ai_consent = False

            if has_ai_consent:
                memory_result = await memory_service.retrieve_for_prompt(
                    user_id=current_user.user_id,
                    session_id=session_id,
                    task_id=task_id,
                    request_id=request_id,
                    query=last_user_text,
                    attachments=request_body.attachments,
                    user=current_user,  # ä¿®æ”¹æ™‚é–“ï¼š2026-01-02 - å‚³é user å°è±¡ç”¨æ–¼æ¬Šé™æª¢æŸ¥
                )
            else:
                from services.api.services.chat_memory_service import MemoryRetrievalResult

                memory_result = MemoryRetrievalResult(
                    injection_messages=[],
                    memory_hit_count=0,
                    memory_sources=[],
                    retrieval_latency_ms=0.0,
                )

            base_system = system_messages[:1] if system_messages else []

            # ä¿®æ”¹æ™‚é–“ï¼š2026-01-27 - å¦‚æœé¸æ“‡äº† Agentï¼Œå…ˆèª¿ç”¨ Agent çš„å·¥å…·ç²å–çµæœï¼ˆæµå¼ç‰ˆæœ¬ï¼‰
            if task_analyzer_result and task_analyzer_result.decision_result:
                chosen_agent_id = task_analyzer_result.decision_result.chosen_agent
                if chosen_agent_id:
                    try:
                        from agents.services.registry.registry import get_agent_registry
                        from mcp.client.client import MCPClient

                        registry = get_agent_registry()
                        agent_info = registry.get_agent_info(chosen_agent_id)

                        if agent_info and agent_info.status.value == "online":
                            logger.info(
                                "agent_selected_for_execution_stream",
                                request_id=request_id,
                                agent_id=chosen_agent_id,
                                agent_name=agent_info.name,
                                capabilities=agent_info.capabilities,
                            )

                            # å¦‚æœ Agent ä½¿ç”¨ MCP å”è­°ï¼Œèª¿ç”¨ Agent çš„å·¥å…·
                            if agent_info.endpoints and agent_info.endpoints.mcp:
                                mcp_endpoint = agent_info.endpoints.mcp
                                logger.info(
                                    "calling_agent_mcp_tools_stream",
                                    request_id=request_id,
                                    agent_id=chosen_agent_id,
                                    mcp_endpoint=mcp_endpoint,
                                    user_query=last_user_text[:200],
                                )

                                # æ ¹æ“šç”¨æˆ¶æŸ¥è©¢é¸æ“‡åˆé©çš„å·¥å…·
                                tool_name = None

                                # å„ªå…ˆåŒ¹é…ï¼šæ ¹æ“šæŸ¥è©¢å…§å®¹é¸æ“‡æœ€åˆé©çš„å·¥å…·
                                query_lower = last_user_text.lower()
                                if (
                                    "æ–™è™Ÿ" in last_user_text
                                    or "æ–™" in last_user_text
                                    or "part" in query_lower
                                ):
                                    # æŸ¥æ‰¾ warehouse_query_part æˆ–é¡ä¼¼çš„æŸ¥è©¢å·¥å…·
                                    for cap in agent_info.capabilities:
                                        cap_lower = cap.lower()
                                        if "query_part" in cap_lower or (
                                            "query" in cap_lower and "part" in cap_lower
                                        ):
                                            tool_name = cap
                                            break
                                    # å¦‚æœæ²’æ‰¾åˆ°ï¼Œå˜—è©¦å…¶ä»–æŸ¥è©¢å·¥å…·
                                    if not tool_name:
                                        for cap in agent_info.capabilities:
                                            if "query" in cap.lower():
                                                tool_name = cap
                                                break
                                elif (
                                    "åˆ—å‡º" in last_user_text
                                    or "å‰" in last_user_text
                                    or "list" in query_lower
                                ):
                                    # æŸ¥æ‰¾ warehouse_execute_task æˆ–é¡ä¼¼çš„åŸ·è¡Œå·¥å…·
                                    for cap in agent_info.capabilities:
                                        cap_lower = cap.lower()
                                        if "execute" in cap_lower or "task" in cap_lower:
                                            tool_name = cap
                                            break

                                # å¦‚æœæ²’æœ‰æ‰¾åˆ°ç‰¹å®šå·¥å…·ï¼Œä½¿ç”¨ç¬¬ä¸€å€‹å¯ç”¨çš„å·¥å…·
                                if not tool_name and agent_info.capabilities:
                                    tool_name = agent_info.capabilities[0]
                                    logger.info(
                                        "using_first_available_agent_tool_stream",
                                        request_id=request_id,
                                        agent_id=chosen_agent_id,
                                        tool_name=tool_name,
                                        all_capabilities=agent_info.capabilities,
                                    )

                                if tool_name:
                                    try:
                                        # é€šé MCP Gateway èª¿ç”¨å·¥å…·
                                        gateway_endpoint = os.getenv(
                                            "MCP_GATEWAY_ENDPOINT", "https://mcp.k84.org"
                                        )
                                        mcp_client = MCPClient(
                                            endpoint=gateway_endpoint, timeout=30.0
                                        )
                                        await mcp_client.initialize()

                                        # æ§‹å»ºå·¥å…·åƒæ•¸ï¼ˆæ ¹æ“šç”¨æˆ¶æŸ¥è©¢ï¼‰
                                        tool_arguments = {
                                            "query": last_user_text,
                                            "task": last_user_text,
                                        }

                                        # èª¿ç”¨å·¥å…·
                                        tool_result = await mcp_client.call_tool(
                                            name=tool_name,
                                            arguments=tool_arguments,
                                        )

                                        await mcp_client.close()

                                        # å°‡å·¥å…·çµæœæ ¼å¼åŒ–ç‚ºæ¶ˆæ¯ï¼Œæ³¨å…¥åˆ° LLM ä¸Šä¸‹æ–‡
                                        if tool_result:
                                            tool_result_text = str(
                                                tool_result.get("text", tool_result)
                                                if isinstance(tool_result, dict)
                                                else tool_result
                                            )
                                            agent_result_message = {
                                                "role": "system",
                                                "content": f"Agent '{agent_info.name}' åŸ·è¡Œå·¥å…· '{tool_name}' çš„çµæœï¼š\n{tool_result_text}",
                                            }
                                            base_system.insert(
                                                0, agent_result_message
                                            )  # æ’å…¥åˆ°é–‹é ­ï¼Œå„ªå…ˆç´šæœ€é«˜

                                            logger.info(
                                                "agent_tool_executed_stream",
                                                request_id=request_id,
                                                agent_id=chosen_agent_id,
                                                tool_name=tool_name,
                                                result_length=len(tool_result_text),
                                            )
                                    except Exception as agent_error:
                                        logger.error(
                                            "agent_tool_execution_failed_stream",
                                            request_id=request_id,
                                            agent_id=chosen_agent_id,
                                            tool_name=tool_name,
                                            error=str(agent_error),
                                            exc_info=True,
                                        )
                                        # Agent å·¥å…·åŸ·è¡Œå¤±æ•—ä¸å½±éŸ¿ä¸»æµç¨‹ï¼Œç¹¼çºŒåŸ·è¡Œ
                    except Exception as agent_registry_error:
                        logger.warning(
                            "agent_registry_lookup_failed_stream",
                            request_id=request_id,
                            error=str(agent_registry_error),
                            exc_info=True,
                        )
                        # Agent æŸ¥æ‰¾å¤±æ•—ä¸å½±éŸ¿ä¸»æµç¨‹ï¼Œç¹¼çºŒåŸ·è¡Œ

            # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - å¦‚æœ Task Analyzer é¸æ“‡äº† document_editing å·¥å…·ï¼Œå¢å¼· System Prompt æŒ‡ç¤º AI ç”Ÿæˆæ–‡æª”å…§å®¹
            # æ³¨æ„ï¼šé€™è£¡ä¸ä¾è³´é—œéµè©åŒ¹é…ï¼Œè€Œæ˜¯ä¾è³´ Task Analyzer çš„èªç¾©åˆ†æçµæœ
            if task_analyzer_result:
                decision_result = task_analyzer_result.decision_result
                if (
                    decision_result
                    and decision_result.chosen_tools
                    and (
                        "document_editing" in decision_result.chosen_tools
                        or "file_editing" in decision_result.chosen_tools
                    )
                ):
                    # Task Analyzer é€šéèªç¾©åˆ†æè­˜åˆ¥å‡ºéœ€è¦ document_editing å·¥å…·
                    # è§£æç›®æ¨™æ–‡ä»¶åï¼ˆå¦‚æœç”¨æˆ¶æŒ‡å®šäº†ï¼‰
                    folder_path, filename = _parse_target_path(last_user_text)
                    if not filename:
                        filename = _default_filename_for_intent(last_user_text)

                    # æ§‹å»ºæ–‡æª”ç”ŸæˆæŒ‡ç¤º
                    doc_format = Path(filename).suffix.lower().lstrip(".")
                    if doc_format not in ["md", "txt", "json"]:
                        doc_format = "md"

                    # æ·»åŠ  System Prompt æŒ‡ç¤º
                    document_generation_instruction = (
                        f"\n\nã€é‡è¦ï¼šç”¨æˆ¶è¦æ±‚ç”Ÿæˆæ–‡æª”ã€‘\n"
                        f"ç”¨æˆ¶æŒ‡ä»¤ï¼š{last_user_text}\n"
                        f"ç›®æ¨™æ–‡ä»¶åï¼š{filename}\n"
                        f"æ–‡æª”æ ¼å¼ï¼š{doc_format}\n\n"
                        f"è«‹æ ¹æ“šç”¨æˆ¶æŒ‡ä»¤ç”Ÿæˆå®Œæ•´çš„æ–‡æª”å…§å®¹ï¼ˆMarkdown æ ¼å¼ï¼‰ã€‚\n"
                        f"- ä¸è¦è¼¸å‡ºè§£é‡‹æ–‡å­—ï¼Œåªè¼¸å‡ºæ–‡æª”å…§å®¹\n"
                        f"- æ–‡æª”æ‡‰è©²åŒ…å«å®Œæ•´çš„çµæ§‹å’Œå…§å®¹\n"
                        f"- å¦‚æœç”¨æˆ¶è¦æ±‚ç”Ÿæˆç‰¹å®šä¸»é¡Œçš„æ–‡æª”ï¼ˆå¦‚ã€ŒData Agent çš„èªªæ˜ã€ï¼‰ï¼Œè«‹ç”Ÿæˆè©²ä¸»é¡Œçš„å®Œæ•´æ–‡æª”\n"
                        f"- æ–‡æª”æ‡‰è©²åŒ…å«æ¨™é¡Œã€ç« ç¯€ã€è©³ç´°èªªæ˜ç­‰å®Œæ•´å…§å®¹\n"
                    )

                    # å°‡æŒ‡ç¤ºæ·»åŠ åˆ° System Message
                    if base_system and len(base_system) > 0:
                        base_system[0]["content"] = (
                            base_system[0].get("content", "") + document_generation_instruction
                        )
                    else:
                        base_system = [
                            {"role": "system", "content": document_generation_instruction}
                        ]

                    logger.info(
                        "document_generation_intent_detected_via_task_analyzer",
                        request_id=request_id,
                        user_text=last_user_text[:200],
                        filename=filename,
                        doc_format=doc_format,
                        chosen_tools=decision_result.chosen_tools,
                        note="Task Analyzer identified document creation intent, added instruction to system prompt",
                    )

            messages_for_llm = base_system + memory_result.injection_messages + windowed_history

            # æº–å‚™ MoE context
            task_classification = None
            provider = None
            model = None

            if model_selector.mode == "auto":
                # G6ï¼šprovider allowlistï¼ˆAutoï¼‰- å°‡ allowlist å‚³çµ¦ MoE åš provider éæ¿¾
                allowed_providers = policy_gate.get_allowed_providers()

                # ç²å–ç”¨æˆ¶çš„æ”¶è—æ¨¡å‹åˆ—è¡¨ï¼ˆç”¨æ–¼ Auto æ¨¡å¼å„ªå…ˆé¸æ“‡ï¼‰
                favorite_model_ids: List[str] = []
                try:
                    from services.api.services.user_preference_service import (
                        get_user_preference_service,
                    )

                    preference_service = get_user_preference_service()
                    favorite_model_ids = preference_service.get_favorite_models(
                        user_id=current_user.user_id
                    )
                except Exception as exc:  # noqa: BLE001
                    logger.debug(
                        f"Failed to get favorite models for user {current_user.user_id}: {exc}"
                    )
                    # fallback åˆ°å…§å­˜ç·©å­˜
                    favorite_model_ids = _favorite_models_by_user.get(current_user.user_id, [])

                # ä»»åŠ¡åˆ†æï¼šä½¿ç”¨ TaskClassifier å¯¹ç”¨æˆ·è¾“å…¥è¿›è¡Œåˆ†ç±»
                logger.info(
                    "task_analysis_start",
                    request_id=request_id,
                    user_text=last_user_text[:200],
                    user_id=current_user.user_id,
                    session_id=session_id,
                    task_id=task_id,
                )

                task_classification = classifier.classify(
                    last_user_text,
                    context={
                        "user_id": current_user.user_id,
                        "session_id": session_id,
                        "task_id": task_id,
                    },
                )

                logger.info(
                    "task_analysis_completed",
                    request_id=request_id,
                    task_type=task_classification.type.value if task_classification else None,
                    confidence=task_classification.confidence if task_classification else None,
                    reasoning=(
                        task_classification.reasoning[:200]
                        if task_classification and task_classification.reasoning
                        else None
                    ),
                )

                # æ·»åŠ  print è°ƒè¯•è¾“å‡º
                print("\n[DEBUG] Task Analysis Result:")
                print(
                    f"  Type: {task_classification.type.value if task_classification else 'None'}"
                )
                print(
                    f"  Confidence: {task_classification.confidence if task_classification else 'None'}"
                )
                print(
                    f"  Reasoning: {task_classification.reasoning[:200] if task_classification and task_classification.reasoning else 'None'}"
                )
                print()

                # ç²å– API keysï¼ˆæ‰€æœ‰å…è¨±çš„ providersï¼‰
                llm_api_keys = config_resolver.resolve_api_keys_map(
                    tenant_id=tenant_id,
                    user_id=current_user.user_id,
                    providers=allowed_providers,
                )
            else:
                # manual/favoriteï¼šprovider/model override
                selected_model_id = model_selector.model_id or ""
                provider = _infer_provider_from_model_id(selected_model_id)
                model = selected_model_id

                # G6ï¼šmanual/favorite allowlist gate
                if not policy_gate.is_model_allowed(provider.value, selected_model_id):
                    yield f"data: {json.dumps({'type': 'error', 'data': {'error': f'Model {selected_model_id} is not allowed by policy'}})}\n\n"
                    return

                # ç²å– API keysï¼ˆæŒ‡å®šçš„ providerï¼‰
                llm_api_keys = config_resolver.resolve_api_keys_map(
                    tenant_id=tenant_id,
                    user_id=current_user.user_id,
                    providers=[provider.value],
                )

            # æ§‹å»º MoE context
            moe_context: Dict[str, Any] = {
                "user_id": current_user.user_id,
                "tenant_id": tenant_id,
                "session_id": session_id,
                "task_id": task_id,
                "llm_api_keys": llm_api_keys,
            }

            if model_selector.mode == "auto":
                moe_context["allowed_providers"] = allowed_providers
                moe_context["favorite_models"] = favorite_model_ids

            # æ·»åŠ å·¥å…·ä¿¡æ¯åˆ° context
            # allowed_tools å·²åœ¨å‡½æ•°å¼€å§‹å¤„å®šä¹‰ï¼ˆç¬¬1069è¡Œï¼‰
            if allowed_tools:
                moe_context["allowed_tools"] = allowed_tools
                logger.debug(
                    "tools_enabled",
                    request_id=request_id,
                    allowed_tools=allowed_tools,
                )

            # ç™¼é€é–‹å§‹æ¶ˆæ¯ï¼ˆæ­¤æ™‚é‚„ä¸çŸ¥é“ provider å’Œ modelï¼Œå…ˆç™¼é€åŸºæœ¬ä¿¡æ¯ï¼‰
            logger.info(
                "stream_start",
                request_id=request_id,
                messages_count=len(messages_for_llm),
                has_web_search_results=any(
                    "ç¶²çµ¡æœç´¢çµæœ" in str(m.get("content", "")) for m in messages_for_llm
                ),
            )
            yield f"data: {json.dumps({'type': 'start', 'data': {'request_id': request_id, 'session_id': session_id}})}\n\n"

            # ç´¯ç©å®Œæ•´å…§å®¹ï¼ˆç”¨æ–¼å¾ŒçºŒè¨˜éŒ„ï¼‰
            full_content = ""
            chunk_count = 0

            # èª¿ç”¨ MoE Manager çš„ chat_stream æ–¹æ³•
            try:
                logger.info(
                    "moe_chat_stream_start",
                    request_id=request_id,
                    provider=provider.value if provider else None,
                    model=model,
                    task_classification=task_classification.type if task_classification else None,
                )
                async for chunk in moe.chat_stream(
                    messages_for_llm,
                    task_classification=task_classification,
                    provider=provider,
                    model=model,
                    temperature=0.7,
                    max_tokens=2000,
                    context=moe_context,
                ):
                    chunk_count += 1
                    full_content += chunk
                    # ç™¼é€å…§å®¹å¡Š
                    yield f"data: {json.dumps({'type': 'content', 'data': {'chunk': chunk}})}\n\n"

                logger.info(
                    "moe_chat_stream_completed",
                    request_id=request_id,
                    chunk_count=chunk_count,
                    content_length=len(full_content),
                )
            except Exception as stream_exc:
                logger.error(
                    "moe_chat_stream_error",
                    request_id=request_id,
                    error=str(stream_exc),
                    chunk_count=chunk_count,
                    content_length=len(full_content),
                    exc_info=True,
                )
                yield f"data: {json.dumps({'type': 'error', 'data': {'error': str(stream_exc)}})}\n\n"
                return

            # ç™¼é€çµæŸæ¶ˆæ¯
            yield f"data: {json.dumps({'type': 'done', 'data': {'request_id': request_id}})}\n\n"

            # è¨˜éŒ„ assistant messageï¼ˆç•°æ­¥åŸ·è¡Œï¼Œä¸é˜»å¡æµå¼éŸ¿æ‡‰ï¼‰
            _record_if_changed(
                context_manager=context_manager,
                session_id=session_id,
                role="assistant",
                content=full_content,
                metadata={
                    "user_id": current_user.user_id,
                    "session_id": session_id,
                    "task_id": task_id,
                    "request_id": request_id,
                },
            )

            # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - å¦‚æœ Task Analyzer é¸æ“‡äº† document_editing å·¥å…·ï¼Œå˜—è©¦å‰µå»ºæ–‡ä»¶
            # æ³¨æ„ï¼šé€™è£¡ä¸ä¾è³´é—œéµè©åŒ¹é…ï¼Œè€Œæ˜¯ä¾è³´ Task Analyzer çš„èªç¾©åˆ†æçµæœ
            try:
                # æ·»åŠ è©³ç´°æ—¥èªŒè¿½è¹¤
                logger.info(
                    "checking_file_creation_intent",
                    request_id=request_id,
                    has_task_analyzer_result=task_analyzer_result is not None,
                    task_id=task_id,
                    user_text=last_user_text[:200],
                    content_length=len(full_content),
                )

                if task_analyzer_result:
                    decision_result = task_analyzer_result.decision_result
                    logger.info(
                        "task_analyzer_decision_result_check",
                        request_id=request_id,
                        has_decision_result=decision_result is not None,
                        chosen_tools=decision_result.chosen_tools if decision_result else None,
                        needs_tools=decision_result.needs_tools if decision_result else None,
                        intent_type=decision_result.intent_type if decision_result else None,
                    )

                    if (
                        decision_result
                        and decision_result.chosen_tools
                        and (
                            "document_editing" in decision_result.chosen_tools
                            or "file_editing" in decision_result.chosen_tools
                        )
                    ):
                        # Task Analyzer é€šéèªç¾©åˆ†æè­˜åˆ¥å‡ºéœ€è¦ document_editing å·¥å…·
                        logger.info(
                            "document_editing_tool_detected_for_file_creation",
                            request_id=request_id,
                            chosen_tools=decision_result.chosen_tools,
                            task_id=task_id,
                            note="Attempting to create file",
                        )

                        # å˜—è©¦å‰µå»ºæ–‡ä»¶ï¼ˆä¸ä¾è³´é—œéµè©åŒ¹é…ï¼‰
                        create_action = _try_create_file_from_chat_output(
                            user_text=last_user_text,
                            assistant_text=full_content,
                            task_id=task_id,
                            current_user=current_user,
                            force_create=True,  # å¼·åˆ¶å‰µå»ºï¼Œä¸ä¾è³´é—œéµè©åŒ¹é…
                        )
                        if create_action:
                            logger.info(
                                "file_created_from_stream",
                                request_id=request_id,
                                file_id=create_action.get("file_id"),
                                filename=create_action.get("filename"),
                                note="File created based on Task Analyzer semantic analysis",
                            )
                            # ç™¼é€æ–‡ä»¶å‰µå»ºäº‹ä»¶
                            yield f"data: {json.dumps({'type': 'file_created', 'data': create_action})}\n\n"
                        else:
                            logger.warning(
                                "file_creation_returned_none",
                                request_id=request_id,
                                task_id=task_id,
                                user_text=last_user_text[:200],
                                note="File creation function returned None, check logs for details",
                            )
                    else:
                        # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - æ·»åŠ è©³ç´°æ—¥èªŒè¿½è¹¤ç‚ºä»€éº¼æ²’æœ‰é¸æ“‡ document_editing å·¥å…·
                        router_decision = (
                            task_analyzer_result.router_decision
                            if task_analyzer_result
                            and hasattr(task_analyzer_result, "router_decision")
                            else None
                        )
                        logger.info(
                            "document_editing_tool_not_detected",
                            request_id=request_id,
                            has_decision_result=decision_result is not None,
                            chosen_tools=decision_result.chosen_tools if decision_result else None,
                            router_needs_tools=router_decision.needs_tools
                            if router_decision
                            else None,
                            router_intent_type=router_decision.intent_type
                            if router_decision
                            else None,
                            router_confidence=router_decision.confidence
                            if router_decision
                            else None,
                            user_text=last_user_text[:200],
                            note="âŒ Task Analyzer did not select document_editing tool - check Router LLM, Capability Matcher, and Decision Engine logs",
                        )

                        # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - Fallbackï¼šå¦‚æœ Task Analyzer æ²’æœ‰é¸æ“‡ document_editing å·¥å…·ï¼Œä½†ç”¨æˆ¶æ–‡æœ¬åŒ…å«æ–‡ä»¶å‰µå»ºé—œéµè©ï¼Œä¹Ÿå˜—è©¦å‰µå»ºæ–‡ä»¶
                        if _looks_like_create_file_intent(last_user_text):
                            logger.info(
                                "fallback_to_keyword_matching_for_file_creation",
                                request_id=request_id,
                                task_id=task_id,
                                user_text=last_user_text[:200],
                                note="Task Analyzer did not select document_editing tool, but user text contains file creation keywords - attempting file creation via keyword matching",
                            )

                            # å˜—è©¦å‰µå»ºæ–‡ä»¶ï¼ˆä½¿ç”¨é—œéµè©åŒ¹é…ï¼‰
                            create_action = _try_create_file_from_chat_output(
                                user_text=last_user_text,
                                assistant_text=full_content,
                                task_id=task_id,
                                current_user=current_user,
                                force_create=False,  # ä½¿ç”¨é—œéµè©åŒ¹é…
                            )
                            if create_action:
                                logger.info(
                                    "file_created_from_stream_via_keyword_fallback",
                                    request_id=request_id,
                                    file_id=create_action.get("file_id"),
                                    filename=create_action.get("filename"),
                                    note="File created via keyword matching fallback",
                                )
                                # ç™¼é€æ–‡ä»¶å‰µå»ºäº‹ä»¶
                                yield f"data: {json.dumps({'type': 'file_created', 'data': create_action})}\n\n"
                            else:
                                logger.warning(
                                    "file_creation_fallback_returned_none",
                                    request_id=request_id,
                                    task_id=task_id,
                                    user_text=last_user_text[:200],
                                    note="File creation via keyword matching returned None, check logs for details",
                                )
                else:
                    logger.info(
                        "no_task_analyzer_result",
                        request_id=request_id,
                        note="Task Analyzer result is None, cannot check for document creation intent",
                    )

                    # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - Fallbackï¼šå¦‚æœ Task Analyzer çµæœç‚º Noneï¼Œä½†ç”¨æˆ¶æ–‡æœ¬åŒ…å«æ–‡ä»¶å‰µå»ºé—œéµè©ï¼Œä¹Ÿå˜—è©¦å‰µå»ºæ–‡ä»¶
                    if _looks_like_create_file_intent(last_user_text):
                        logger.info(
                            "fallback_to_keyword_matching_no_task_analyzer",
                            request_id=request_id,
                            task_id=task_id,
                            user_text=last_user_text[:200],
                            note="Task Analyzer result is None, but user text contains file creation keywords - attempting file creation via keyword matching",
                        )

                        # å˜—è©¦å‰µå»ºæ–‡ä»¶ï¼ˆä½¿ç”¨é—œéµè©åŒ¹é…ï¼‰
                        create_action = _try_create_file_from_chat_output(
                            user_text=last_user_text,
                            assistant_text=full_content,
                            task_id=task_id,
                            current_user=current_user,
                            force_create=False,  # ä½¿ç”¨é—œéµè©åŒ¹é…
                        )
                        if create_action:
                            logger.info(
                                "file_created_from_stream_via_keyword_fallback_no_analyzer",
                                request_id=request_id,
                                file_id=create_action.get("file_id"),
                                filename=create_action.get("filename"),
                                note="File created via keyword matching fallback (no Task Analyzer result)",
                            )
                            # ç™¼é€æ–‡ä»¶å‰µå»ºäº‹ä»¶
                            yield f"data: {json.dumps({'type': 'file_created', 'data': create_action})}\n\n"
                        else:
                            logger.warning(
                                "file_creation_fallback_no_analyzer_returned_none",
                                request_id=request_id,
                                task_id=task_id,
                                user_text=last_user_text[:200],
                                note="File creation via keyword matching returned None (no Task Analyzer result), check logs for details",
                            )
            except Exception as file_create_exc:
                stream_elapsed_time = time.time() - stream_start_time
                std_logger.error(
                    f"[{request_id}] file_creation_failed_in_stream after {stream_elapsed_time:.2f}s - {file_create_exc}",
                    exc_info=True,
                )
                logger.error(
                    "file_creation_failed_in_stream",
                    request_id=request_id,
                    error=str(file_create_exc),
                    exc_info=True,
                )

        except Exception as exc:
            stream_elapsed_time = time.time() - stream_start_time
            std_logger.error(
                f"[{request_id}] chat_product_stream ERROR after {stream_elapsed_time:.2f}s - {exc}",
                exc_info=True,
            )
            logger.error(f"Streaming chat error: {exc}", exc_info=True)
            yield f"data: {json.dumps({'type': 'error', 'data': {'error': str(exc)}})}\n\n"

        # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - åœ¨æµå¼éŸ¿æ‡‰çµæŸæ™‚è¨˜éŒ„å®Œæˆæ—¥èªŒ
        stream_elapsed_time = time.time() - stream_start_time
        std_logger.info(
            f"[{request_id}] chat_product_stream COMPLETE - elapsed_time={stream_elapsed_time:.2f}s, "
            f"task_id={task_id}, user_id={current_user.user_id}"
        )

    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # ç¦ç”¨ Nginx ç·©è¡
        },
    )


@router.post("", status_code=status.HTTP_200_OK)
async def chat_product(
    request_body: ChatRequest,
    request: Request,
    tenant_id: str = Depends(get_current_tenant_id),
    current_user: User = Depends(get_current_user),
) -> JSONResponse:
    """
    ç”¢å“ç´š Chat å…¥å£ï¼šå‰ç«¯è¼¸å…¥æ¡†çµ±ä¸€å…¥å£ã€‚

    - Autoï¼šTaskClassifier â†’ task_classification â†’ MoE chat
    - Manual/Favoriteï¼šä»¥ model_id æ¨å° providerï¼Œä¸¦åš provider/model override
    """
    moe = get_moe_manager()
    classifier = get_task_classifier()
    context_manager = get_context_manager()
    memory_service = get_chat_memory_service()
    trace_store = get_genai_trace_store_service()
    metrics = get_genai_metrics_service()
    policy_gate = get_genai_policy_gate_service()
    file_permission_service = get_file_permission_service()

    session_id = request_body.session_id or str(uuid.uuid4())
    task_id = request_body.task_id
    request_id = getattr(request.state, "request_id", None) or str(uuid.uuid4())

    messages = [m.model_dump() for m in request_body.messages]
    model_selector = request_body.model_selector

    routing: Dict[str, Any] = {}
    observability = ObservabilityInfo(
        request_id=request_id,
        session_id=session_id,
        task_id=task_id,
        token_input=None,  # type: ignore[call-arg]  # token_input æœ‰é»˜èªå€¼
    )

    start_time = time.perf_counter()

    try:
        # æ–°å¢ï¼šæŠ½å‡ºå¯é‡ç”¨ pipelineï¼ˆä¾› /chat èˆ‡ /chat/requests å…±ç”¨ï¼‰
        response = await _process_chat_request(
            request_body=request_body,
            request_id=request_id,
            tenant_id=tenant_id,
            current_user=current_user,
        )
        return APIResponse.success(
            data=response.model_dump(mode="json"),
            message="Chat success",
        )

        # G5ï¼šå…¥å£äº‹ä»¶ï¼ˆlog + traceï¼‰
        logger.info(
            "genai_chat_request_received",
            request_id=request_id,
            session_id=session_id,
            task_id=task_id,
            user_id=current_user.user_id,
            model_selector_mode=model_selector.mode,
            model_id=model_selector.model_id,
        )
        trace_store.add_event(
            GenAITraceEvent(
                event="chat.request_received",
                request_id=request_id,
                session_id=session_id,
                task_id=task_id,
                user_id=current_user.user_id,
                status="ok",
            )
        )

        # å–æœ€å¾Œä¸€å‰‡ user messageï¼ˆè‹¥æ‰¾ä¸åˆ°å°±å–æœ€å¾Œä¸€å‰‡ï¼‰
        user_messages = [m for m in messages if m.get("role") == "user"]
        last_user_text = str(user_messages[-1].get("content", "")) if user_messages else ""
        if not last_user_text and messages:
            last_user_text = str(messages[-1].get("content", ""))

        # G3ï¼šå…ˆè¨˜éŒ„ user messageï¼ˆé¿å…é‡è¤‡å¯«å…¥ï¼‰
        _record_if_changed(
            context_manager=context_manager,
            session_id=session_id,
            role="user",
            content=last_user_text,
            metadata={
                "user_id": current_user.user_id,
                "session_id": session_id,
                "task_id": task_id,
                "request_id": request_id,
            },
        )

        # G3ï¼šç”¨ windowed history ä½œç‚º MoE çš„ messagesï¼ˆä¸¦ä¿ç•™å‰ç«¯æä¾›çš„ system messageï¼‰
        system_messages = [m for m in messages if m.get("role") == "system"]
        windowed_history = context_manager.get_context_with_window(session_id=session_id)
        observability.context_message_count = (
            len(windowed_history) if isinstance(windowed_history, list) else 0
        )
        # G6ï¼šé™„ä»¶ file_id æ¬Šé™æª¢æŸ¥ï¼ˆé¿å…é€é RAG è®€åˆ°ä¸å±¬æ–¼è‡ªå·±çš„æ–‡ä»¶ï¼‰
        if request_body.attachments:
            for att in request_body.attachments:
                file_permission_service.check_file_access(
                    user=current_user,
                    file_id=att.file_id,
                    required_permission=Permission.FILE_READ.value,
                )

        # G6ï¼šData consent gateï¼ˆAI_PROCESSINGï¼‰- æœªåŒæ„å‰‡ä¸æª¢ç´¢/ä¸æ³¨å…¥/ä¸å¯«å…¥
        has_ai_consent = False
        try:
            from services.api.models.data_consent import ConsentType

            consent_service = get_consent_service()
            has_ai_consent = consent_service.check_consent(
                current_user.user_id, ConsentType.AI_PROCESSING
            )
        except Exception as exc:  # noqa: BLE001
            logger.warning(
                "genai_consent_check_failed",
                error=str(exc),
                request_id=request_id,
                user_id=current_user.user_id,
            )
            has_ai_consent = False

        if has_ai_consent:
            memory_result = await memory_service.retrieve_for_prompt(
                user_id=current_user.user_id,
                session_id=session_id,
                task_id=task_id,
                request_id=request_id,
                query=last_user_text,
                attachments=request_body.attachments,
                user=current_user,  # ä¿®æ”¹æ™‚é–“ï¼š2026-01-02 - å‚³é user å°è±¡ç”¨æ–¼æ¬Šé™æª¢æŸ¥
            )
            observability.memory_hit_count = memory_result.memory_hit_count
            observability.memory_sources = memory_result.memory_sources
            observability.retrieval_latency_ms = memory_result.retrieval_latency_ms
        else:
            from services.api.services.chat_memory_service import MemoryRetrievalResult

            memory_result = MemoryRetrievalResult(
                injection_messages=[],
                memory_hit_count=0,
                memory_sources=[],
                retrieval_latency_ms=0.0,
            )
            observability.memory_hit_count = 0
            observability.memory_sources = []
            observability.retrieval_latency_ms = 0.0

        base_system = system_messages[:1] if system_messages else []
        messages_for_llm = base_system + memory_result.injection_messages + windowed_history

        trace_store.add_event(
            GenAITraceEvent(
                event="chat.memory_retrieved",
                request_id=request_id,
                session_id=session_id,
                task_id=task_id,
                user_id=current_user.user_id,
                memory_hit_count=observability.memory_hit_count,
                memory_sources=observability.memory_sources,
                retrieval_latency_ms=observability.retrieval_latency_ms,
                context_message_count=observability.context_message_count,
                status="ok",
            )
        )

        llm_call_start = time.perf_counter()
        if model_selector.mode == "auto":
            # G6ï¼šprovider allowlistï¼ˆAutoï¼‰- å°‡ allowlist å‚³çµ¦ MoE åš provider éæ¿¾
            allowed_providers = policy_gate.get_allowed_providers()

            # ç²å–ç”¨æˆ¶çš„æ”¶è—æ¨¡å‹åˆ—è¡¨ï¼ˆç”¨æ–¼ Auto æ¨¡å¼å„ªå…ˆé¸æ“‡ï¼‰
            favorite_model_ids: List[str] = []
            try:
                from services.api.services.user_preference_service import (
                    get_user_preference_service,
                )

                preference_service = get_user_preference_service()
                favorite_model_ids = preference_service.get_favorite_models(
                    user_id=current_user.user_id
                )
            except Exception as exc:  # noqa: BLE001
                logger.debug(
                    f"Failed to get favorite models for user {current_user.user_id}: {exc}"
                )
                # fallback åˆ°å…§å­˜ç·©å­˜
                favorite_model_ids = _favorite_models_by_user.get(current_user.user_id, [])

            task_classification = classifier.classify(
                last_user_text,
                context={
                    "user_id": current_user.user_id,
                    "session_id": session_id,
                    "task_id": task_id,
                },
            )

            result = await moe.chat(
                messages_for_llm,
                task_classification=task_classification,
                context={
                    "user_id": current_user.user_id,
                    "session_id": session_id,
                    "task_id": task_id,
                    "allowed_providers": allowed_providers,
                    "favorite_models": favorite_model_ids,  # å‚³éæ”¶è—æ¨¡å‹åˆ—è¡¨
                },
            )

        else:
            # manual/favoriteï¼šprovider/model override
            selected_model_id = model_selector.model_id or ""
            provider = _infer_provider_from_model_id(selected_model_id)
            # G6ï¼šmanual/favorite allowlist gate
            if not policy_gate.is_model_allowed(provider.value, selected_model_id):
                return APIResponse.error(
                    message="Model is not allowed by policy",
                    error_code="MODEL_NOT_ALLOWED",
                    details={
                        "provider": provider.value,
                        "model_id": selected_model_id,
                    },
                    status_code=status.HTTP_403_FORBIDDEN,
                )
            result = await moe.chat(
                messages_for_llm,
                provider=provider,
                model=selected_model_id,
                context={
                    "user_id": current_user.user_id,
                    "session_id": session_id,
                    "task_id": task_id,
                },
            )

        content = _extract_content(result)
        routing = (result.get("_routing", {}) if isinstance(result, dict) else {}) or {}

        llm_latency_ms = (time.perf_counter() - llm_call_start) * 1000.0
        total_latency_ms = (time.perf_counter() - start_time) * 1000.0

        trace_store.add_event(
            GenAITraceEvent(
                event="chat.llm_completed",
                request_id=request_id,
                session_id=session_id,
                task_id=task_id,
                user_id=current_user.user_id,
                provider=str(routing.get("provider") or "unknown"),
                model=routing.get("model"),
                strategy=str(routing.get("strategy") or "unknown"),
                failover_used=bool(routing.get("failover_used") or False),
                fallback_provider=routing.get("fallback_provider"),
                memory_hit_count=observability.memory_hit_count,
                memory_sources=observability.memory_sources,
                retrieval_latency_ms=observability.retrieval_latency_ms,
                context_message_count=observability.context_message_count,
                total_latency_ms=total_latency_ms,
                llm_latency_ms=llm_latency_ms,
                status="ok",
            )
        )

        # G3ï¼šè¨˜éŒ„ assistant messageï¼ˆé¿å…é‡è¤‡å¯«å…¥ï¼‰
        _record_if_changed(
            context_manager=context_manager,
            session_id=session_id,
            role="assistant",
            content=content,
            metadata={
                "user_id": current_user.user_id,
                "session_id": session_id,
                "task_id": task_id,
                "request_id": request_id,
                "routing": routing,
            },
        )

        # G6ï¼šåŒæ„æ‰å¯«å…¥ long-termï¼ˆMVPï¼šsnippetï¼›å¤±æ•—ä¸é˜»æ“‹å›è¦†ï¼‰
        if has_ai_consent:
            await memory_service.write_from_turn(
                user_id=current_user.user_id,
                session_id=session_id,
                task_id=task_id,
                request_id=request_id,
                user_text=last_user_text,
                assistant_text=content,
            )

        routing_info = RoutingInfo(
            provider=str(routing.get("provider") or "unknown"),
            model=routing.get("model"),
            strategy=str(routing.get("strategy") or "unknown"),
            latency_ms=routing.get("latency_ms"),
            failover_used=bool(routing.get("failover_used") or False),
            fallback_provider=routing.get("fallback_provider"),
        )

        response = ChatResponse(
            content=content,
            session_id=session_id,
            task_id=task_id,
            routing=routing_info,
            observability=observability,
        )

        final_event = GenAITraceEvent(
            event="chat.response_sent",
            request_id=request_id,
            session_id=session_id,
            task_id=task_id,
            user_id=current_user.user_id,
            provider=routing_info.provider,
            model=routing_info.model,
            strategy=routing_info.strategy,
            failover_used=routing_info.failover_used,
            fallback_provider=routing_info.fallback_provider,
            memory_hit_count=observability.memory_hit_count,
            memory_sources=observability.memory_sources,
            retrieval_latency_ms=observability.retrieval_latency_ms,
            context_message_count=observability.context_message_count,
            total_latency_ms=total_latency_ms,
            llm_latency_ms=llm_latency_ms,
            status="ok",
        )
        trace_store.add_event(final_event)
        metrics.record_final_event(final_event)

        logger.info(
            "genai_chat_response_sent",
            request_id=request_id,
            session_id=session_id,
            task_id=task_id,
            user_id=current_user.user_id,
            provider=routing_info.provider,
            model=routing_info.model,
            strategy=routing_info.strategy,
            failover_used=routing_info.failover_used,
            fallback_provider=routing_info.fallback_provider,
            memory_hit_count=observability.memory_hit_count,
            memory_sources=observability.memory_sources,
            retrieval_latency_ms=observability.retrieval_latency_ms,
            context_message_count=observability.context_message_count,
            total_latency_ms=total_latency_ms,
            llm_latency_ms=llm_latency_ms,
        )

        return APIResponse.success(
            data=response.model_dump(mode="json"),
            message="Chat success",
        )
    except HTTPException as exc:
        total_latency_ms = (time.perf_counter() - start_time) * 1000.0
        detail = exc.detail
        if isinstance(detail, dict):
            message = str(detail.get("message") or "Request failed")
            error_code = str(detail.get("error_code") or "CHAT_HTTP_ERROR")

            failed_event = GenAITraceEvent(
                event="chat.failed",
                request_id=request_id,
                session_id=session_id,
                task_id=task_id,
                user_id=current_user.user_id,
                status="error",
                error_code=error_code,
                error_message=message,
                total_latency_ms=total_latency_ms,
            )
            trace_store.add_event(failed_event)
            metrics.record_final_event(failed_event)

            return APIResponse.error(
                message=message,
                error_code=error_code,
                details=detail,
                status_code=exc.status_code,
            )

        logger.warning(
            "chat_product_http_error",
            error=str(detail),
            status_code=exc.status_code,
            user_id=current_user.user_id,
            session_id=session_id,
            task_id=task_id,
            request_id=request_id,
        )
        failed_event = GenAITraceEvent(
            event="chat.failed",
            request_id=request_id,
            session_id=session_id,
            task_id=task_id,
            user_id=current_user.user_id,
            status="error",
            error_code="CHAT_HTTP_ERROR",
            error_message=str(detail),
            total_latency_ms=total_latency_ms,
            memory_hit_count=observability.memory_hit_count,
            memory_sources=observability.memory_sources,
            retrieval_latency_ms=observability.retrieval_latency_ms,
            context_message_count=observability.context_message_count,
        )
        trace_store.add_event(failed_event)
        metrics.record_final_event(failed_event)
        return APIResponse.error(
            message=str(detail),
            error_code="CHAT_HTTP_ERROR",
            status_code=exc.status_code,
        )
    except Exception as exc:  # noqa: BLE001
        total_latency_ms = (time.perf_counter() - start_time) * 1000.0
        logger.error(
            "chat_product_failed",
            error=str(exc),
            user_id=current_user.user_id,
            session_id=session_id,
            task_id=task_id,
            request_id=request_id,
        )

        failed_event = GenAITraceEvent(
            event="chat.failed",
            request_id=request_id,
            session_id=session_id,
            task_id=task_id,
            user_id=current_user.user_id,
            status="error",
            error_code="CHAT_PRODUCT_FAILED",
            error_message=str(exc),
            total_latency_ms=total_latency_ms,
            memory_hit_count=observability.memory_hit_count,
            memory_sources=observability.memory_sources,
            retrieval_latency_ms=observability.retrieval_latency_ms,
            context_message_count=observability.context_message_count,
        )
        trace_store.add_event(failed_event)
        metrics.record_final_event(failed_event)

        return APIResponse.error(
            message=f"Chat failed: {exc}",
            error_code="CHAT_PRODUCT_FAILED",
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        )


async def _run_async_request(
    *, request_id: str, request_body: ChatRequest, tenant_id: str, current_user: User
) -> None:
    store = get_genai_chat_request_store_service()

    try:
        if store.is_aborted(request_id=request_id):
            store.update(request_id=request_id, status=GenAIRequestStatus.aborted)
            return

        store.update(request_id=request_id, status=GenAIRequestStatus.running)

        response = await _process_chat_request(
            request_body=request_body,
            request_id=request_id,
            tenant_id=tenant_id,
            current_user=current_user,
        )

        store.update(
            request_id=request_id,
            status=GenAIRequestStatus.succeeded,
            response=response.model_dump(mode="json"),
        )
    except asyncio.CancelledError:
        store.set_abort(request_id=request_id)
        store.update(request_id=request_id, status=GenAIRequestStatus.aborted)
        raise
    except HTTPException as exc:
        # abortï¼šä½¿ç”¨ 409 çµ±ä¸€è¦–ç‚º aborted
        if exc.status_code == status.HTTP_409_CONFLICT:
            store.set_abort(request_id=request_id)
            store.update(request_id=request_id, status=GenAIRequestStatus.aborted)
            return

        detail = exc.detail
        if isinstance(detail, dict):
            store.update(
                request_id=request_id,
                status=GenAIRequestStatus.failed,
                error_code=str(detail.get("error_code") or "CHAT_HTTP_ERROR"),
                error_message=str(detail.get("message") or "Request failed"),
            )
        else:
            store.update(
                request_id=request_id,
                status=GenAIRequestStatus.failed,
                error_code="CHAT_HTTP_ERROR",
                error_message=str(detail),
            )
    except Exception as exc:  # noqa: BLE001
        store.update(
            request_id=request_id,
            status=GenAIRequestStatus.failed,
            error_code="CHAT_REQUEST_FAILED",
            error_message=str(exc),
        )
    finally:
        _pop_request_task(request_id=request_id)


@router.post("/requests", status_code=status.HTTP_202_ACCEPTED)
async def create_chat_request(
    request_body: ChatRequest,
    background_tasks: BackgroundTasks,
    executor: str = "local",  # local/rq
    tenant_id: str = Depends(get_current_tenant_id),
    current_user: User = Depends(get_current_user),
) -> JSONResponse:
    """
    éåŒæ­¥ Chat è«‹æ±‚ï¼šç«‹å³å› request_idï¼Œå¾Œç«¯åœ¨èƒŒæ™¯è™•ç†ï¼›å‰ç«¯å¯è¼ªè©¢ç‹€æ…‹æˆ– abortã€‚
    """
    store = get_genai_chat_request_store_service()

    request_id = str(uuid.uuid4())
    session_id = request_body.session_id or str(uuid.uuid4())

    request_dict = request_body.model_dump(mode="json")
    request_dict["session_id"] = session_id

    record = GenAIChatRequestRecord(
        request_id=request_id,
        tenant_id=tenant_id,
        user_id=current_user.user_id,
        session_id=session_id,
        task_id=request_body.task_id,
        status=GenAIRequestStatus.queued,
        request=request_dict,
    )
    store.create(record)

    # executor=rqï¼šé©åˆé•·ä»»å‹™/Agentï¼ˆè‹¥ rq ä¸å¯ç”¨å‰‡è‡ªå‹• fallback to localï¼‰
    if executor == "rq":
        try:
            from database.rq.queue import GENAI_CHAT_QUEUE, get_task_queue
            from workers.genai_chat_job import run_genai_chat_request

            q = get_task_queue(queue_name=GENAI_CHAT_QUEUE)
            q.enqueue(
                run_genai_chat_request,
                request_id,
                request_dict,
                tenant_id,
                current_user.to_dict(),
            )
        except Exception as exc:  # noqa: BLE001
            logger.warning(
                "genai_chat_request_enqueue_failed_fallback_local",
                request_id=request_id,
                error=str(exc),
            )
            executor = "local"

    # executor=localï¼šåŒä¸€é€²ç¨‹å…§èƒŒæ™¯ä»»å‹™ï¼ˆMVPï¼‰
    if executor != "rq":
        background_tasks.add_task(
            _run_async_request,
            request_id=request_id,
            request_body=ChatRequest.model_validate(request_dict),
            tenant_id=tenant_id,
            current_user=current_user,
        )

    payload = GenAIChatRequestCreateResponse(
        request_id=request_id,
        session_id=session_id,
        status=GenAIRequestStatus.queued,
    )
    return APIResponse.success(
        data=payload.model_dump(mode="json"),
        message="Chat request created",
        status_code=status.HTTP_202_ACCEPTED,
    )


@router.get("/requests/{request_id}", status_code=status.HTTP_200_OK)
async def get_chat_request_state(
    request_id: str,
    tenant_id: str = Depends(get_current_tenant_id),
    current_user: User = Depends(get_current_user),
) -> JSONResponse:
    store = get_genai_chat_request_store_service()
    record = store.get(request_id=str(request_id))
    if (
        record is None
        or record.user_id != current_user.user_id
        or str(record.tenant_id) != str(tenant_id)
    ):
        return APIResponse.error(
            message="Request not found",
            error_code="REQUEST_NOT_FOUND",
            status_code=status.HTTP_404_NOT_FOUND,
        )

    payload = GenAIChatRequestStateResponse(
        request_id=record.request_id,
        status=record.status,
        created_at_ms=record.created_at_ms,
        updated_at_ms=record.updated_at_ms,
        tenant_id=record.tenant_id,
        session_id=record.session_id,
        task_id=record.task_id,
        response=record.response,
        error_code=record.error_code,
        error_message=record.error_message,
    )
    return APIResponse.success(
        data=payload.model_dump(mode="json"),
        message="Chat request state retrieved",
    )


@router.post("/requests/{request_id}/abort", status_code=status.HTTP_200_OK)
async def abort_chat_request(
    request_id: str,
    tenant_id: str = Depends(get_current_tenant_id),
    current_user: User = Depends(get_current_user),
) -> JSONResponse:
    store = get_genai_chat_request_store_service()
    record = store.get(request_id=str(request_id))
    if (
        record is None
        or record.user_id != current_user.user_id
        or str(record.tenant_id) != str(tenant_id)
    ):
        return APIResponse.error(
            message="Request not found",
            error_code="REQUEST_NOT_FOUND",
            status_code=status.HTTP_404_NOT_FOUND,
        )

    store.set_abort(request_id=record.request_id)

    task = _get_request_task(request_id=record.request_id)
    if task is not None and not task.done():
        task.cancel()

    store.update(request_id=record.request_id, status=GenAIRequestStatus.aborted)
    return APIResponse.success(
        data={"request_id": record.request_id, "status": "aborted"},
        message="Chat request aborted",
    )


@router.get("/observability/stats", status_code=status.HTTP_200_OK)
async def get_chat_observability_stats(
    current_user: User = Depends(get_current_user),
) -> JSONResponse:
    """G5ï¼šç”¢å“ç´š Chat æŒ‡æ¨™å½™ç¸½ï¼ˆJSONï¼‰ã€‚"""
    metrics = get_genai_metrics_service()
    return APIResponse.success(
        data={"stats": metrics.get_stats(), "user_id": current_user.user_id},
        message="Chat observability stats retrieved",
    )


@router.get("/observability/traces/{request_id}", status_code=status.HTTP_200_OK)
async def get_chat_observability_trace(
    request_id: str,
    current_user: User = Depends(get_current_user),
) -> JSONResponse:
    """G5ï¼šä¾ request_id å›æ”¾äº‹ä»¶åºåˆ—ï¼ˆMVPï¼šin-memoryï¼‰ã€‚"""
    trace_store = get_genai_trace_store_service()
    events = trace_store.get_trace(request_id=str(request_id))
    return APIResponse.success(
        data={
            "request_id": request_id,
            "events": events,
            "user_id": current_user.user_id,
        },
        message="Chat trace retrieved",
    )


@router.get("/observability/recent", status_code=status.HTTP_200_OK)
async def get_chat_observability_recent(
    limit: int = 50,
    session_id: Optional[str] = None,
    task_id: Optional[str] = None,
    event: Optional[str] = None,
    current_user: User = Depends(get_current_user),
) -> JSONResponse:
    """G5ï¼šåˆ—å‡ºæœ€è¿‘ N ç­†äº‹ä»¶ï¼ˆMVPï¼šin-memoryï¼‰ã€‚"""
    trace_store = get_genai_trace_store_service()
    items = trace_store.list_recent(
        limit=limit,
        user_id=current_user.user_id,
        session_id=session_id,
        task_id=task_id,
        event=event,
    )
    return APIResponse.success(
        data={"events": items, "user_id": current_user.user_id},
        message="Recent chat observability events retrieved",
    )


@router.get("/models", status_code=status.HTTP_200_OK)
async def list_available_models(
    refresh: bool = False,
    include_disallowed: bool = False,
    tenant_id: str = Depends(get_current_tenant_id),
    current_user: User = Depends(get_current_user),
) -> JSONResponse:
    """
    ç”¢å“ç´šæ¨¡å‹æ¸…å–®ï¼ˆJSONï¼‰ã€‚

    - config: genai.model_registry.models
    - ollama: (å¯é¸) /api/tags å‹•æ…‹ç™¼ç¾ï¼ˆgenai.model_registry.enable_ollama_discoveryï¼‰
    - é è¨­æœƒå¥—ç”¨ genai.policy allowlist éæ¿¾
    """
    registry = get_genai_model_registry_service()
    config_resolver = get_genai_config_resolver_service()
    policy_gate = config_resolver.get_effective_policy_gate(
        tenant_id=tenant_id,
        user_id=current_user.user_id,
    )

    items = await registry.list_models(refresh=refresh)
    if not include_disallowed:
        items = [
            m
            for m in items
            if policy_gate.is_model_allowed(
                str(m.get("provider") or ""),
                str(m.get("model_id") or ""),
            )
        ]

    return APIResponse.success(
        data={"models": items, "user_id": current_user.user_id},
        message="Model list retrieved",
    )


@router.get("/sessions/{session_id}/messages", status_code=status.HTTP_200_OK)
async def get_session_messages(
    session_id: str,
    limit: Optional[int] = None,
    current_user: User = Depends(get_current_user),
) -> JSONResponse:
    """G3ï¼šSession å›æ”¾ï¼ˆæœ€å°å¯ç”¨ï¼‰ã€‚"""
    context_manager = get_context_manager()
    safe_limit = int(limit) if isinstance(limit, int) and limit and limit > 0 else None
    try:
        messages = context_manager.get_messages(session_id=session_id, limit=safe_limit)
        payload = [m.model_dump(mode="json") for m in messages]
    except Exception as exc:  # noqa: BLE001
        logger.warning(
            "get_session_messages_failed",
            error=str(exc),
            user_id=current_user.user_id,
            session_id=session_id,
        )
        payload = []
    return APIResponse.success(
        data={"session_id": session_id, "messages": payload},
        message="Session messages retrieved",
    )


class FavoriteModelsUpdateRequest(BaseModel):
    """æ”¶è—æ¨¡å‹æ›´æ–°è«‹æ±‚ï¼ˆMVPï¼‰ã€‚"""

    model_ids: List[str] = Field(default_factory=list, description="æ”¶è— model_id åˆ—è¡¨")


@router.get("/preferences/models", status_code=status.HTTP_200_OK)
async def get_favorite_models(
    current_user: User = Depends(get_current_user),
) -> JSONResponse:
    user_id = current_user.user_id
    try:
        from services.api.services.user_preference_service import get_user_preference_service

        service = get_user_preference_service()
        model_ids = service.get_favorite_models(user_id=user_id)
    except Exception as exc:  # noqa: BLE001
        logger.warning("favorite_models_service_failed", user_id=user_id, error=str(exc))
        model_ids = _favorite_models_by_user.get(user_id, [])
    return APIResponse.success(
        data={"model_ids": model_ids},
        message="Favorite models retrieved",
    )


@router.put("/preferences/models", status_code=status.HTTP_200_OK)
async def set_favorite_models(
    request_body: FavoriteModelsUpdateRequest,
    tenant_id: str = Depends(get_current_tenant_id),
    current_user: User = Depends(get_current_user),
) -> JSONResponse:
    import logging

    std_logger = logging.getLogger("api.routers.chat")

    user_id = current_user.user_id
    normalized: list[str] = []  # ä¿®æ”¹æ™‚é–“ï¼š2026-01-06 - ç¢ºä¿ normalized è®Šé‡å§‹çµ‚è¢«å®šç¾©

    std_logger.info(
        f"set_favorite_models START - user_id={user_id}, model_ids_count={len(request_body.model_ids)}"
    )

    try:
        # G6ï¼šæ”¶è—æ¨¡å‹å¯«å…¥å‰å…ˆåš allowlist éæ¿¾ï¼ˆå»é™¤ä¸å…è¨±è€…ï¼‰
        config_resolver = get_genai_config_resolver_service()
        policy_gate = config_resolver.get_effective_policy_gate(
            tenant_id=tenant_id,
            user_id=user_id,
        )
        filtered = policy_gate.filter_favorite_models(request_body.model_ids)

        from services.api.services.user_preference_service import get_user_preference_service

        service = get_user_preference_service()
        normalized = service.set_favorite_models(user_id=user_id, model_ids=filtered)

        std_logger.info(
            f"set_favorite_models SUCCESS - user_id={user_id}, normalized_count={len(normalized)}"
        )
    except Exception as exc:  # noqa: BLE001
        std_logger.error(
            f"set_favorite_models ERROR - user_id={user_id}, error={exc}",
            exc_info=True,
        )
        logger.warning("favorite_models_service_failed", user_id=user_id, error=str(exc))
        # å»é‡ä¸”ä¿åºï¼ˆfallbackï¼‰
        seen: set[str] = set()
        normalized = []
        for mid in request_body.model_ids:
            mid = str(mid).strip()
            if not mid or mid in seen:
                continue
            seen.add(mid)
            normalized.append(mid)
        _favorite_models_by_user[user_id] = normalized

        std_logger.info(
            f"set_favorite_models FALLBACK - user_id={user_id}, normalized_count={len(normalized)}"
        )

    return APIResponse.success(
        data={"model_ids": normalized},
        message="Favorite models updated",
    )
