# 方案2实施报告 - NER 模型参数优化

**创建日期**: 2026-01-03
**创建人**: Daniel Chung
**最后修改日期**: 2026-01-03

---

## 📋 实施概述

根据问题分析文档中的方案2，已成功实施 NER 模型参数优化，旨在提高实体识别准确率，解决亮能環科.pdf 文件圖譜提取数据为 0 的问题。

---

## ✅ 实施的改进

### 1. 改进 Prompt Template

**位置**: `genai/api/services/ner_service.py` - `OllamaNERModel.__init__`

**改进内容**:

#### 1.1 明确要求识别更多实体

- ✅ 添加了 **"必須識別盡可能多的實體"** 的明确要求
- ✅ 强调不要遗漏任何重要的实体
- ✅ 明确列出需要识别的实体类型：人名、组织名、地点、日期、金额、产品、设备、技术等

#### 1.2 处理中文文本的特殊说明

- ✅ 特别强调识别中文实体，包括公司名称、产品名称、技术术语等
- ✅ 添加了处理乱码字符的说明（忽略特殊字符，专注识别有效实体）

#### 1.3 添加 Few-Shot 示例

添加了 3 个针对中文商业文本的 Few-Shot 示例：

**示例 1: 中文商业文本**
```
文本：亮能環境科技股份有限公司為台灣一家上櫃企業，客戶群體主要為台灣各類型的工業工廠，特別是製造業。
输出：识别了 3 个实体（ORG, LOC, INDUSTRY）
```

**示例 2: 技术和设备描述**
```
文本：移動式城市廢棄物處理設備，設計類似亮能的設備，採用低溫無氧熱解技術。
输出：识别了 3 个实体（EQUIPMENT, ORG, TECHNOLOGY）
```

**示例 3: 财务和项目信息**
```
文本：總投資約新台幣 4,000萬元，預計年創造價值可達 2600萬元，投資回收期約 2~3年。
输出：识别了 3 个实体（MONEY, MONEY, DURATION）
```

### 2. 调整模型参数

**位置**: `genai/api/services/ner_service.py` - `OllamaNERModel.extract_entities`

**参数调整**:

| 参数 | 原值 | 新值 | 说明 |
|------|------|------|------|
| `temperature` | 未设置（默认） | `0.0` | 降低随机性，提高稳定性 |
| `max_tokens` | 未设置（默认） | `2048` | 增加最大 token 数，确保完整输出 |
| `top_p` | 未设置 | `0.9` | 核采样参数，提高输出质量 |
| `top_k` | 未设置 | `40` | Top-K 采样参数 |
| `num_ctx` | `32768` | `32768` | 保持不变（32k context window） |

---

## 📊 预期效果

### 改进前的问题

1. ❌ 多个 chunk 实体数量不足（0-1 个实体）
2. ❌ NER 模型返回格式错误（`ollama_ner_no_valid_json`）
3. ❌ 无法构建三元组（实体不足）

### 改进后的预期

1. ✅ **提高实体识别准确率**：Few-shot 示例帮助模型更好地理解中文商业文本
2. ✅ **识别更多实体**：明确的 prompt 要求模型识别尽可能多的实体
3. ✅ **提高输出稳定性**：`temperature=0.0` 降低随机性，确保一致性
4. ✅ **确保完整输出**：`max_tokens=2048` 确保不会截断输出
5. ✅ **处理乱码字符**：prompt 中明确说明忽略乱码，专注有效实体

---

## 🔧 代码修改详情

### 修改文件

- **文件**: `genai/api/services/ner_service.py`
- **类**: `OllamaNERModel`
- **修改位置**:
  1. `__init__` 方法：更新 `_prompt_template`
  2. `extract_entities` 方法：添加模型参数

### 关键代码片段

```python
# 改进后的 prompt template
self._prompt_template = """你是一個專業的命名實體識別（NER）助手。請仔細閱讀以下文本，識別並提取所有命名實體。

重要規則：
1. **必須識別盡可能多的實體**：不要遺漏任何重要的實體...
2. **僅返回一個 JSON 數組**...
3. **嚴格遵守 JSON 格式**...
4. **處理中文文本**：特別注意識別中文實體...
5. **處理亂碼字符**：如果文本中包含特殊字符或亂碼，請忽略這些字符...

Few-Shot 示例：
[3 个详细的中文商业文本示例]

待分析的文本內容：
{text}
"""

# 改进后的模型参数
response = await self.client.generate(
    prompt,
    model=self.model_name,
    format="json",
    temperature=0.0,  # 降低隨機性
    max_tokens=2048,   # 確保完整輸出
    options={
        "num_ctx": 32768,
        "top_p": 0.9,
        "top_k": 40,
    },
)
```

---

## 🧪 测试建议

### 测试步骤

1. **重新触发圖譜提取**
   ```bash
   # 使用 API 重新生成圖譜
   POST /api/v1/files/{file_id}/regenerate
   Body: {"type": "graph"}
   ```

2. **监控处理进度**
   - 检查 RQ worker 日志
   - 观察实体识别数量是否增加
   - 验证是否成功构建三元组

3. **验证结果**
   - 检查 `entities_count` 是否 > 0
   - 检查 `relations_count` 是否 > 0
   - 检查 `triples_count` 是否 > 0

### 预期测试结果

- ✅ 每个 chunk 至少识别 2+ 个实体
- ✅ 成功构建三元组
- ✅ 圖譜数据 > 0

---

## 📝 后续优化建议

如果方案2实施后仍有问题，可以考虑：

1. **方案1**: 清理 PDF 文本编码问题（移除乱码字符）
2. **方案3**: 降低实体数量要求（允许在实体较少时构建三元组）
3. **方案4**: 改进文本预处理（在分块前清理文本）

---

## ✅ 实施状态

- [x] 改进 prompt template
- [x] 添加 Few-shot 示例
- [x] 调整模型参数（temperature, max_tokens, top_p, top_k）
- [x] 代码检查通过（无 linter 错误）
- [ ] 测试验证（待重新触发圖譜提取）

---

**实施完成时间**: 2026-01-03 23:45

