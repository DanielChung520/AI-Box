# 圖譜標簽化與服務連接問題分析報告

**創建日期**: 2025-12-10  
**創建人**: Daniel Chung  
**最後修改日期**: 2025-12-10

## 執行摘要

本報告分析了圖譜標簽化（NER/RE/RT）功能的模型配置、Ollama連接問題、超時原因，以及Redis服務的部署狀態。

---

## 一、圖譜標簽化模型配置

### 1.1 當前配置

根據 `config/config.json` 和代碼檢查：

**NER（命名實體識別）配置**:
- **模型類型**: `ollama`
- **主模型名稱**: `mistral-nemo:12b`（配置文件中已更新）
- **實際使用**: `qwen3-coder:30b`（代碼中硬編碼的默認值）
- **備用模型**: `ollama:llama3.1:8b`
- **模型類型備選**: `spacy`（但spaCy未安裝）

**Ollama服務配置**:
- **Host**: `localhost`（但.env中配置為 `olm.k84.org`）
- **Port**: `11434`
- **超時時間**: `60秒`（配置文件中為120秒，但實際使用60秒）

### 1.2 模型連接方式

圖譜標簽化使用以下連接流程：

```
NERService → OllamaNERModel → OllamaClient → HTTP請求 → Ollama服務
```

**連接代碼路徑**:
1. `genai/api/services/ner_service.py` - NER服務主類
2. `genai/api/services/ner_service.py::OllamaNERModel` - Ollama模型實現
3. `llm/clients/ollama.py::OllamaClient` - Ollama客戶端
4. 使用 `httpx.AsyncClient` 發送HTTP請求到 `http://localhost:11434/api/generate`

### 1.3 實際使用的模型

根據代碼邏輯和實際測試：
- **主模型**: `qwen3-coder:30b`（30.5B參數，大模型）
- **備用模型**: `gemini:gemini-pro`（但Gemini SDK未安裝，不可用）

**問題**: 
1. 配置文件中已更新為 `mistral-nemo:12b`，但代碼中 `NERService.__init__()` 有硬編碼的默認值 `qwen3-coder:30b`
2. 配置讀取失敗時，會使用硬編碼的默認值

---

## 二、Ollama連接問題分析

### 2.1 連接狀態檢查

**測試結果**:
- ✅ Ollama服務在 `localhost:11434` 可訪問
- ✅ 可以獲取模型列表（5個模型可用）
- ✅ 本地Ollama服務正在運行（進程ID: 95459）
- ⚠️ 但模型生成請求超時

**可用模型列表**:
1. `qwen3-vl:8b` (8.8B參數)
2. `mistral-nemo:12b` (12.2B參數)
3. `llama3.1:8b` (8.0B參數)
4. `gpt-oss:20b` (20.9B參數)
5. `qwen3-coder:30b` (30.5B參數)

### 2.2 超時原因分析

根據日誌分析，超時問題的原因：

1. **模型大小問題**:
   - `qwen3-coder:30b` 是30.5B參數的大模型
   - 模型加載和推理需要大量內存（建議32GB+）
   - 首次加載模型可能需要數分鐘

2. **超時設置過短**:
   - 當前超時時間: `60秒`（從 `services.ollama.request_timeout` 讀取，但實際使用60秒）
   - 配置文件中設置為120秒，但代碼讀取時可能使用了默認值
   - 大模型生成可能需要更長時間（特別是首次加載）

3. **模型未預加載**:
   - Ollama模型需要首次加載到內存
   - 30B模型加載可能需要數分鐘
   - 如果模型未預加載，首次請求會觸發加載過程

4. **資源競爭**:
   - 如果同時有多個請求，可能導致資源競爭
   - 內存不足時，模型加載會更慢

### 2.3 本地Ollama連接問題

**實際情況**:
- ✅ Ollama服務正在運行（本地進程）
- ✅ 服務可以訪問（可以獲取模型列表）
- ⚠️ 但生成請求超時

**可能原因**:

1. **配置不一致**:
   - `.env` 中配置了 `OLLAMA_REMOTE_HOST=olm.k84.org`
   - 但代碼可能使用 `localhost`
   - 導致連接到錯誤的服務器

2. **模型未預加載**:
   - 30B模型需要大量內存
   - 首次加載可能需要數分鐘
   - 超時時間不足以完成加載

3. **資源不足**:
   - 內存不足導致模型加載緩慢
   - CPU性能不足導致推理緩慢

### 2.4 解決方案建議

1. **使用更小的模型**:
   - 推薦: `llama3.1:8b`（8B參數，更快）
   - 或: `qwen3-vl:8b`（8B參數）
   - 修改 `genai/api/services/ner_service.py` 中的默認值

2. **增加超時時間**:
   - 建議: `180-300秒`
   - 修改 `config/config.json` 中的 `services.ollama.request_timeout`
   - 確保代碼正確讀取配置

3. **預加載模型**:
   - 在Ollama服務啟動時預加載常用模型
   - 使用 `ollama pull <model>` 預先下載模型
   - 使用 `ollama run <model> "test"` 觸發模型加載

4. **檢查配置一致性**:
   - 確保 `.env` 和 `config.json` 中的Ollama配置一致
   - 確保代碼使用正確的主機地址

---

## 三、Redis服務狀態分析

### 3.1 當前狀態

**檢查結果**:
- ✅ **Redis服務已在docker-compose.yml中配置**
- ❌ **Redis服務未運行**（Docker容器未啟動）
- ⚠️ **代碼中有Redis使用，但服務不可用**

**Docker Compose配置**:
```yaml
redis:
  image: redis:7-alpine
  container_name: redis
  ports:
    - "6379:6379"
  volumes:
    - redis_data:/data
  command: redis-server --appendonly yes
```

### 3.2 Redis使用情況

**代碼中的Redis使用**:

1. **處理狀態更新**:
   - `api/routers/file_upload.py` - 更新文件處理狀態
   - 鍵格式: `processing:status:{file_id}`

2. **JWT黑名單**:
   - `system/security/jwt_service.py` - 存儲已註銷的JWT token
   - 鍵格式: `jwt:blacklist:{token_hash}`

3. **圖譜統計信息**:
   - `api/routers/file_management.py` - 存儲圖譜提取統計（已修復為不依賴Redis）

### 3.3 Redis配置

**環境變量**（`.env`）:
```
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=
REDIS_URL=redis://redis:6379/0
```

**問題**:
- 環境變量配置為 `REDIS_HOST=redis`（Docker服務名）
- 但代碼嘗試連接到 `localhost:6379`
- 如果API服務不在Docker中運行，無法連接到Redis容器

### 3.4 是否需要部署Redis？

**建議**: **需要啟動Redis服務**

**原因**:
1. **處理狀態追蹤**: 文件處理（向量化、圖譜提取）的狀態更新需要Redis
2. **JWT黑名單**: 安全功能需要Redis存儲已註銷的token
3. **性能優化**: Redis可以提供快速的緩存和狀態查詢

**影響**:
- 當前Redis不可用時，系統仍可運行，但：
  - 無法更新處理狀態（前端無法顯示進度）
  - JWT黑名單功能失效（已註銷的token仍可使用）
  - 圖譜統計信息無法從Redis獲取（已修復為從ArangoDB獲取）

**啟動Redis**:
```bash
# 啟動Redis容器
docker-compose up -d redis

# 檢查Redis狀態
docker ps | grep redis
redis-cli ping  # 如果Redis在localhost運行
```

---

## 四、問題總結與建議

### 4.1 問題總結

| 問題 | 狀態 | 影響 | 優先級 |
|------|------|------|--------|
| Ollama模型超時 | ⚠️ 未解決 | 無法生成圖譜數據 | 高 |
| 模型配置不一致 | ⚠️ 需修復 | 使用錯誤的模型 | 高 |
| Redis服務未啟動 | ❌ 未部署 | 無法更新處理狀態、JWT黑名單失效 | 中 |
| 超時配置未生效 | ⚠️ 需修復 | 超時時間過短 | 中 |

### 4.2 建議行動計劃

#### 優先級1: 修復模型配置和超時問題

1. **修復NER服務默認值**:
   ```python
   # 修改 genai/api/services/ner_service.py
   # 第324行，將默認值改為從配置讀取
   self.model_name = self.config.get("model_name", "llama3.1:8b")  # 使用更小的模型
   ```

2. **確保超時配置生效**:
   ```json
   // config/config.json
   {
     "services": {
       "ollama": {
         "request_timeout": 300  // 增加到300秒
       }
     }
   }
   ```

3. **使用更小的模型**:
   ```json
   // config/config.json
   {
     "text_analysis": {
       "ner": {
         "model_name": "llama3.1:8b"  // 使用8B模型
       }
     }
   }
   ```

#### 優先級2: 啟動Redis服務

1. **啟動Redis容器**:
   ```bash
   docker-compose up -d redis
   ```

2. **檢查Redis連接**:
   ```bash
   # 如果API服務在Docker中運行
   docker exec -it redis redis-cli ping
   
   # 如果API服務在本地運行，需要修改.env
   REDIS_HOST=localhost
   REDIS_URL=redis://localhost:6379/0
   ```

3. **驗證Redis功能**:
   ```bash
   redis-cli ping  # 應該返回 PONG
   ```

#### 優先級3: 預加載模型

1. **預加載常用模型**:
   ```bash
   ollama pull llama3.1:8b
   ollama run llama3.1:8b "test"  # 觸發模型加載
   ```

2. **檢查模型狀態**:
   ```bash
   ollama list
   ```

---

## 五、技術細節

### 5.1 模型配置加載流程

```
config/config.json
  ↓
system.infra.config.config.get_config_section()
  ↓
genai.api.services.ner_service.NERService.__init__()
  ↓ (如果配置讀取失敗，使用硬編碼默認值)
genai.api.services.ner_service.OllamaNERModel
  ↓
llm.clients.ollama.OllamaClient
  ↓
HTTP請求到 localhost:11434 或 olm.k84.org:11434
```

### 5.2 超時機制

- **OllamaClient**: 使用 `httpx.AsyncClient` 的 `timeout` 參數
- **超時設置**: 從 `config.json` 的 `services.ollama.request_timeout` 讀取
- **默認值**: 60秒（如果未配置）
- **當前值**: 60秒（配置文件中為120秒，但實際使用60秒）

### 5.3 Redis使用場景

1. **文件處理狀態**:
   - 鍵: `processing:status:{file_id}`
   - 值: JSON格式的處理狀態
   - TTL: 無（手動刪除）

2. **JWT黑名單**:
   - 鍵: `jwt:blacklist:{token_hash}`
   - 值: 時間戳
   - TTL: JWT過期時間

### 5.4 配置不一致問題

**發現的問題**:
1. `.env` 中 `OLLAMA_REMOTE_HOST=olm.k84.org`，但代碼可能使用 `localhost`
2. `config.json` 中模型為 `mistral-nemo:12b`，但代碼默認值為 `qwen3-coder:30b`
3. `config.json` 中超時為120秒，但實際使用60秒
4. Redis配置為 `redis`（Docker服務名），但API服務可能不在Docker中運行

---

## 六、附錄

### 6.1 相關文件

- `config/config.json` - 配置文件
- `.env` - 環境變量配置
- `genai/api/services/ner_service.py` - NER服務
- `llm/clients/ollama.py` - Ollama客戶端
- `database/redis/client.py` - Redis客戶端
- `docker-compose.yml` - Docker服務配置

### 6.2 日誌文件

- `logs/api_kg_final.log` - API服務日誌
- `logs/fastapi.log` - FastAPI日誌

### 6.3 測試命令

```bash
# 測試Ollama連接
curl http://localhost:11434/api/tags

# 測試Redis連接
docker exec -it redis redis-cli ping
# 或
redis-cli -h localhost -p 6379 ping

# 檢查服務狀態
docker ps
ps aux | grep -E "ollama|redis|uvicorn"

# 檢查Ollama模型
ollama list
```

### 6.4 快速修復命令

```bash
# 1. 啟動Redis
docker-compose up -d redis

# 2. 預加載模型
ollama pull llama3.1:8b
ollama run llama3.1:8b "test"

# 3. 重啟API服務（使配置生效）
pkill -f "uvicorn api.main"
# 然後重新啟動服務
```

---

**報告結束**
