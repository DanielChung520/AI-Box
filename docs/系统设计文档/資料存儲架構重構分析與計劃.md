# 資料存儲架構重構分析與計劃

**創建日期**: 2025-12-29
**創建人**: Daniel Chung
**最後修改日期**: 2025-12-29
**關聯文檔**: [資料架構建議報告](./資料架构建议报告.md)

---

## 📊 重構實施進度管控表

**專案開始日期**: 2025-12-29
**預估完成日期**: 待定
**總工期**: 約 7-10 週（35-50 個工作日）

### 專案概覽

| 指標 | 數值 |
|------|------|
| **總階段數** | 5 個階段 |
| **總任務數** | 約 30+ 個主要任務 |
| **總里程碑** | 5 個里程碑 |
| **總預估工期** | 7-10 週 |
| **當前進度** | 🔄 進行中 (20%) |

### 階段總覽

| 階段 | 階段名稱 | 時間範圍 | 工作日 | 狀態 | 進度 | 負責人 |
|------|---------|---------|--------|------|------|--------|
| **階段一** | Phase 1: 基礎設施就緒 | 2025-12-29 ~ 待定 | 2-3 週 | ✅ 已完成 | 100% | DevOps 工程師、後端開發工程師 |
| **階段二** | Phase 2: 治理層接入 | 待定 | 2-3 週 | ⏸️ 待開始 | 0% | 後端開發工程師 |
| **階段三** | Phase 3: 存儲層遷移 | 待定 | 2-3 週 | ⏸️ 待開始 | 0% | 後端開發工程師 |
| **階段四** | Phase 4: 測試與驗證 | 待定 | 1 週 | ⏸️ 待開始 | 0% | 測試工程師、後端開發工程師 |
| **階段五** | Phase 5: 文檔更新 | 待定 | 1 週 | ⏸️ 待開始 | 0% | 技術文檔工程師 |

**狀態說明**:

- ✅ 已完成
- 🔄 進行中
- ⏸️ 待開始
- ⚠️ 延遲
- ❌ 阻塞

### 階段一：基礎設施就緒 (Phase 1)

**目標日期**: 2025-12-29 ~ 2026-01-12
**當前日期**: 2025-12-29
**狀態**: ✅ 已完成
**進度**: 100% (2/2 主要任務完成)
**總預估時間**: 2-3 週
**實際完成時間**: 1 天（提前完成）

#### 工作項詳情

| 工作項 ID | 工作項名稱 | 預估時間 | 狀態 | 完成度 | 開始日期 | 完成日期 | 負責人 |
|----------|----------|---------|------|--------|---------|---------|--------|
| **任務 1.1** | SeaweedFS 部署與配置（雙服務架構） | 1 週 | ✅ | 100% | 2025-12-29 | 2025-12-29 | DevOps 工程師 |
| 1.1.1 | AI-Box SeaweedFS 服務部署 | 2 天 | ✅ | 100% | 2025-12-29 | 2025-12-29 | DevOps 工程師 |
| 1.1.2 | DataLake SeaweedFS 服務部署 | 2 天 | ✅ | 100% | 2025-12-29 | 2025-12-29 | DevOps 工程師 |
| 1.1.3 | Buckets 創建與配置 | 1 天 | ✅ | 100% | 2025-12-29 | 2025-12-29 | DevOps 工程師 |
| **任務 1.2** | SeaweedFS 客戶端封裝 | 1 週 | ✅ | 100% | 2025-12-29 | 2025-12-29 | 後端開發工程師 |
| 1.2.1 | S3FileStorage 類實現 | 2 天 | ✅ | 100% | 2025-12-29 | 2025-12-29 | 後端開發工程師 |
| 1.2.2 | 雙服務支持實現 | 2 天 | ✅ | 100% | 2025-12-29 | 2025-12-29 | 後端開發工程師 |
| 1.2.3 | 單元測試 | 1 天 | ✅ | 100% | 2025-12-29 | 2025-12-29 | 後端開發工程師 |

**階段一最新進度說明**：

- ✅ **已完成**：所有階段一任務已完成
- ✅ **AI-Box SeaweedFS 服務**：Kubernetes 部署配置文件已創建（`k8s/seaweedfs-ai-box/`）
- ✅ **DataLake SeaweedFS 服務**：Kubernetes 部署配置文件已創建（`k8s/seaweedfs-datalake/`）
- ✅ **Buckets 創建腳本**：已創建 `scripts/migration/create_seaweedfs_buckets.py`
- ✅ **S3FileStorage 類**：已實現完整的 S3/SeaweedFS 存儲類（`storage/s3_storage.py`）
- ✅ **雙服務支持**：已實現 SeaweedFSService 枚舉和配置選擇邏輯
- ✅ **單元測試**：已創建完整的單元測試（`tests/storage/test_s3_storage.py`）
- ✅ **環境配置**：已更新 `env.example` 添加兩個服務的配置
- ✅ **文檔更新**：已創建存儲架構文檔（`docs/系统设计文档/核心组件/存储架构.md`）

**注意事項**：

- ⚠️ **DataLake 專案本身**：根據計劃說明，DataLake 專案本身的創建不在本計劃範圍內。本計劃僅包含 DataLake SeaweedFS 服務的部署配置，已完成。
- ⚠️ **實際部署**：Kubernetes 配置文件已創建，但需要在實際 Kubernetes 集群中部署才能使用。

---

### 階段二：治理層接入 (Phase 2)

**目標日期**: 待定
**當前日期**: 2025-12-30
**狀態**: ⏸️ 待開始
**進度**: 0% (0/4 主要任務完成)
**總預估時間**: 2-3 週

#### 工作項詳情

| 工作項 ID | 工作項名稱 | 預估時間 | 狀態 | 完成度 | 開始日期 | 完成日期 | 負責人 |
|----------|----------|---------|------|--------|---------|---------|--------|
| **任務 2.1** | 審計日誌服務遷移 | 3 天 | ⏸️ | 0% | - | - | 後端開發工程師 |
| **任務 2.2** | 系統日誌服務遷移 | 3 天 | ⏸️ | 0% | - | - | 後端開發工程師 |
| **任務 2.3** | 版本歷史服務實現 | 3 天 | ⏸️ | 0% | - | - | 後端開發工程師 |
| **任務 2.4** | 變更提案機制實現 | 3 天 | ⏸️ | 0% | - | - | 後端開發工程師 |

**階段二最新進度說明**：

- ⏸️ 尚未開始，等待階段一完成

---

### 階段三：存儲層遷移 (Phase 3)

**目標日期**: 待定
**當前日期**: 2025-12-30
**狀態**: ⏸️ 待開始
**進度**: 0% (0/3 主要任務完成)
**總預估時間**: 2-3 週

#### 工作項詳情

| 工作項 ID | 工作項名稱 | 預估時間 | 狀態 | 完成度 | 開始日期 | 完成日期 | 負責人 |
|----------|----------|---------|------|--------|---------|---------|--------|
| **任務 3.1** | 文件存儲服務改造 | 1 週 | ⏸️ | 0% | - | - | 後端開發工程師 |
| **任務 3.2** | 文件遷移腳本開發 | 1 週 | ⏸️ | 0% | - | - | 後端開發工程師 |
| **任務 3.3** | DataLake 數據遷移 | 3 天 | ⏸️ | 0% | - | - | 後端開發工程師 |

**階段三最新進度說明**：

- ⏸️ 尚未開始，等待階段二完成

---

### 階段四：測試與驗證 (Phase 4)

**目標日期**: 待定
**當前日期**: 2025-12-30
**狀態**: ⏸️ 待開始
**進度**: 0% (0/4 主要任務完成)
**總預估時間**: 1 週

#### 工作項詳情

| 工作項 ID | 工作項名稱 | 預估時間 | 狀態 | 完成度 | 開始日期 | 完成日期 | 負責人 |
|----------|----------|---------|------|--------|---------|---------|--------|
| **任務 4.1** | 單元測試 | 1 天 | ⏸️ | 0% | - | - | 測試工程師 |
| **任務 4.2** | 集成測試 | 2 天 | ⏸️ | 0% | - | - | 測試工程師 |
| **任務 4.3** | 性能測試 | 1 天 | ⏸️ | 0% | - | - | 測試工程師 |
| **任務 4.4** | 數據遷移驗證 | 1 天 | ⏸️ | 0% | - | - | 測試工程師 |

**階段四最新進度說明**：

- ⏸️ 尚未開始，等待階段三完成

---

### 階段五：文檔更新 (Phase 5)

**目標日期**: 待定
**當前日期**: 2025-12-30
**狀態**: ⏸️ 待開始
**進度**: 0% (0/3 主要任務完成)
**總預估時間**: 1 週

#### 工作項詳情

| 工作項 ID | 工作項名稱 | 預估時間 | 狀態 | 完成度 | 開始日期 | 完成日期 | 負責人 |
|----------|----------|---------|------|--------|---------|---------|--------|
| **任務 5.1** | 架構文檔更新 | 2 天 | ⏸️ | 0% | - | - | 技術文檔工程師 |
| **任務 5.2** | API 文檔更新 | 2 天 | ⏸️ | 0% | - | - | 技術文檔工程師 |
| **任務 5.3** | 開發指南更新 | 1 天 | ⏸️ | 0% | - | - | 技術文檔工程師 |

**階段五最新進度說明**：

- ⏸️ 尚未開始，等待階段四完成

---

## 📌 計劃實施要點

### 1. 開發規範遵循

**重要**：所有代碼開發必須嚴格遵循以下規範：

#### 1.1 規範文件參考

- ✅ **必須嚴格依據** `@AI-Box/.cursor/rules/develop-rule.mdc` 規範進行開發
- ✅ 所有代碼修改前，請先閱讀並理解規範要求
- ✅ 如有疑問，請及時諮詢架構師或技術負責人

#### 1.2 代碼質量檢查

**每次提交代碼前，必須執行以下檢查**：

1. **Ruff 檢查**：

   ```bash
   ruff check --fix <文件路徑>
   ```

   - 必須修復所有可自動修復的問題
   - 高優先級錯誤（F821, E722）必須立即修復

2. **Mypy 類型檢查**：

   ```bash
   mypy <文件路徑>
   ```

   - 所有函數參數必須有類型注解
   - 所有返回值必須有類型注解
   - 使用 `Optional[T]` 而不是 `T = None`
   - 必須通過 mypy 檢查才能提交

3. **Black 格式化**：

   ```bash
   black <文件路徑>
   ```

   - 確保代碼符合 Black 格式規範
   - 行長度最大 100 字符

4. **Pre-commit Hooks**：
   - 所有 pre-commit hooks 必須通過
   - 如果檢查失敗，必須修復後重新提交

#### 1.3 代碼審查檢查清單

**提交前必須檢查**：

- [ ] 所有類型注解完整且正確
- [ ] 所有可能為 None 的值都有檢查
- [ ] Import 語句在文件頂部
- [ ] 沒有未使用的變量
- [ ] 通過 pre-commit hooks（black, ruff, mypy）
- [ ] API 調用參數正確
- [ ] 數據庫連接使用前有 None 檢查
- [ ] 模型對象使用前有可用性檢查

### 2. 架構文檔對照檢查

**重要**：每次完成階段任務後，必須對照檢查架構文檔要求。

#### 2.1 文檔參考

- ✅ **必須仔細研讀** `@AI-Box/docs/系统设计文档/資料架构建议报告.md`
- ✅ 理解架構設計的目標和原則
- ✅ 確保實施方案符合架構設計要求

#### 2.2 階段完成檢查

**每個階段完成後，必須檢查以下項目**：

1. **功能完整性檢查**：
   - [ ] 是否實現了架構文檔中要求的所有功能？
   - [ ] 是否滿足架構設計的目標？
   - [ ] 是否遵循了架構設計的原則？

2. **數據存儲檢查**：
   - [ ] 數據存儲位置是否正確（ArangoDB vs SeaweedFS）？
   - [ ] 存儲格式是否符合要求（JSON Lines、JSON 等）？
   - [ ] 數據遷移是否完整？

3. **服務接口檢查**：
   - [ ] API 接口是否符合架構設計？
   - [ ] 服務接口是否向後兼容？
   - [ ] 錯誤處理是否完善？

4. **性能與可擴展性檢查**：
   - [ ] 是否滿足性能要求？
   - [ ] 是否支持 Kubernetes 環境下的擴展？
   - [ ] 是否實現了必要的緩存策略？

#### 2.3 文檔更新要求

**每個階段完成後，必須更新**：

- [ ] 更新本進度管控表（標記完成狀態、更新進度百分比）
- [ ] 更新相關技術文檔
- [ ] 記錄實施過程中的問題和解決方案

### 3. 實施流程規範

#### 3.1 任務開始前

1. **確認任務理解**：
   - [ ] 閱讀任務描述和相關文檔
   - [ ] 確認技術方案和實現方式
   - [ ] 如有疑問，及時溝通

2. **環境準備**：
   - [ ] 確認開發環境已配置
   - [ ] 確認依賴已安裝
   - [ ] 確認測試環境可用

#### 3.2 任務實施中

1. **代碼開發**：
   - [ ] 遵循開發規範
   - [ ] 編寫清晰的代碼註釋
   - [ ] 實現必要的錯誤處理

2. **測試**：
   - [ ] 編寫單元測試
   - [ ] 執行集成測試
   - [ ] 驗證功能正確性

3. **代碼檢查**：
   - [ ] 運行 ruff 檢查
   - [ ] 運行 mypy 檢查
   - [ ] 運行 black 格式化
   - [ ] 確保所有檢查通過

#### 3.3 任務完成後

1. **代碼提交**：
   - [ ] 確保所有檢查通過
   - [ ] 提交代碼並通過 pre-commit hooks
   - [ ] 更新進度管控表

2. **文檔更新**：
   - [ ] 更新技術文檔
   - [ ] 記錄實施過程中的問題
   - [ ] 更新進度說明

3. **架構對照檢查**：
   - [ ] 對照架構建議報告檢查實施結果
   - [ ] 確認滿足架構設計要求
   - [ ] 如有偏差，記錄原因和解決方案

### 4. 質量保證

#### 4.1 代碼質量標準

- ✅ **類型安全**：所有代碼必須通過 mypy 檢查
- ✅ **代碼風格**：所有代碼必須符合 ruff 和 black 規範
- ✅ **錯誤處理**：必須實現完善的錯誤處理機制
- ✅ **日誌記錄**：關鍵操作必須記錄日誌

#### 4.2 測試要求

- ✅ **單元測試覆蓋率**：關鍵功能必須有單元測試
- ✅ **集成測試**：必須驗證服務間的集成
- ✅ **性能測試**：必須驗證性能指標
- ✅ **數據遷移驗證**：必須驗證數據完整性

#### 4.3 文檔要求

- ✅ **代碼註釋**：關鍵邏輯必須有註釋
- ✅ **API 文檔**：所有 API 必須有文檔
- ✅ **架構文檔**：必須與實施保持一致
- ✅ **變更記錄**：重要變更必須記錄

---

## 📋 報告概述

本報告基於 [資料架構建議報告](./資料架构建议报告.md) 中的「整體AI-Box實際資料存儲規劃」，分析當前架構狀態，並提供詳細的重構任務清單與實施計劃。

### 重構目標

根據架構建議報告，需要引入 **SeaweedFS** 作為**統一對象存儲 (Unified Object Storage)**，用於存儲日誌、版本歷史和文件數據。

**重要決策**：經過分析，決定**不引入 PostgreSQL**，原因如下：

- 審計日誌和系統日誌是 Append-Only 模式，適合存儲在 SeaweedFS
- 版本歷史和變更提案也是 Append-Only 模式，適合文件存儲
- 系統設置 JSON 需要頻繁 CRUD 操作，保留在 ArangoDB 更合適
- 簡化架構，減少運維複雜度

### 專案架構說明

**重要**：未來 **DataLake** 將是獨立於 AI-Box 的專案，但在 AI-Box workspace 中會包含兩個 project：

1. **AI-Box**：現有的 AI-Box 專案
2. **DataLake**：獨立的 DataLake 專案

**SeaweedFS 雙服務部署架構**：

SeaweedFS 將部署兩個獨立的服務實例：

#### 1. AI-Box 內的 SeaweedFS 服務

**用途**：存放 AI-Box 專案內的非結構化數據

**主要存儲內容**：

- **審計日誌**：審計日誌記錄（Append-Only）
- **系統日誌**：系統日誌記錄（Append-Only）
- **版本歷史記錄**：配置和 Ontology 的歷史版本（Append-Only）
- **變更提案**：變更提案記錄（Append-Only）
- **AI-Box 內其他非結構化資料**：
  - Data Agent 保存的 DataLake dictionary 定義
  - Data Agent 保存的 DataLake schema 定義
  - 其他 AI-Box 專案相關的非結構化數據
  - **注意**：目前這些數據似乎保存在 ArangoDB 中，未來需要遷移到 SeaweedFS

**不存儲在 SeaweedFS 的數據**：

- ❌ **系統設置 JSON**：需要頻繁 CRUD 操作，保留在 ArangoDB（`system_configs` / `tenant_configs` / `user_configs`）

**部署位置**：AI-Box 專案內

#### 2. DataLake 專案內的 SeaweedFS 服務

**用途**：主要用於文件備份

**主要存儲內容**：

- 文件備份數據
- DataLake 專案相關的存儲需求

**部署位置**：DataLake 專案內（獨立部署）

**架構優勢**：

- ✅ 職責分離：AI-Box 和 DataLake 各自管理自己的存儲
- ✅ 獨立擴展：兩個服務可以根據各自需求獨立擴展
- ✅ 數據隔離：避免兩個專案之間的數據混雜
- ✅ 靈活部署：可以根據實際需求選擇不同的部署策略

### 關於 DataLake 專案的說明

**重要說明**：本計劃主要關注 **AI-Box 專案的重構**，包含以下內容：

#### ✅ 本計劃包含的 DataLake 相關內容

1. **DataLake SeaweedFS 服務部署**：在 Phase 1.1.2 中詳細規劃了 DataLake 專案內的 SeaweedFS 服務部署
2. **DataLake 相關數據遷移**：在 Phase 3.2.1 中規劃了從 ArangoDB 遷移 DataLake dictionary 和 schema 定義到 SeaweedFS
3. **雙服務架構支持**：在客戶端封裝中支持選擇不同的 SeaweedFS 服務（AI-Box 或 DataLake）

#### ❌ 本計劃不包含的 DataLake 專案內容

1. **DataLake 專案本身的創建**：DataLake 專案的初始化、目錄結構設計等
2. **DataLake 專案的整體架構設計**：DataLake 專案的完整架構規劃
3. **DataLake 專案的其他組件部署**：除了 SeaweedFS 服務外的其他 DataLake 組件
4. **DataLake 專案的業務邏輯實現**：DataLake 專案的核心功能開發

**原因**：DataLake 是獨立於 AI-Box 的專案，應該有獨立的專案計劃和架構文檔。本計劃僅關注 AI-Box 專案的重構，以及與 DataLake 專案相關的存儲服務部署（SeaweedFS）。

**建議**：如需完整的 DataLake 專案創建和部署計劃，請參考獨立的 DataLake 專案文檔。

---

## 🔍 當前架構狀態分析

### 1. 文件存儲現狀

**當前實現**：

- **存儲方式**：本地文件系統 (`LocalFileStorage`)
- **存儲路徑**：`./data/datasets/files`
- **實現位置**：`storage/file_storage.py`
- **使用場景**：
  - 用戶上傳的文件（PDF/Word/Excel等）
  - Agent 產出的文件（HTML/PDF報告）
  - 文件版本快照（`{file_id}__v{version}`）
  - 任務工作區文件

**問題點**：

- ❌ 無法在 Kubernetes 環境下實現無狀態擴展
- ❌ Pod 重啟或漂移會導致文件丟失
- ❌ 難以實現跨節點文件共享
- ❌ 不支持對象存儲的生命周期管理

**需要重構的文件**：

```
storage/file_storage.py                    # 文件存儲抽象層
api/routers/file_upload.py                 # 文件上傳路由
api/routers/docs_editing.py                # 文檔編輯（版本快照）
agents/services/file_service/              # Agent 文件服務
services/api/services/file_metadata_service.py  # 文件元數據服務
```

### 2. 治理數據現狀

**當前實現**：

- **存儲位置**：ArangoDB
- **Collections**：
  - `audit_logs`：審計日誌（`services/api/services/audit_log_service.py`）
  - `system_logs`：系統日誌（`services/api/core/log/log_service.py`）
  - `ontologies`：Ontology 定義（版本管理在 ArangoDB）
  - `system_configs` / `tenant_configs` / `user_configs`：配置管理
  - `file_metadata`：文件元數據（包含版本信息）

**問題點**：

- ❌ ArangoDB 不適合 Append-Only 的審計日誌模式
- ❌ 日誌數據占用 ArangoDB 存儲空間，影響知識圖譜查詢性能
- ❌ 版本歷史和變更提案（Proposal）機制未實現
- ❌ 日誌查詢與知識圖譜查詢混在一起，職責不清

**需要遷移到 SeaweedFS 的數據（從 ArangoDB）**：

```
audit_logs          → SeaweedFS (AI-Box 服務，Append-Only)
system_logs         → SeaweedFS (AI-Box 服務，Append-Only)
版本歷史記錄        → SeaweedFS (AI-Box 服務，Append-Only)
變更提案 (Proposal) → SeaweedFS (AI-Box 服務，Append-Only)
DataLake dictionary 定義 → SeaweedFS (AI-Box 服務)
DataLake schema 定義    → SeaweedFS (AI-Box 服務)
```

**需要保留在 ArangoDB 的數據（Active State）**：

```
ontologies          → ArangoDB (Active Knowledge)
system_configs     → ArangoDB (Active State - 需要頻繁 CRUD)
tenant_configs     → ArangoDB (Active State - 需要頻繁 CRUD)
user_configs       → ArangoDB (Active State - 需要頻繁 CRUD)
file_metadata       → ArangoDB (Active State)
entities / relations → ArangoDB (知識圖譜)
```

**存儲分配原則**：

- ✅ **ArangoDB**：專注於 Active State 數據（當前生效的配置、知識圖譜）
- ✅ **SeaweedFS**：專注於 Append-Only 數據（日誌、版本歷史）和非結構化文件
- ✅ **系統設置 JSON**：保留在 ArangoDB，因為需要頻繁的 CRUD 操作和複雜查詢

### 3. 知識數據現狀（無需變更）

**當前實現**：

- **ArangoDB**：
  - `ontologies`：Ontology 定義（Active State）
  - `entities` / `relations`：知識圖譜實體和關係
- **ChromaDB**：向量存儲（RAG 檢索）

**狀態**：✅ **保持不變**，這些數據屬於「認知與知識 (Active Knowledge)」層

---

## 🎯 重構任務清單

### Phase 1: 基礎設施就緒 (Infrastructure Ready)

#### 1.1 SeaweedFS 部署與配置（雙服務架構）

**重要**：SeaweedFS 將部署兩個獨立的服務實例，分別服務於 AI-Box 和 DataLake 專案。

##### 1.1.1 AI-Box 專案內的 SeaweedFS 服務

**部署任務**：

- [x] 在 Kubernetes 集群中部署 **AI-Box SeaweedFS 集群**（Master + Volume + Filer）
  - ✅ 已創建 Kubernetes 部署配置文件（`k8s/seaweedfs-ai-box/`）
  - ✅ 配置 Master 節點（高可用，3 副本）
  - ✅ 配置 Volume 節點（存儲節點，3 副本）
  - ✅ 配置 Filer 節點（文件系統接口，2 副本）
  - ✅ **服務名稱**：`seaweedfs-ai-box`（用於區分）
- [x] 啟用 S3 API 支持（SeaweedFS 內建 S3 兼容 API）（已在 Filer 配置中啟用）
- [x] 創建必要的 Buckets（已創建 Buckets 創建腳本）：
  - `bucket-governance-logs`：治理相關日誌（審計日誌、系統日誌）
  - `bucket-version-history`：版本歷史記錄
  - `bucket-change-proposals`：變更提案記錄
  - `bucket-datalake-dictionary`：Data Agent 保存的 DataLake dictionary 定義
  - `bucket-datalake-schema`：Data Agent 保存的 DataLake schema 定義
  - `bucket-ai-box-assets`：AI-Box 專案其他非結構化數據
- [x] 配置 SeaweedFS S3 API 訪問憑證（Access Key / Secret Key）（已在 Secret 配置中準備）
- [x] 配置環境變數（AI-Box 專案）（已更新 `env.example`）：

  ```bash
  # AI-Box 專案的 SeaweedFS 配置
  AI_BOX_SEAWEEDFS_S3_ENDPOINT=http://seaweedfs-ai-box-filer:8333
  AI_BOX_SEAWEEDFS_S3_ACCESS_KEY=...
  AI_BOX_SEAWEEDFS_S3_SECRET_KEY=...
  AI_BOX_SEAWEEDFS_USE_SSL=false
  # 可選：直接使用 Filer API
  AI_BOX_SEAWEEDFS_FILER_ENDPOINT=http://seaweedfs-ai-box-filer:8888
  ```

- [ ] 測試 AI-Box SeaweedFS S3 API 連接和基本操作（需在實際 Kubernetes 集群部署後測試）

**數據遷移任務**：

- [ ] 從 ArangoDB 遷移審計日誌到 SeaweedFS
- [ ] 從 ArangoDB 遷移系統日誌到 SeaweedFS
- [ ] 從 ArangoDB 遷移 DataLake dictionary 定義到 SeaweedFS
- [ ] 從 ArangoDB 遷移 DataLake schema 定義到 SeaweedFS

##### 1.1.2 DataLake 專案內的 SeaweedFS 服務

**前置條件**：

- ⚠️ **重要**：部署 DataLake SeaweedFS 服務前，需要先完成 DataLake 專案的創建和基礎架構設置
- ⚠️ DataLake 專案應該有獨立的專案計劃和架構文檔
- ⚠️ 本計劃僅包含 DataLake SeaweedFS 服務的部署，不包含 DataLake 專案本身的創建

**部署任務**：

- [x] **前置**：確認 DataLake 專案已創建並完成基礎架構設置（註：DataLake 專案本身的創建不在本計劃範圍內，但 SeaweedFS 服務配置已準備就緒）
- [x] 在 Kubernetes 集群中部署 **DataLake SeaweedFS 集群**（Master + Volume + Filer）
  - ✅ 已創建 Kubernetes 部署配置文件（`k8s/seaweedfs-datalake/`）
  - ✅ 配置 Master 節點（高可用，3 副本）
  - ✅ 配置 Volume 節點（存儲節點，3 副本）
  - ✅ 配置 Filer 節點（文件系統接口，2 副本）
  - ✅ **服務名稱**：`seaweedfs-datalake`（用於區分）
- [x] 啟用 S3 API 支持（已在 Filer 配置中啟用）
- [x] 創建必要的 Buckets（已創建 Buckets 創建腳本）：
  - `bucket-file-backups`：文件備份數據
  - `bucket-datalake-assets`：DataLake 專案相關的其他存儲需求
- [x] 配置 SeaweedFS S3 API 訪問憑證（Access Key / Secret Key）（已在 Secret 配置中準備）
- [x] 配置環境變數（DataLake 專案）（已更新 `env.example`）：

  ```bash
  # DataLake 專案的 SeaweedFS 配置
  DATALAKE_SEAWEEDFS_S3_ENDPOINT=http://seaweedfs-datalake-filer:8333
  DATALAKE_SEAWEEDFS_S3_ACCESS_KEY=...
  DATALAKE_SEAWEEDFS_S3_SECRET_KEY=...
  DATALAKE_SEAWEEDFS_USE_SSL=false
  # 可選：直接使用 Filer API
  DATALAKE_SEAWEEDFS_FILER_ENDPOINT=http://seaweedfs-datalake-filer:8888
  ```

- [ ] 測試 DataLake SeaweedFS S3 API 連接和基本操作（需在實際 Kubernetes 集群部署後測試）

**相關文件**：

- `k8s/seaweedfs-ai-box/`：AI-Box 專案的 Kubernetes 部署配置
- `k8s/seaweedfs-datalake/`：DataLake 專案的 Kubernetes 部署配置
- `.env.example`：環境變數配置示例（包含兩個服務的配置）
- `config/config.example.json`：配置文件示例

**架構優勢**：

- ✅ **職責分離**：AI-Box 和 DataLake 各自管理自己的存儲
- ✅ **獨立擴展**：兩個服務可以根據各自需求獨立擴展
- ✅ **數據隔離**：避免兩個專案之間的數據混雜
- ✅ **靈活部署**：可以根據實際需求選擇不同的部署策略

**SeaweedFS 優勢**：

- ✅ 高效的分布式文件系統，適合處理大量小文件
- ✅ 支持多副本和分片存儲，確保數據高可用性
- ✅ 內建 S3 兼容 API，無需額外配置
- ✅ 支持 Filer（文件系統接口）和 S3 API 兩種訪問方式

#### 1.2 SeaweedFS 客戶端封裝（支持雙服務）

**任務**：

- [x] 創建 `storage/s3_storage.py`（實現 `FileStorage` 接口）
- [x] 實現 `S3FileStorage` 類（使用 boto3 連接 SeaweedFS S3 API）：

  ```python
  import boto3
  from botocore.client import Config
  from enum import Enum

  class SeaweedFSService(str, Enum):
      """SeaweedFS 服務類型"""
      AI_BOX = "ai_box"      # AI-Box 專案的 SeaweedFS 服務
      DATALAKE = "datalake"  # DataLake 專案的 SeaweedFS 服務

  class S3FileStorage(FileStorage):
      def __init__(
          self,
          endpoint: str,
          access_key: str,
          secret_key: str,
          use_ssl: bool = False,
          service_type: SeaweedFSService = SeaweedFSService.AI_BOX
      ):
          # 初始化 SeaweedFS S3 客戶端（使用 boto3）
          self.s3_client = boto3.client(
              's3',
              endpoint_url=endpoint,
              aws_access_key_id=access_key,
              aws_secret_access_key=secret_key,
              use_ssl=use_ssl,
              config=Config(signature_version='s3v4')
          )
          self.endpoint = endpoint
          self.service_type = service_type  # 標記服務類型

      def save_file(...) -> Tuple[str, str]:
          # 保存文件到 SeaweedFS，返回 (file_id, s3_uri)
          # 使用 boto3 put_object
          # 根據 service_type 選擇對應的 bucket
          pass

      def get_file_path(...) -> Optional[str]:
          # 返回 S3 URI (s3://bucket/key 或 https://endpoint/bucket/key)
          pass

      def read_file(...) -> Optional[bytes]:
          # 從 SeaweedFS 讀取文件
          # 使用 boto3 get_object
          pass

      def delete_file(...) -> bool:
          # 從 SeaweedFS 刪除文件
          # 使用 boto3 delete_object
          pass
  ```

- [x] 實現 Bucket 管理（自動創建 Bucket，使用 `create_bucket`）
  - AI-Box 服務：`bucket-governance-logs`, `bucket-version-history`, `bucket-change-proposals`, `bucket-datalake-dictionary`, `bucket-datalake-schema`, `bucket-ai-box-assets`
  - DataLake 服務：`bucket-file-backups`, `bucket-datalake-assets`
- [x] 實現文件版本管理（SeaweedFS 支持對象版本控制）（通過 S3 URI 和文件路徑管理）
- [x] 實現服務類型選擇邏輯：

  ```python
  def create_storage_from_config(config: Optional[dict] = None, service_type: SeaweedFSService = SeaweedFSService.AI_BOX) -> FileStorage:
      """根據配置創建存儲實例，支持選擇不同的 SeaweedFS 服務"""
      if service_type == SeaweedFSService.AI_BOX:
          endpoint = config.get("ai_box_seaweedfs_s3_endpoint")
          access_key = config.get("ai_box_seaweedfs_s3_access_key")
          secret_key = config.get("ai_box_seaweedfs_s3_secret_key")
      elif service_type == SeaweedFSService.DATALAKE:
          endpoint = config.get("datalake_seaweedfs_s3_endpoint")
          access_key = config.get("datalake_seaweedfs_s3_access_key")
          secret_key = config.get("datalake_seaweedfs_s3_secret_key")
      # ...
  ```

- [ ] 可選：實現 Filer API 封裝（如果需要文件系統接口）（暫未實現，使用 S3 API）
- [x] 編寫單元測試（測試兩個服務的連接）（已創建 `tests/storage/test_s3_storage.py`）

**相關文件**：

- `storage/s3_storage.py`：S3/SeaweedFS 存儲實現（支持雙服務）
- `storage/file_storage.py`：更新 `create_storage_from_config` 支持雙服務選擇
- `tests/storage/test_s3_storage.py`：單元測試

**技術說明**：

- SeaweedFS 完全兼容 S3 API，可以使用標準的 `boto3` 庫
- 也可以使用 SeaweedFS 的 Filer API（RESTful 接口）進行文件操作
- 建議使用 S3 API 以保持與其他對象存儲系統的兼容性
- **雙服務支持**：通過 `service_type` 參數區分不同的 SeaweedFS 服務實例

---

### Phase 2: 治理層接入 (Governance Integration)

#### 2.1 審計日誌服務遷移（ArangoDB → SeaweedFS）

**任務**：

- [ ] 創建 `services/api/services/governance/seaweedfs_log_service.py`
- [ ] 實現 `SeaweedFSAuditLogService` 類：

  ```python
  class SeaweedFSAuditLogService:
      def __init__(self, seaweedfs_storage: S3FileStorage):
          self.storage = seaweedfs_storage
          self.bucket = "bucket-governance-logs"

      async def create_audit_log(self, log: AuditLog) -> str:
          # 1. 生成日誌文件路徑（按時間分片）
          # 例如：audit/2025/12/29.jsonl
          file_path = self._get_log_file_path(log.timestamp, "audit")

          # 2. 讀取現有文件（如果存在）
          existing_content = self.storage.read_file(file_path)

          # 3. 追加新日誌（JSON Lines 格式）
          log_line = json.dumps(log.dict(), ensure_ascii=False) + "\n"
          new_content = (existing_content or b"") + log_line.encode('utf-8')

          # 4. 寫回 SeaweedFS
          self.storage.save_file(
              new_content,
              filename=file_path,
              file_id=None  # 使用路徑作為 key
          )
          return log.id

      async def get_audit_logs(
          self,
          user_id: Optional[str] = None,
          action: Optional[AuditAction] = None,
          start_time: Optional[datetime] = None,
          end_time: Optional[datetime] = None,
          limit: int = 100
      ) -> List[AuditLog]:
          # 1. 根據時間範圍確定需要讀取的文件列表
          files = self._get_log_files_in_range(start_time, end_time, "audit")

          # 2. 並行讀取文件並過濾
          logs = []
          for file_path in files:
              content = self.storage.read_file(file_path)
              if content:
                  for line in content.decode('utf-8').split('\n'):
                      if line:
                          log = json.loads(line)
                          if self._matches_filters(log, user_id, action, start_time, end_time):
                              logs.append(AuditLog(**log))

          # 3. 排序和分頁
          sorted_logs = sorted(logs, key=lambda x: x.timestamp, reverse=True)
          return sorted_logs[:limit]

      def _get_log_file_path(self, timestamp: datetime, log_type: str) -> str:
          """生成日誌文件路徑（按天分片）"""
          date_str = timestamp.strftime("%Y/%m/%d")
          return f"{log_type}/{date_str}.jsonl"

      def _get_log_files_in_range(
          self,
          start_time: Optional[datetime],
          end_time: Optional[datetime],
          log_type: str
      ) -> List[str]:
          """獲取時間範圍內的所有日誌文件路徑"""
          # 實現邏輯：根據 start_time 和 end_time 生成文件路徑列表
          pass
  ```

- [ ] 更新 `services/api/services/audit_log_service.py`：
  - 保留 `AuditLogService` 接口
  - 內部使用 `SeaweedFSAuditLogService`
  - 向後兼容現有代碼
- [ ] 更新所有使用 `AuditLogService` 的地方
- [ ] 編寫數據遷移腳本（從 ArangoDB 遷移到 SeaweedFS）

**相關文件**：

- `services/api/services/governance/seaweedfs_log_service.py`：SeaweedFS 日誌服務實現
- `services/api/services/audit_log_service.py`：適配器（向後兼容）
- `scripts/migration/migrate_audit_logs_to_seaweedfs.py`：數據遷移腳本

**存儲格式**：JSON Lines (`.jsonl`)，每行一個日誌記錄，便於追加寫入和流式讀取

#### 2.2 系統日誌服務遷移（ArangoDB → SeaweedFS）

**任務**：

- [ ] 擴展 `services/api/services/governance/seaweedfs_log_service.py`
- [ ] 實現 `SeaweedFSSystemLogService` 類（類似審計日誌服務）
- [ ] 更新 `services/api/core/log/log_service.py`：
  - 保留 `LogService` 接口
  - 內部使用 `SeaweedFSSystemLogService`
  - 向後兼容現有代碼
- [ ] 實現按日誌類型分片存儲：
  - `system/task/YYYY/MM/DD.jsonl`：任務日誌
  - `system/audit/YYYY/MM/DD.jsonl`：審計日誌
  - `system/security/YYYY/MM/DD.jsonl`：安全日誌
- [ ] 更新所有使用 `LogService` 的地方
- [ ] 編寫數據遷移腳本

**相關文件**：

- `services/api/services/governance/seaweedfs_log_service.py`：SeaweedFS 日誌服務實現
- `services/api/core/log/log_service.py`：適配器（向後兼容）
- `scripts/migration/migrate_system_logs_to_seaweedfs.py`：數據遷移腳本

#### 2.3 版本歷史服務實現（SeaweedFS 存儲）

**任務**：

- [ ] 創建 `services/api/services/governance/version_history_service.py`
- [ ] 實現 `SeaweedFSVersionHistoryService` 類：

  ```python
  class SeaweedFSVersionHistoryService:
      def __init__(self, seaweedfs_storage: S3FileStorage):
          self.storage = seaweedfs_storage
          self.bucket = "bucket-version-history"

      async def create_version(
          self,
          resource_type: str,
          resource_id: str,
          change_type: str,
          changed_by: str,
          change_summary: str,
          previous_version: Dict[str, Any],
          current_version: Dict[str, Any]
      ) -> int:
          # 1. 獲取當前版本號
          version = await self._get_next_version(resource_type, resource_id)

          # 2. 生成版本文件路徑
          # 例如：versions/ontologies/{resource_id}/v{version}.json
          file_path = f"versions/{resource_type}/{resource_id}/v{version}.json"

          # 3. 創建版本記錄
          version_record = {
              "resource_type": resource_type,
              "resource_id": resource_id,
              "version": version,
              "change_type": change_type,
              "changed_by": changed_by,
              "change_summary": change_summary,
              "previous_version": previous_version,
              "current_version": current_version,
              "created_at": datetime.utcnow().isoformat()
          }

          # 4. 保存到 SeaweedFS
          self.storage.save_file(
              json.dumps(version_record, ensure_ascii=False).encode('utf-8'),
              filename=file_path,
              file_id=None
          )

          return version

      async def get_version_history(
          self,
          resource_type: str,
          resource_id: str,
          limit: int = 100
      ) -> List[VersionHistory]:
          # 1. 列出所有版本文件
          prefix = f"versions/{resource_type}/{resource_id}/"
          files = self._list_files(prefix)

          # 2. 讀取並解析版本記錄
          versions = []
          for file_path in sorted(files, reverse=True)[:limit]:
              content = self.storage.read_file(file_path)
              if content:
                  version_record = json.loads(content.decode('utf-8'))
                  versions.append(VersionHistory(**version_record))

          return versions

      async def get_version(
          self,
          resource_type: str,
          resource_id: str,
          version: int
      ) -> Optional[VersionHistory]:
          # 讀取特定版本文件
          file_path = f"versions/{resource_type}/{resource_id}/v{version}.json"
          content = self.storage.read_file(file_path)
          if content:
              return VersionHistory(**json.loads(content.decode('utf-8')))
          return None
  ```

- [ ] 集成到現有服務：
  - `OntologyStoreService`：Ontology 更新時記錄版本到 SeaweedFS
  - `ConfigStoreService`：Config 更新時記錄版本到 SeaweedFS
  - `FileMetadataService`：文件更新時記錄版本到 SeaweedFS（已在 `docs_editing.py` 中實現部分邏輯）

**相關文件**：

- `services/api/services/governance/version_history_service.py`：版本歷史服務（SeaweedFS）
- `services/api/services/ontology_store_service.py`：集成版本歷史
- `services/api/services/config_store_service.py`：集成版本歷史
- `api/routers/docs_editing.py`：更新版本記錄邏輯

#### 2.4 變更提案機制實現（SeaweedFS 存儲）

**任務**：

- [ ] 創建 `services/api/services/governance/change_proposal_service.py`
- [ ] 實現 `SeaweedFSChangeProposalService` 類：

  ```python
  class SeaweedFSChangeProposalService:
      def __init__(self, seaweedfs_storage: S3FileStorage):
          self.storage = seaweedfs_storage
          self.bucket = "bucket-change-proposals"

      async def create_proposal(
          self,
          proposal_type: str,
          resource_id: Optional[str],
          proposed_by: str,
          proposal_data: Dict[str, Any],
          approval_required: bool = True
      ) -> str:
          # 1. 生成提案 ID
          proposal_id = f"{proposal_type}_{resource_id}_{int(time.time() * 1000)}"

          # 2. 生成提案文件路徑
          # 例如：proposals/{proposal_type}/{resource_id}/{proposal_id}.json
          file_path = f"proposals/{proposal_type}/{resource_id or 'global'}/{proposal_id}.json"

          # 3. 創建提案記錄
          proposal_record = {
              "proposal_id": proposal_id,
              "proposal_type": proposal_type,
              "resource_id": resource_id,
              "proposed_by": proposed_by,
              "status": "PENDING",
              "proposal_data": proposal_data,
              "approval_required": approval_required,
              "created_at": datetime.utcnow().isoformat(),
              "updated_at": datetime.utcnow().isoformat()
          }

          # 4. 保存到 SeaweedFS
          self.storage.save_file(
              json.dumps(proposal_record, ensure_ascii=False).encode('utf-8'),
              filename=file_path,
              file_id=None
          )

          return proposal_id

      async def approve_proposal(
          self,
          proposal_id: str,
          approved_by: str
      ) -> bool:
          # 1. 讀取提案文件
          proposal = await self._get_proposal(proposal_id)
          if not proposal:
              return False

          # 2. 更新提案狀態
          proposal["status"] = "APPROVED"
          proposal["approved_by"] = approved_by
          proposal["approved_at"] = datetime.utcnow().isoformat()
          proposal["updated_at"] = datetime.utcnow().isoformat()

          # 3. 保存更新後的提案
          file_path = self._get_proposal_file_path(proposal_id)
          self.storage.save_file(
              json.dumps(proposal, ensure_ascii=False).encode('utf-8'),
              filename=file_path,
              file_id=None
          )

          # 4. 應用到 ArangoDB（Active State）
          await self._apply_proposal_to_arangodb(proposal)

          return True

      async def reject_proposal(
          self,
          proposal_id: str,
          rejected_by: str,
          reason: str
      ) -> bool:
          # 類似 approve_proposal，但狀態改為 REJECTED
          pass
  ```

- [ ] 實現 Proposal Flow：
  1. AI 生成變更提案 → 存入 SeaweedFS
  2. 人工審批（或自動審批）
  3. 審批通過後 → 寫入 ArangoDB（Active State）
- [ ] 集成到 `SystemConfigAgent`：
  - AI 修改 Config 前，先創建 Proposal 存入 SeaweedFS
  - 審批通過後再更新 ArangoDB

**相關文件**：

- `services/api/services/governance/change_proposal_service.py`：變更提案服務（SeaweedFS）
- `agents/builtin/system_config_agent/agent.py`：集成 Proposal Flow
- `api/routers/governance.py`：治理相關 API 路由（新建）

---

### Phase 3: 存儲層遷移 (Storage Migration)

#### 3.1 文件存儲服務改造

**任務**：

- [ ] 更新 `storage/file_storage.py`：
  - 更新 `create_storage_from_config` 支持 S3/SeaweedFS
  - 配置優先級：S3 > Local（生產環境使用 S3）
- [ ] 更新 `api/routers/file_upload.py`：
  - 確保使用新的存儲後端
  - 更新文件路徑返回邏輯（返回 S3 URI）
- [ ] 更新 `api/routers/docs_editing.py`：
  - 版本快照存儲到 SeaweedFS
  - 更新版本文件路徑邏輯
- [ ] 更新 `agents/services/file_service/agent_file_service.py`：
  - Agent 產出文件存儲到 SeaweedFS
- [ ] 更新 `services/api/services/file_metadata_service.py`：
  - `storage_path` 字段存儲 S3 URI 而非本地路徑

**相關文件**：

- `storage/file_storage.py`：存儲抽象層
- `api/routers/file_upload.py`：文件上傳路由
- `api/routers/docs_editing.py`：文檔編輯路由
- `agents/services/file_service/agent_file_service.py`：Agent 文件服務
- `services/api/services/file_metadata_service.py`：文件元數據服務

#### 3.2 文件遷移腳本

**任務**：

- [ ] 創建 `scripts/migration/migrate_files_to_seaweedfs.py`：

  ```python
  def migrate_files_to_seaweedfs():
      # 1. 掃描本地文件系統 (./data/datasets/files)
      # 2. 讀取每個文件
      # 3. 上傳到 SeaweedFS（保持相同的路徑結構）
      # 4. 更新 file_metadata.storage_path 為 S3 URI
      # 5. 驗證遷移結果
      # 6. 可選：刪除本地文件（備份後）
      pass
  ```

- [ ] 實現增量遷移（支持中斷後繼續）
- [ ] 實現遷移驗證（文件完整性檢查）
- [ ] 編寫遷移文檔

**相關文件**：

- `scripts/migration/migrate_files_to_seaweedfs.py`：文件遷移腳本
- `docs/系统设计文档/資料存儲架構重構/文件遷移指南.md`：遷移文檔

#### 3.2.1 DataLake 相關數據遷移（從 ArangoDB 到 SeaweedFS）

**任務**：

- [ ] 創建 `scripts/migration/migrate_datalake_data_to_seaweedfs.py`：

  ```python
  def migrate_datalake_data_to_seaweedfs():
      # 1. 從 ArangoDB 查詢 DataLake dictionary 定義
      # 2. 從 ArangoDB 查詢 DataLake schema 定義
      # 3. 將這些數據轉換為 JSON 格式
      # 4. 上傳到 AI-Box SeaweedFS 服務：
      #    - dictionary 定義 → bucket-datalake-dictionary
      #    - schema 定義 → bucket-datalake-schema
      # 5. 更新相關服務的引用（從 ArangoDB 改為 SeaweedFS URI）
      # 6. 驗證遷移結果
      # 7. 可選：從 ArangoDB 刪除已遷移的數據（備份後）
      pass
  ```

- [ ] 實現數據格式轉換（ArangoDB Document → JSON 文件）
- [ ] 實現遷移驗證（數據完整性檢查）
- [ ] 更新 Data Agent 相關服務：
  - 修改讀取邏輯（從 ArangoDB 改為從 SeaweedFS 讀取）
  - 修改寫入邏輯（寫入到 SeaweedFS 而非 ArangoDB）
- [ ] 編寫遷移文檔

**相關文件**：

- `scripts/migration/migrate_datalake_data_to_seaweedfs.py`：DataLake 數據遷移腳本
- `agents/services/data_agent/`：Data Agent 相關服務（需要更新）
- `docs/系统设计文档/資料存儲架構重構/DataLake數據遷移指南.md`：遷移文檔

#### 3.3 RAG 流程更新（可選優化）

**任務**：

- [ ] 更新 `genai/workflows/rag/`：
  - 文件上傳後直接存入 SeaweedFS
  - ChromaDB 僅存儲向量和 SeaweedFS URI 引用
  - 不再在 ChromaDB 中存儲大量文本 Payload
- [ ] 更新向量檢索邏輯：
  - 檢索到向量後，從 SeaweedFS 讀取原始文本（如需要）

**相關文件**：

- `genai/workflows/rag/retrieval_service.py`：檢索服務
- `genai/api/routers/chunk_processing.py`：分塊處理路由

---

### Phase 4: 測試與驗證

#### 4.1 單元測試

**任務**：

- [ ] 測試 SeaweedFS 存儲實現
- [ ] 測試審計日誌服務（SeaweedFS）
- [ ] 測試系統日誌服務（SeaweedFS）
- [ ] 測試版本歷史服務（SeaweedFS）
- [ ] 測試變更提案服務（SeaweedFS）

#### 4.2 集成測試

**任務**：

- [ ] 測試文件上傳流程（SeaweedFS）
- [ ] 測試文件版本管理（SeaweedFS）
- [ ] 測試審計日誌記錄（SeaweedFS）
- [ ] 測試系統日誌記錄（SeaweedFS）
- [ ] 測試版本歷史記錄（SeaweedFS）
- [ ] 測試變更提案流程（SeaweedFS → ArangoDB）

#### 4.3 性能測試

**任務**：

- [ ] 測試 SeaweedFS 文件讀寫性能
- [ ] 測試 SeaweedFS 日誌查詢性能（按時間範圍查詢）
- [ ] 測試日誌統計查詢性能（聚合查詢）
- [ ] 對比遷移前後的性能指標

#### 4.4 數據遷移驗證

**任務**：

- [ ] 驗證審計日誌遷移完整性（ArangoDB → SeaweedFS）
- [ ] 驗證系統日誌遷移完整性（ArangoDB → SeaweedFS）
- [ ] 驗證文件遷移完整性（本地文件系統 → SeaweedFS）
- [ ] 驗證版本歷史記錄完整性
- [ ] 驗證數據一致性

---

### Phase 5: 文檔更新

#### 5.1 架構文檔更新

**任務**：

- [ ] 更新 [資料架構建議報告](./資料架构建议报告.md)（標記完成狀態）
- [ ] 更新 [README.md](./README.md)（數據層架構圖）
- [ ] 創建 SeaweedFS 使用指南
- [ ] 創建日誌存儲格式文檔（JSON Lines 格式說明）

#### 5.2 API 文檔更新

**任務**：

- [ ] 更新文件上傳 API 文檔（S3 URI 返回格式）
- [ ] 新增治理 API 文檔（版本歷史、變更提案）

#### 5.3 開發指南更新

**任務**：

- [ ] 更新開發環境設置指南（SeaweedFS 配置）
- [ ] 更新部署指南（Kubernetes 配置，包含雙服務部署）
- [ ] 更新數據遷移指南（ArangoDB → SeaweedFS）

---

## 📊 重構影響範圍分析

### 受影響的模組

| 模組 | 影響程度 | 說明 |
|------|---------|------|
| `storage/file_storage.py` | 🔴 高 | 需要新增 S3 實現 |
| `api/routers/file_upload.py` | 🟡 中 | 需要更新存儲後端調用 |
| `api/routers/docs_editing.py` | 🟡 中 | 版本快照存儲路徑更新 |
| `services/api/services/audit_log_service.py` | 🔴 高 | 需要遷移到 SeaweedFS |
| `services/api/core/log/log_service.py` | 🔴 高 | 需要遷移到 SeaweedFS |
| `agents/builtin/system_config_agent/` | 🟡 中 | 需要集成 Proposal Flow |
| `services/api/services/ontology_store_service.py` | 🟢 低 | 需要集成版本歷史記錄（SeaweedFS） |
| `services/api/services/config_store_service.py` | 🟢 低 | 需要集成版本歷史記錄（SeaweedFS） |

### 新增的模組

| 模組 | 說明 |
|------|------|
| `storage/s3_storage.py` | SeaweedFS/S3 存儲實現（支持雙服務） |
| `services/api/services/governance/` | 治理服務（審計、版本、提案，使用 SeaweedFS） |
| `api/routers/governance.py` | 治理相關 API |

---

## ⚠️ 風險評估與應對

### 風險 1：數據遷移過程中服務中斷

**風險等級**：🔴 高

**應對措施**：

- 實施雙寫策略（遷移期間同時寫入舊系統和新系統）
- 分階段遷移（先遷移歷史數據，再切換新數據）
- 準備回滾方案

### 風險 2：SeaweedFS 性能問題

**風險等級**：🟡 中

**應對措施**：

- 進行性能測試和優化
- 實施緩存策略（熱點文件緩存）
- 監控 SeaweedFS 性能指標（Master、Volume、Filer 節點）
- 優化 SeaweedFS 配置（副本數、分片策略等）

### 風險 3：SeaweedFS 日誌查詢性能

**風險等級**：🟡 中

**應對措施**：

- 實施按時間分片存儲，縮小查詢範圍
- 對於複雜查詢，可考慮在 ArangoDB 中建立輕量級索引
- 實施緩存策略（熱點查詢結果緩存）
- 監控查詢性能，必要時優化查詢邏輯

### 風險 4：文件遷移數據丟失

**風險等級**：🔴 高

**應對措施**：

- 遷移前完整備份
- 實施增量遷移和驗證
- 保留本地文件備份（遷移完成後再刪除）

---

## 📅 建議實施時間表

### 第一階段（2-3 週）：基礎設施就緒

- Week 1: SeaweedFS 雙服務部署
- Week 2: SeaweedFS 客戶端封裝開發
- Week 3: 單元測試和集成測試

### 第二階段（2-3 週）：治理層接入

- Week 1: 審計日誌和系統日誌服務遷移（ArangoDB → SeaweedFS）
- Week 2: 版本歷史和變更提案服務實現（SeaweedFS）
- Week 3: 集成測試和數據遷移

### 第三階段（2-3 週）：存儲層遷移

- Week 1: 文件存儲服務改造
- Week 2: 文件遷移腳本開發和執行
- Week 3: 驗證和優化

### 第四階段（1 週）：測試與文檔

- Week 1: 全面測試、文檔更新、上線準備

**總計**：約 7-10 週

---

## ✅ 檢查清單

### 基礎設施

- [ ] AI-Box SeaweedFS 服務部署完成
- [ ] DataLake SeaweedFS 服務部署完成
- [ ] 環境變數配置完成（包含兩個 SeaweedFS 服務的配置）
- [ ] 連接測試通過（兩個 SeaweedFS 服務）
- [ ] Buckets 創建完成（governance-logs, version-history, change-proposals 等）

### 代碼實現

- [ ] SeaweedFS 存儲實現完成（支持雙服務）
- [ ] 審計日誌服務遷移完成（ArangoDB → SeaweedFS）
- [ ] 系統日誌服務遷移完成（ArangoDB → SeaweedFS）
- [ ] 版本歷史服務實現完成（SeaweedFS）
- [ ] 變更提案服務實現完成（SeaweedFS）
- [ ] 文件存儲服務改造完成

### 數據遷移

- [ ] 審計日誌遷移完成（ArangoDB → SeaweedFS AI-Box 服務）
- [ ] 系統日誌遷移完成（ArangoDB → SeaweedFS AI-Box 服務）
- [ ] 文件遷移完成（本地文件系統 → SeaweedFS）
- [ ] DataLake dictionary 遷移完成（ArangoDB → SeaweedFS AI-Box 服務）
- [ ] DataLake schema 遷移完成（ArangoDB → SeaweedFS AI-Box 服務）
- [ ] 數據驗證通過

### 測試

- [ ] 單元測試通過
- [ ] 集成測試通過
- [ ] 性能測試通過
- [ ] 數據遷移驗證通過

### 文檔

- [ ] 架構文檔更新完成
- [ ] API 文檔更新完成
- [ ] 開發指南更新完成
- [ ] 部署指南更新完成

---

## 📝 總結

本重構計劃將 AI-Box 從「原型」階段提升到「企業級產品」階段，通過引入 SeaweedFS，實現：

1. **治理與控制**：嚴格的審計、版本管理和變更提案機制（存儲在 SeaweedFS）
2. **無狀態擴展**：SeaweedFS 分布式文件系統支持 Kubernetes 環境下的彈性擴展，適合處理大量小文件
3. **職責分離**：
   - **ArangoDB**：專注於 Active State 數據（知識圖譜、當前生效的配置）
   - **SeaweedFS**：專注於 Append-Only 數據（日誌、版本歷史）和非結構化文件
4. **高性能存儲**：SeaweedFS 提供高效的分布式存儲，支持多副本和分片，確保數據高可用性
5. **架構簡化**：不需要 PostgreSQL，降低運維複雜度和成本

重構過程需要：

- ✅ 分階段實施，降低風險
- ✅ 充分測試，確保數據完整性
- ✅ 向後兼容，平滑遷移
- ✅ 文檔同步，便於維護

---

**最後更新**: 2025-12-29（已更新：MinIO → SeaweedFS，移除 PostgreSQL，日誌存儲改為 SeaweedFS，階段一已完成）
**維護者**: Daniel Chung
