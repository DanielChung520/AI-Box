# KA-Agent 知識上架流程與邏輯檢討

**最後更新**: 2026-01-27 23:00 UTC+8  
**維護人**: Daniel Chung  

**本文檔作為「KA-Agent 文件上架測試」之管控文件**，規範上架目標、驗收目標與執行流程。

> **📋 通用流程參考**：本文檔基於 [Agent 專業知識上架管理](../Agent專業知識知識上架管理.md)，補充 KA-Agent 專屬的特殊要求。建議先閱讀通用流程文檔，再查看本文檔的 KA-Agent 專屬內容。

---

## 1. 上架目標與驗收目標

### 1.1 上架目標文件

| 項目 | 說明 |
|------|------|
| **路徑** | `docs/系统设计文档/核心组件/Agent平台/KA-Agent/知識庫` |
| **絕對路徑** | `/Users/daniel/GitHub/AI-Box/docs/系统设计文档/核心组件/Agent平台/KA-Agent/知識庫` |
| **內容** | 知識庫目錄下所有文件（含 KA-Agent 作業模版、作業規範、KSLS、版本號規範、架構白皮書等） |

### 1.2 驗收目標（上架測試通過條件）

| # | 目標 | 說明 | 驗收方式 |
|---|------|------|----------|
| **1** | **systemAdmin 登錄，前端能看到「KA-Agent」任務** | 以 systemAdmin 登入前端後，任務列表中顯示「KA-Agent」任務 | 前端登入 → 任務區檢視 |
| **2** | **任務文件區能看到知識文件，並能查看向量及圖譜** | 在「KA-Agent」任務下可看到已上架知識文件；可進入檔案詳情查看向量（Qdrant collection）與圖譜（entities/relations） | 前端任務 → 文件列表 → 單檔詳情（向量/圖譜） |
| **3** | **Qdrant、SeaweedFS Dashboard 能看到資料** | 向量存於 Qdrant；原始檔案存於 SeaweedFS；經 Dashboard 可檢視 | Qdrant Dashboard、SeaweedFS Dashboard |

**Qdrant Dashboard**：`http://localhost:6333/dashboard`（或依環境配置）  
**SeaweedFS**：依專案 Filer/Volume 配置（如 `http://localhost:8888` 等）

---

## 2. 系統邏輯順序

上架 **KA-Agent 自身知識**（如 `知識庫/` 下文件）時，正確順序為：

1. **先導入 Ontology**  
   - 將 `KA-Agent/Ontology/` 下的 `ka-agent-domain.json`、`ka-agent-major.json` 導入系統。  
   - **ArangoDB**：經 `OntologyStoreService.save_ontology` 寫入 `ontologies` collection，供 KG 提取與 merge 使用。  
   - **ontology_list.json**：註冊 domain/major 與 `quick_index`，供 `OntologySelector` 在編碼時選擇。

2. **再執行上架**  
   - 經 `POST /api/v1/files/v2/upload` 上傳 `知識庫/` 內文件。  
   - 上傳 pipeline：分塊 → 向量化 → 圖譜提取 → **知識資產編碼**（Ontology 對齊、KNW-Code 生成）→ 寫入 `file_metadata`。  
   - 編碼階段依賴 `OntologySelector`（讀 `ontology_list.json`）與 ArangoDB 中的 Ontology；故 **Ontology 須先導入**。

## 3. 預期效果（對應驗收目標）

| 項目 | 說明 | 對應驗收目標 |
|------|------|--------------|
| **上架 user** | `systemAdmin` | 目標 1 |
| **user tasks** | `task_id = "KA-Agent"`（任務標題亦為 "KA-Agent"） | 目標 1 |
| **前端可見** | 上架後可於前端文件系統看到「KA-Agent」任務及其下文件 | 目標 1、2 |
| **知識文件 + 向量/圖譜** | 任務文件區可檢視知識文件，並能查看向量與圖譜 | 目標 2 |
| **Qdrant / SeaweedFS** | Dashboard 可見到對應向量與檔案 | 目標 3 |
| **知識庫目錄** | `docs/系统设计文档/核心组件/Agent平台/KA-Agent/知識庫/` | 上架來源 |
| **Ontology 目錄** | `docs/系统设计文档/核心组件/Agent平台/KA-Agent/Ontology/` | 須先導入 |

## 4. 相關組件

- **Ontology 選擇**：`kag/ontology_selector.py`（`ontology_list.json`）  
- **Ontology 存儲**：`services/api/services/ontology_store_service.py`（ArangoDB）  
- **知識資產編碼**：`services/api/services/knowledge_asset_encoding_service.py`  
- **文件上傳**：`api/routers/file_upload.py`（v2 upload）  
- **任務與元數據**：`UserTaskService`、`FileMetadataService`  

## 5. 執行步驟

### 5.1 導入 Ontology（僅需第一次執行）

```bash
python scripts/import_ka_agent_ontology.py
```

- 讀取 `kag/ontology/ka-agent-domain.json`、`ka-agent-major.json`
- 寫入 ArangoDB `ontologies` collection（系統級，`tenant_id=None`）
- **注意**：如果 Ontology 已存在，腳本會自動跳過導入（避免重複導入）
- **後續測試**：如果 Ontology 已導入，可跳過此步驟，直接執行 §5.2

### 5.2 上架知識庫

**前提**（測試前須就緒；若有問題則**修復根因**後再測，**不以補跑代替**）：

- **API 服務**已啟動（如 `http://localhost:8000`）。
- **RQ Worker** 已啟動，且監聽 `file_processing`（及可選 `vectorization`、`kg_extraction`）。
  - 啟動方式：`python -m workers.service --queues file_processing vectorization kg_extraction --num-workers 3`
  - `--num-workers 3`：並發處理 3 個 job（默認 3，可調整）
- **Redis** 與 API 使用同一實例（同一 `REDIS_URL`）。
- API 運行環境已安裝 `rq`（否則上傳後入隊會失敗，但 API 不拋錯）。

1. 設定 **systemAdmin 密碼**（與 ArangoDB 中 system users 一致）：
   ```bash
   export SYSTEADMIN_PASSWORD="你的 systemAdmin 密碼"
   ```
2. 執行上架腳本：
   ```bash
   python scripts/upload_ka_agent_knowledge.py
   ```
   或顯式傳入：
   ```bash
   python scripts/upload_ka_agent_knowledge.py --password "你的密碼" [--api-base http://localhost:8000]
   ```

腳本會：登入 → 建立/確認任務「KA-Agent」→ 將 `知識庫/` 下所有檔案上傳至該任務。上傳走 `POST /api/v1/files/v2/upload`，**上傳成功後會自動入隊**，由 RQ Worker 執行分塊、向量化、圖譜提取與知識資產編碼。**測試流程不包含補跑**；若處理未完成，應**定位並修復根因**，然後清掉測試資料、重新執行完整流程（§5.1 → §5.2 → §5.3）。

### 5.3 前端與 Dashboard 驗收

上架後，依 **§1.2 驗收目標** 執行：

1. **目標 1**：以 **systemAdmin** 登入前端，確認任務列表中有「KA-Agent」任務。
2. **目標 2**：進入「KA-Agent」任務 → 任務文件區，確認可見知識文件；點選單檔，確認可查看向量及圖譜。
3. **目標 3**：開啟 **Qdrant Dashboard**、**SeaweedFS**（或 Filer）對應頁面，確認能見到該任務相關向量與檔案。

---

## 6. 自動化測試

| 項目 | 指令 | 說明 |
|------|------|------|
| Ontology 導入 | `python scripts/import_ka_agent_ontology.py` | 寫入 ArangoDB；**僅需第一次執行**，後續會自動跳過（已存在檢查） |
| KA-Agent E2E | `pytest tests/agents/builtin/test_ka_ingestion_flow.py -v` | 管理流程（Todo + 確認 + 註冊）+ 檢索流程（mock LLM）|
| 上架知識庫 | `SYSTEADMIN_PASSWORD=xxx python scripts/upload_ka_agent_knowledge.py` | 需 API、RQ Worker、Redis 就緒；上傳後**自動處理**，不需補跑 |

## 7. 檢索測試

上架完成後，再進行 **檢索查詢** 測試（規格 Ch 10 `knowledge.query` / `ka.retrieve`）。

---

## 8. 故障排除：有檔案、SeaweedFS 有檔，但無 Qdrant 向量與圖譜

**現象**：前端可見檔案、SeaweedFS 有檔，但 **未產生 Qdrant 向量** 也 **未產生知識圖譜**。

**原因**：上傳成功後，**分塊 → 向量化 → 圖譜提取** 由 **RQ Worker** 非同步執行。若 **RQ Worker 未運行**、**入隊失敗**（如 Redis 連線、`rq` 未安裝）等，則任務不會執行，故無向量與圖譜。

**測試環境原則**：**不依賴補跑**。出現上述現象時，表示**正常流程失敗**，應**定位根因、修復、清掉測試資料、重新執行完整流程**（Ontology → 上架 → 驗收），而不是用補跑繞過。

**處理步驟**（修復根因，非補跑）：

1. **確認 RQ Worker 已啟動**，且監聽 `file_processing`（及可選 `vectorization`、`kg_extraction`）：
   ```bash
   python -m workers.service --queues file_processing vectorization kg_extraction --num-workers 3
   ```
   - `--num-workers 3`：並發處理 3 個 job（默認 3，可根據系統資源調整）
   - 或依專案既有方式啟動 Worker（如 `scripts/start_rq_worker.sh`）。

2. **確認 Redis** 與 API 使用同一個實例（同一 `REDIS_URL` / host）。

3. 若 API 曾回報 **「RQ is not installed」**：在 **API 運行環境**（與 `api` 同一個 Python）中執行 `pip install rq`，確認 Redis 可連。

4. **修復後**：依 §10 清除該任務測試資料（如 `TEST_TASK_ID=KA-Agent python scripts/cleanup_test_data.py`），再重新執行 §5.1 → §5.2 → §5.3，驗證**上傳後自動處理**即能產生向量與圖譜。

---

**補跑僅作故障恢復參考**（生產／維運情境）：若在**非測試**環境中，已確定 Worker、Redis 正常，僅因先前中斷導致部分檔案未處理，可視需要執行 `reprocess_ka_agent_knowledge.py` 或對單檔呼叫 `POST /api/v1/files/{file_id}/regenerate`（`type`: `vector` | `graph` | `full`）。**測試流程不包含此步驟**。

---

## 9. 檢查報告：核心代碼一致性與 file_metadata KA 屬性

### 9.1 核心代碼是否一致？

**結論：一致。**

依 [上傳的功能架構說明-v4.0](../文件上傳向量圖譜/上傳的功能架構說明-v4.0.md) 與 [KA-Agent-規格書](./KA-Agent-規格書.md)：

- **前端上傳**與 **KA-Agent 上架** 皆經 `POST /api/v1/files/v2/upload`。
- 上傳 API 同樣會入隊 `process_file_chunking_and_vectorization_task`（`file_processing` 隊列），由 **同一** `process_file_chunking_and_vectorization` 執行：分塊 → 向量化（Qdrant）→ 圖譜提取 → **知識資產編碼**（Ontology 對齊、KNW-Code 生成）→ 寫入 `file_metadata` 的 KA 屬性。
- 上架腳本 `upload_ka_agent_knowledge.py` 呼叫的即 v2 upload，**與前端同一套核心代碼**。差異僅在 `task_id=KA-Agent`、`user_id=systemAdmin`，不影響 pipeline 邏輯。

### 9.2 為何 KA-Agent 上架沒有向量、圖譜？

**原因：pipeline 未跑，不是代碼分岐。**

- 分塊、向量化、圖譜提取在 **RQ Worker** 內執行；上傳 API 僅負責入隊。
- 若 **Worker 未運行** 或 **入隊失敗**（如 Redis 連線、`rq` 未安裝），任務不會被消費，自然沒有 Qdrant 向量與圖譜。
- 處理方式見 **§8 故障排除**：啟動 Worker、必要時執行 `reprocess_ka_agent_knowledge.py` 補跑。

### 9.3 為何 file_metadata 沒有 KA 核心屬性？

**KA 屬性只在「知識資產編碼」階段寫入；編碼在 pipeline 成功後才執行。**

- 寫入位置：`api/routers/file_upload.py` 的 `_encode_knowledge_asset_async`，於 `process_file_chunking_and_vectorization` **完成** 分塊／向量／圖譜後，若 `overall_status in ("completed", "partial_completed")` 時呼叫。
- 編碼服務 `KnowledgeAssetEncodingService.encode_file` 產出 `knw_code`、`ka_id`、`domain`、`major`、`lifecycle_state`、`version`，並經 `FileMetadataService.update` 寫回 `file_metadata`。

**根因（已修復，2026-01-25）**：原先以 `asyncio.create_task` 非阻塞觸發編碼。RQ Worker 以 `loop.run_until_complete(process_file_chunking_and_vectorization(...))` 執行，主協程結束後立即 `loop.close()`，**未完成的 `create_task` 編碼任務被取消**，故 KA 屬性從未寫入。  
**修復**：改為 `await _encode_knowledge_asset_async(...)`，確保編碼完成後主協程才返回，loop 關閉前 KA 已寫入 `file_metadata`。

- **Pipeline 未跑** → 無編碼 → `file_metadata` 的 KA 欄位保持未寫入；與「沒有向量、圖譜」同根因。**Pipeline 有跑但編碼未 await**（已修復）→ 同上。

### 9.4 file_metadata 的 KA 相關欄位與現狀

| 欄位 | 說明 | 目前寫入處 |
|------|------|------------|
| `knw_code` | 檔案編碼（KNW-Code） | `_encode_knowledge_asset_async` |
| `ka_id` | 知識資產邏輯 ID | 同上 |
| `domain` | 領域（對標 Ontology） | 同上 |
| `major` | 專業層（對標 Ontology） | 同上 |
| `lifecycle_state` | 生命週期狀態 | 同上 |
| `version` | SemVer 版本號 | 同上 |
| `vector_refs` | 向量引用（如 Qdrant collection） | `_encode_knowledge_asset_async`（pipeline 傳入） |
| `graph_refs` | 圖譜引用（entities/relations） | 同上 |

- **`vector_refs` / `graph_refs`**：pipeline 完成向量化／圖譜提取後，將 `collection_name`（Qdrant）與 `entities` / `relations`（ArangoDB 圖譜 collections）傳入 `_encode_knowledge_asset_async`，一併寫入 `file_metadata`。

### 9.5 小結與建議

1. **核心代碼一致**：前端上傳與 KA-Agent 上架共用同一 v2 upload → 同一 RQ 任務 → 同一處理 pipeline。
2. **無向量／圖譜／KA 屬性**：均因 **pipeline 未執行**（Worker／入隊問題）。修正後跑完 pipeline（含補跑），即可產生向量、圖譜並寫入 KA 屬性。
3. **已實作**：pipeline 在編碼階段已將 `vector_refs`（Qdrant collection）、`graph_refs`（entities/relations）寫入 `file_metadata`。

---

## 10. 測試期間常用腳本：Cleanup（清除測試資料）

`scripts/` 內有多個 cleanup 腳本，**本段測試期間**建議以以下兩個為主：

### 10.1 `scripts/complete_cleanup.py` — 全量清除

**用途**：清除 ArangoDB、Qdrant、SeaweedFS 測試資料，並給出前端 localStorage 清除指引。

| 清除項目 | 說明 |
|----------|------|
| ArangoDB | `user_tasks`（保留 systemAdmin 預設）、`file_metadata`（保留必要系統檔）、`entities`、`relations`、fileTree 緩存 |
| Qdrant | 所有 collections |
| SeaweedFS | 測試用文件 |
| 前端 | 僅輸出清除 localStorage 的 JavaScript 片段，需自行在瀏覽器 Console 執行 |

**用法**：

```bash
python scripts/complete_cleanup.py
```

執行後依提示在瀏覽器執行 localStorage 清除並強制刷新（Ctrl+F5）。

---

### 10.2 `scripts/cleanup_test_data.py` — 依任務清除（推薦用於 KA-Agent）

**用途**：依 `task_id` 清除該任務的 ArangoDB、Qdrant（對應 file_ids）、SeaweedFS。支援 `--dry-run`、`--yes`。

| 清除項目 | 說明 |
|----------|------|
| ArangoDB | `user_tasks`、`file_metadata`、`entities`、`relations` 中 `task_id == TASK_ID` 的記錄 |
| Qdrant | 依該任務的 `file_metadata` 取得 `file_id`，刪除對應 collections |
| SeaweedFS | `/{bucket}/tasks/{TASK_ID}/` 下文件 |

**任務 ID**：由環境變數 `TEST_TASK_ID` 決定，默認 `SystemDocs`。**清除 KA-Agent 測試資料**時設為 `KA-Agent`。

**用法**：

```bash
# 預覽（不實際刪除）
TEST_TASK_ID=KA-Agent python3 scripts/cleanup_test_data.py --dry-run

# 確認後執行（會提示確認）
TEST_TASK_ID=KA-Agent python3 scripts/cleanup_test_data.py

# 跳過確認直接執行
TEST_TASK_ID=KA-Agent python3 scripts/cleanup_test_data.py --yes
```

---

### 10.3 其他 cleanup 腳本（必要時參考）

| 腳本 | 用途 |
|------|------|
| `cleanup_all_data.py` | 全量清除 ArangoDB、Qdrant、SeaweedFS、本地檔；支援 `--force` |
| `cleanup_all.py` | 精簡版全量清除（ArangoDB、Qdrant、SeaweedFS） |
| `cleanup_test_files.py` | 依 `--file-ids`、`--filename-pattern` 或 `--clean-all-test-files` 清理 |
| `cleanup_user_all_data.py` | 依 `user_id` 清理該使用者所有資料 |
| `clear_rq_jobs.py` | 清理 RQ 隊列中的任務（如 `file_processing`、`vectorization`、`kg_extraction`） |
| `cleanup_seaweedfs.py` | 僅清理 SeaweedFS（支援 `--prefix`、`--task-id` 等） |

**建議**：清除 **KA-Agent 測試資料** 時優先使用 `cleanup_test_data.py`（`TEST_TASK_ID=KA-Agent`）；若要**整機重置**再使用 `complete_cleanup.py` 或 `cleanup_all_data.py`。

### 10.4 修正說明（2026-01-25）

**問題**：原 `cleanup_test_data.py` 的 entities/relations 清理邏輯有誤，使用 `task_id` 過濾，但 entities/relations 沒有 `task_id` 欄位。

**修正**：
- **entities/relations 清理**：改為先從 `file_metadata` 取得該 `task_id` 的所有 `file_id`，然後過濾 entities/relations 中 `file_id` 或 `file_ids` 包含這些 `file_id` 的記錄。
- **AQL 查詢**：
  ```aql
  FOR e IN entities
  FILTER e.file_id IN @file_ids OR (
      e.file_ids != null AND LENGTH(INTERSECTION(e.file_ids, @file_ids)) > 0
  )
  RETURN e
  ```
- **清理範圍確認**：
  - ✅ **ArangoDB**：`user_tasks`（`task_id="KA-Agent"`）、`file_metadata`（`task_id="KA-Agent"`）、`entities`/`relations`（根據 `file_id` 過濾）
  - ✅ **Qdrant**：根據 `file_metadata` 取得的 `file_id` 刪除對應 collections（`file_{file_id}`）
  - ✅ **SeaweedFS**：`/{bucket}/tasks/KA-Agent/` 目錄下的文件

---

## 11. 測試記錄（按輪次記錄）

每輪測試依 **§1.2 驗收目標** 執行並記錄結果；後續輪次於本節追加。

**說明**：**正確測試流程為 Ontology → 上架 → 驗收**，**不含補跑**。若出現「有檔案但無向量／圖譜」，應**定位根因、修復、清掉測試資料、重跑完整流程**。下述第 1、2 輪曾使用補跑僅為當時除錯作法；後續輪次以修復根因與重測為準。

### 第 1 輪（2026-01-25）

**執行內容**

| 步驟 | 指令 / 操作 | 結果 |
|------|-------------|------|
| 1. 導入 Ontology | `python scripts/import_ka_agent_ontology.py` | ✅ 成功（Domain + Major 寫入 ArangoDB） |
| 2. 上架知識庫 | `python scripts/upload_ka_agent_knowledge.py --api-base http://localhost:8000` | ✅ 成功（5 / 5 檔案上傳） |
| （曾嘗試補跑） | `reprocess_ka_agent_knowledge.py` | ❌ API 回報 `RQ is not installed`，補跑 0 / 5 |

**驗收結果（對應 §1.2）**

| # | 驗收目標 | 結果 | 備註 |
|---|----------|------|------|
| **1** | systemAdmin 登錄，前端能看到「KA-Agent」任務 | ✅ 通過 | `GET /api/v1/user-tasks` 含 KA-Agent 任務 |
| **2** | 任務文件區能看到知識文件，並能查看向量及圖譜 | ⚠️ 部分 | 文件可見（5 筆）；向量／圖譜未產生（`vector_count`、`kg_status` 皆為 null） |
| **3** | Qdrant、SeaweedFS Dashboard 能看到資料 | ⚠️ 部分 | Qdrant 無本輪 `file_id`；SeaweedFS 可連。本輪上傳未經 pipeline，故無對應向量。 |

**本輪結論**

- 上架與任務／文件可見性正常；**向量與圖譜未產生** 係因 **API 環境未安裝 `rq`**，入隊失敗，Pipeline 未執行。
- **正確後續**：於 API 環境 `pip install rq`，啟動 RQ Worker，**清掉測試資料、重跑完整流程**（Ontology → 上架 → 驗收），不以補跑代替。

---

### 第 2 輪（2026-01-25 22:23 UTC+8）

**執行內容**

| 步驟 | 指令 / 操作 | 結果 |
|------|-------------|------|
| 1. 導入 Ontology | `python scripts/import_ka_agent_ontology.py` | ✅ 成功（Domain + Major 寫入 ArangoDB） |
| 2. 上架知識庫 | `python scripts/upload_ka_agent_knowledge.py --api-base http://localhost:8000` | ✅ 成功（5 / 5 檔案上傳） |
| （曾嘗試補跑） | `reprocess_ka_agent_knowledge.py` | ⚠️ 已提交 5 個 job_id，但處理狀態仍為 null |

**驗收結果（對應 §1.2）**

| # | 驗收目標 | 結果 | 備註 |
|---|----------|------|------|
| **1** | systemAdmin 登錄，前端能看到「KA-Agent」任務 | ✅ 通過 | `GET /api/v1/files?task_id=KA-Agent` 回傳 5 筆文件 |
| **2** | 任務文件區能看到知識文件，並能查看向量及圖譜 | ❌ 失敗 | 文件可見（5 筆）；`vector_count`、`kg_status` 皆為 null |
| **3** | Qdrant、SeaweedFS Dashboard 能看到資料 | ⚠️ 部分 | **SeaweedFS**：✅ 5 個文件；**Qdrant**：❌ 無本輪 `file_id` |

**問題定位**

- **RQ Worker**：在運行，監聽 `file_processing`、`vectorization`、`kg_extraction`
- **處理狀態**：等待後仍為 null；Worker 日誌未見 `process_file_chunking_and_vectorization_task` 執行記錄
- **可能原因**：任務未達 Worker、處理時出錯未記錄、Worker 配置／依賴問題等

**本輪結論**

- 上架與 SeaweedFS 存儲正常；**自動處理未完成**，向量與圖譜未產生。
- **正確後續**：**定位根因**（RQ Dashboard、Worker 日誌、API 入隊日誌等）→ **修復** → **清掉測試資料** → **重跑完整流程**（Ontology → 上架 → 驗收），不以補跑代替。
