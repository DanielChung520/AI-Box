# Data Agent è¦æ ¼æ›¸

**ç‰ˆæœ¬**ï¼š2.0
**å‰µå»ºæ—¥æœŸ**ï¼š2026-01-13
**å‰µå»ºäºº**ï¼šDaniel Chung
**æœ€å¾Œä¿®æ”¹æ—¥æœŸ**ï¼š2026-01-13

> **ğŸ“‹ ç›¸é—œæ–‡æª”**ï¼š
>
> - [AI-Box-Agent-æ¶æ§‹è¦æ ¼æ›¸.md](./AI-Box-Agent-æ¶æ§‹è¦æ ¼æ›¸.md) - Agent æ¶æ§‹ç¸½é«”è¨­è¨ˆ
> - [æ¨¡æ“¬-Datalake-è¦åŠƒæ›¸.md](./æ¨¡æ“¬-Datalake-è¦åŠƒæ›¸.md) - Datalake è¦åŠƒæ›¸ï¼ˆ**å¿…è®€**ï¼šäº†è§£æ•¸æ“šå­˜å„²æ¶æ§‹ï¼‰
> - [åº«ç®¡å“¡-Agent-è¦æ ¼æ›¸.md](./åº«ç®¡å“¡-Agent-è¦æ ¼æ›¸.md) - åº«ç®¡å“¡ Agent è¦æ ¼æ›¸ï¼ˆ**å¿…è®€**ï¼šäº†è§£æ¥­å‹™éœ€æ±‚ï¼‰
> - [Agent-é–‹ç™¼è¦ç¯„.md](./Agent-é–‹ç™¼è¦ç¯„.md) - Agent é–‹ç™¼æŒ‡å—
> - [Security-Agent-è¦æ ¼æ›¸.md](./Security-Agent-è¦æ ¼æ›¸.md) - Security Agent è¦æ ¼æ›¸ï¼ˆåƒè€ƒæ ¼å¼ï¼‰

---

## ç›®éŒ„

1. [æ¦‚è¿°](#1-æ¦‚è¿°)
2. [å·¥ä½œè·è²¬](#2-å·¥ä½œè·è²¬)
3. [æŒ‡ä»¤æ¥æ”¶èˆ‡éœ€æ±‚ç¢ºèª](#3-æŒ‡ä»¤æ¥æ”¶èˆ‡éœ€æ±‚ç¢ºèª)
4. [æŸ¥è©¢æŒ‡ä»¤è½‰æ›èˆ‡åŸ·è¡Œ](#4-æŸ¥è©¢æŒ‡ä»¤è½‰æ›èˆ‡åŸ·è¡Œ)
5. [æ•¸æ“šæª¢æŸ¥èˆ‡é©—è­‰](#5-æ•¸æ“šæª¢æŸ¥èˆ‡é©—è­‰)
6. [äº¤ä»˜æ¨™æº–](#6-äº¤ä»˜æ¨™æº–)
7. [å…¶ä»–åŠŸèƒ½](#7-å…¶ä»–åŠŸèƒ½)
8. [ä»£ç¢¼å¯¦ç¾è¦æ ¼](#8-ä»£ç¢¼å¯¦ç¾è¦æ ¼)
9. [èˆ‡å…¶ä»–çµ„ä»¶çš„å”ä½œ](#9-èˆ‡å…¶ä»–çµ„ä»¶çš„å”ä½œ)
10. [å¯¦ç¾è¨ˆåŠƒ](#10-å¯¦ç¾è¨ˆåŠƒ)
11. [æ¶æ§‹è¨­è¨ˆåŸå‰‡](#11-æ¶æ§‹è¨­è¨ˆåŸå‰‡)
12. [æ¸¬è©¦çµæœèˆ‡é©—è­‰](#12-æ¸¬è©¦çµæœèˆ‡é©—è­‰)

---

## 1. æ¦‚è¿°

### 1.1 å®šä½

**Data Agentï¼ˆæ•¸æ“šä»£ç†ï¼‰**æ˜¯ **Datalake ç³»çµ±çš„æ•¸æ“šç®¡ç†æœå‹™**ï¼Œä½œç‚ºå¤–éƒ¨ Agent è¨»å†Šåˆ° AI-Boxï¼Œè² è²¬ï¼š

- **æ•¸æ“šæŸ¥è©¢æœå‹™**ï¼šæä¾› Text-to-SQL è½‰æ›å’Œå®‰å…¨æŸ¥è©¢åŸ·è¡Œ
- **Datalake æ•¸æ“šè¨ªå•**ï¼šæŸ¥è©¢ SeaweedFS Datalake ä¸­çš„çµæ§‹åŒ–å’Œéçµæ§‹åŒ–æ•¸æ“š
- **æ•¸æ“šå­—å…¸ç®¡ç†**ï¼šç®¡ç†æ•¸æ“šå­—å…¸å®šç¾©ï¼Œæ”¯æŒæ•¸æ“šç™¼ç¾ï¼ˆ**å±¬æ–¼ Datalake è·è²¬**ï¼‰
- **Schema ç®¡ç†**ï¼šç®¡ç† JSON Schema å®šç¾©ï¼Œæ”¯æŒæ•¸æ“šé©—è­‰ï¼ˆ**å±¬æ–¼ Datalake è·è²¬**ï¼‰
- **å®‰å…¨æŸ¥è©¢é–˜é“**ï¼šæä¾› SQL æ³¨å…¥é˜²è­·ã€æ¬Šé™é©—è­‰ã€çµæœéæ¿¾

**é‡è¦åŸå‰‡**ï¼š

- âœ… **è·è²¬åˆ†é›¢**ï¼šData Agent å±¬æ–¼ Datalake ç³»çµ±ï¼Œä¸å±¬æ–¼ AI-Box
- âœ… **æ¶æ§‹æ¸…æ™°**ï¼šAI-Box å°ˆæ³¨æ–¼ AI æ“ä½œç³»çµ±åŠŸèƒ½ï¼ŒDatalake è² è²¬æ•¸æ“šç®¡ç†
- âœ… **å¤–éƒ¨æœå‹™**ï¼šData Agent ä½œç‚ºç¨ç«‹æœå‹™ï¼Œé€šé MCP Protocol èˆ‡ AI-Box é€šä¿¡

### 1.2 è¨­è¨ˆç›®æ¨™

1. **çµ±ä¸€æ•¸æ“šè¨ªå•æ¥å£**ï¼šç‚ºæ¥­å‹™ Agent æä¾›çµ±ä¸€çš„æ•¸æ“šæŸ¥è©¢æ¥å£
2. **å®‰å…¨å„ªå…ˆ**ï¼šæ‰€æœ‰æŸ¥è©¢éƒ½ç¶“éå®‰å…¨æª¢æŸ¥å’Œæ¬Šé™é©—è­‰
3. **å¤šæ•¸æ“šæºæ”¯æŒ**ï¼šæ”¯æŒå‚³çµ±æ•¸æ“šåº«ï¼ˆPostgreSQLã€MySQLï¼‰å’Œ Datalakeï¼ˆSeaweedFSï¼‰
4. **æ™ºèƒ½æŸ¥è©¢è½‰æ›**ï¼šæ”¯æŒè‡ªç„¶èªè¨€åˆ° SQL çš„è½‰æ›
5. **æ•¸æ“šè³ªé‡ä¿è­‰**ï¼šæä¾›æ•¸æ“šé©—è­‰å’Œ Schema æª¢æŸ¥
6. **è·è²¬åˆ†é›¢**ï¼šæ•¸æ“šæ¶æ§‹ç®¡ç†å±¬æ–¼ Datalakeï¼Œä¸å±¬æ–¼ AI-Box

### 1.3 æ¶æ§‹ä½ç½®

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Datalake Systemï¼ˆå¤–éƒ¨ç³»çµ±ï¼‰                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Data Agent Serviceï¼ˆç¨ç«‹æœå‹™ï¼Œç«¯å£ 8004ï¼‰         â”‚   â”‚
â”‚  â”‚  - æ¥æ”¶ä¸¦è§£ææŸ¥è©¢æŒ‡ä»¤                             â”‚   â”‚
â”‚  â”‚  - éœ€æ±‚ç¢ºèªèˆ‡æ¾„æ¸…                                 â”‚   â”‚
â”‚  â”‚  - æŸ¥è©¢è½‰æ›èˆ‡åŸ·è¡Œ                                 â”‚   â”‚
â”‚  â”‚  - æ•¸æ“šæª¢æŸ¥èˆ‡é©—è­‰                                 â”‚   â”‚
â”‚  â”‚  - æ•¸æ“šå­—å…¸ç®¡ç† âœ… å±¬æ–¼ Datalake                  â”‚   â”‚
â”‚  â”‚  - Schema ç®¡ç† âœ… å±¬æ–¼ Datalake                  â”‚   â”‚
â”‚  â”‚  - çµæœäº¤ä»˜                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  SeaweedFS å­˜å„²                                   â”‚   â”‚
â”‚  â”‚  - æ•¸æ“šå­˜å„²ï¼ˆbucket-datalake-assetsï¼‰             â”‚   â”‚
â”‚  â”‚  - æ•¸æ“šå­—å…¸ï¼ˆbucket-datalake-dictionaryï¼‰         â”‚   â”‚
â”‚  â”‚  - Schemaï¼ˆbucket-datalake-schemaï¼‰              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“ MCP Protocol
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AI-Boxï¼ˆAI æ“ä½œç³»çµ±ï¼‰                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ç¬¬ä¸€å±¤ï¼šå”èª¿å±¤ï¼ˆAgent Orchestratorï¼‰              â”‚   â”‚
â”‚  â”‚  - æ¥æ”¶æ¥­å‹™ Agent çš„æ•¸æ“šæŸ¥è©¢è«‹æ±‚                  â”‚   â”‚
â”‚  â”‚  - é€šé MCP Client èª¿ç”¨å¤–éƒ¨ Data Agent            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Agent Registry                                  â”‚   â”‚
â”‚  â”‚  - è¨»å†Šå¤–éƒ¨ Data Agent                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  æ¥­å‹™ Agentï¼ˆåº«ç®¡å“¡ Agent ç­‰ï¼‰                   â”‚   â”‚
â”‚  â”‚  - æ¥­å‹™é‚è¼¯è™•ç†                                   â”‚   â”‚
â”‚  â”‚  - é€šé Orchestrator èª¿ç”¨ Data Agent             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. å·¥ä½œè·è²¬

### 2.1 æ ¸å¿ƒè·è²¬

Data Agent ä½œç‚º **Datalake ç³»çµ±çš„æ•¸æ“šç®¡ç†æœå‹™**ï¼Œè² è²¬ä»¥ä¸‹æ ¸å¿ƒè·è²¬ï¼š

#### 2.1.1 æ•¸æ“šæŸ¥è©¢æœå‹™

1. **Text-to-SQL è½‰æ›**
   - å°‡è‡ªç„¶èªè¨€æŸ¥è©¢è½‰æ›ç‚º SQL æŸ¥è©¢
   - æ”¯æŒå¤šç¨®æ•¸æ“šåº«æ–¹è¨€ï¼ˆPostgreSQLã€MySQLã€SQLiteï¼‰
   - æä¾› Schema ä¿¡æ¯ä»¥æå‡è½‰æ›æº–ç¢ºåº¦
   - ç”Ÿæˆåƒæ•¸åŒ–æŸ¥è©¢ä»¥é˜²æ­¢ SQL æ³¨å…¥

2. **å®‰å…¨æŸ¥è©¢åŸ·è¡Œ**
   - åŸ·è¡Œç¶“éé©—è­‰çš„ SQL æŸ¥è©¢
   - æä¾›æŸ¥è©¢è¶…æ™‚å’Œçµæœè¡Œæ•¸é™åˆ¶
   - æ”¯æŒå¤šç§Ÿæˆ¶æ•¸æ“šéš”é›¢
   - è¨˜éŒ„æŸ¥è©¢æ—¥èªŒç”¨æ–¼å¯©è¨ˆ

3. **æŸ¥è©¢é©—è­‰**
   - SQL æ³¨å…¥æª¢æ¸¬
   - å±éšªæ“ä½œæª¢æ¸¬ï¼ˆDROPã€DELETEã€TRUNCATE ç­‰ï¼‰
   - åƒæ•¸åŒ–æŸ¥è©¢å¼·åˆ¶
   - æ¬Šé™é©—è­‰

#### 2.1.2 Datalake æ•¸æ“šè¨ªå•

1. **çµæ§‹åŒ–æ•¸æ“šæŸ¥è©¢**
   - æŸ¥è©¢ç‰©æ–™æ•¸æ“šï¼ˆ`bucket-datalake-assets/parts/`ï¼‰
   - æŸ¥è©¢åº«å­˜æ•¸æ“šï¼ˆ`bucket-datalake-assets/stock/`ï¼‰
   - æŸ¥è©¢åº«å­˜æ­·å²è¨˜éŒ„ï¼ˆ`bucket-datalake-assets/stock_history/`ï¼‰
   - æ”¯æŒç²¾ç¢ºæŸ¥è©¢å’Œæ¨¡ç³ŠæŸ¥è©¢

2. **æ•¸æ“šå­—å…¸ç®¡ç†**ï¼ˆ**å±¬æ–¼ Datalake è·è²¬**ï¼‰
   - å‰µå»ºã€æ›´æ–°ã€æŸ¥è©¢æ•¸æ“šå­—å…¸
   - å­˜å„²åœ¨ `bucket-datalake-dictionary/`
   - æä¾›æ•¸æ“šçµæ§‹æ–‡æª”èªªæ˜
   - æ”¯æŒç‰ˆæœ¬æ§åˆ¶
   - **èªªæ˜**ï¼šæ•¸æ“šæ¶æ§‹ç®¡ç†æ˜¯ Datalake çš„æ ¸å¿ƒè·è²¬ï¼Œä¸å±¬æ–¼ AI-Box

3. **Schema ç®¡ç†**ï¼ˆ**å±¬æ–¼ Datalake è·è²¬**ï¼‰
   - å‰µå»ºã€æ›´æ–°ã€æŸ¥è©¢ JSON Schema
   - å­˜å„²åœ¨ `bucket-datalake-schema/`
   - æ”¯æŒæ•¸æ“šé©—è­‰
   - æ”¯æŒç‰ˆæœ¬æ§åˆ¶
   - **èªªæ˜**ï¼šSchema ç®¡ç†æ˜¯ Datalake çš„æ ¸å¿ƒè·è²¬ï¼Œä¸å±¬æ–¼ AI-Box

4. **æ•¸æ“šé©—è­‰**
   - æ ¹æ“š Schema é©—è­‰æ•¸æ“šçµæ§‹
   - æª¢æŸ¥å¿…å¡«å­—æ®µ
   - é©—è­‰æ•¸æ“šé¡å‹
   - æä¾›é©—è­‰å ±å‘Š

#### 2.1.3 å®‰å…¨èˆ‡åˆè¦

1. **SQL æ³¨å…¥é˜²è­·**
   - æª¢æ¸¬å¸¸è¦‹çš„ SQL æ³¨å…¥æ¨¡å¼
   - å¼·åˆ¶ä½¿ç”¨åƒæ•¸åŒ–æŸ¥è©¢
   - éæ¿¾å±éšªé—œéµå­—

2. **æ¬Šé™é©—è­‰**
   - æª¢æŸ¥ç”¨æˆ¶æŸ¥è©¢æ¬Šé™
   - é©—è­‰ç§Ÿæˆ¶æ•¸æ“šéš”é›¢
   - è¨˜éŒ„æ¬Šé™æª¢æŸ¥æ—¥èªŒ

3. **çµæœéæ¿¾**
   - é™åˆ¶è¿”å›è¡Œæ•¸
   - æ•æ„Ÿæ•¸æ“šè„«æ•
   - çµæœæ ¼å¼æ¨™æº–åŒ–

### 2.2 è·è²¬é‚Šç•Œ

**Data Agent è² è²¬**ï¼š

- âœ… æ•¸æ“šæŸ¥è©¢å’Œè½‰æ›
- âœ… æŸ¥è©¢å®‰å…¨é©—è­‰
- âœ… æ•¸æ“šå­—å…¸å’Œ Schema ç®¡ç†
- âœ… æŸ¥è©¢çµæœæ ¼å¼åŒ–

**Data Agent ä¸è² è²¬**ï¼š

- âŒ æ¥­å‹™é‚è¼¯è™•ç†ï¼ˆç”±æ¥­å‹™ Agent è² è²¬ï¼‰
- âŒ æ•¸æ“šä¿®æ”¹æ“ä½œï¼ˆINSERTã€UPDATEã€DELETEï¼‰
- âŒ æ•¸æ“šåº«çµæ§‹ç®¡ç†ï¼ˆCREATEã€ALTERã€DROPï¼‰
- âŒ æ•¸æ“šå‚™ä»½å’Œæ¢å¾©

---

## 3. æŒ‡ä»¤æ¥æ”¶èˆ‡éœ€æ±‚ç¢ºèª

### 3.1 æŒ‡ä»¤æ¥æ”¶æµç¨‹

Data Agent é€šé `AgentServiceProtocol` æ¥å£æ¥æ”¶æŒ‡ä»¤ï¼š

```python
async def execute(self, request: AgentServiceRequest) -> AgentServiceResponse:
    """
    åŸ·è¡Œæ•¸æ“šæŸ¥è©¢ä»»å‹™

    Args:
        request: Agent æœå‹™è«‹æ±‚ï¼ŒåŒ…å«ï¼š
            - task_id: ä»»å‹™ ID
            - task_data: ä»»å‹™æ•¸æ“šï¼ˆDataAgentRequestï¼‰
            - metadata: å…ƒæ•¸æ“šï¼ˆç”¨æˆ¶ä¿¡æ¯ã€ç§Ÿæˆ¶ä¿¡æ¯ç­‰ï¼‰

    Returns:
        Agent æœå‹™éŸ¿æ‡‰ï¼ŒåŒ…å«ï¼š
            - task_id: ä»»å‹™ ID
            - status: ä»»å‹™ç‹€æ…‹ï¼ˆcompleted/failed/errorï¼‰
            - result: åŸ·è¡Œçµæœï¼ˆDataAgentResponseï¼‰
            - error: éŒ¯èª¤ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            - metadata: å…ƒæ•¸æ“š
    """
```

### 3.2 æŒ‡ä»¤è§£æèˆ‡é©—è­‰

#### 3.2.1 è«‹æ±‚æ¨¡å‹è§£æ

```python
class DataAgentRequest(BaseModel):
    """Data Agent è«‹æ±‚æ¨¡å‹"""

    # å¿…éœ€å­—æ®µ
    action: str  # æ“ä½œé¡å‹

    # Text-to-SQL åƒæ•¸
    natural_language: Optional[str] = None
    database_type: Optional[str] = "postgresql"
    schema_info: Optional[Dict[str, Any]] = None

    # æŸ¥è©¢åŸ·è¡Œåƒæ•¸
    sql_query: Optional[str] = None
    connection_string: Optional[str] = None

    # Datalake æŸ¥è©¢åƒæ•¸
    bucket: Optional[str] = None
    key: Optional[str] = None
    query_type: Optional[str] = "exact"  # exact/fuzzy
    filters: Optional[Dict[str, Any]] = None

    # é€šç”¨åƒæ•¸
    user_id: Optional[str] = None
    tenant_id: Optional[str] = None
    timeout: Optional[int] = 30
    max_rows: Optional[int] = 1000
```

#### 3.2.2 æŒ‡ä»¤é©—è­‰æ­¥é©Ÿ

**æ­¥é©Ÿ 1ï¼šåŸºæœ¬é©—è­‰**

```python
def _validate_request(self, request: DataAgentRequest) -> ValidationResult:
    """é©—è­‰è«‹æ±‚çš„åŸºæœ¬å®Œæ•´æ€§"""

    # 1. æª¢æŸ¥ action æ˜¯å¦æœ‰æ•ˆ
    valid_actions = [
        "text_to_sql",
        "execute_query",
        "validate_query",
        "get_schema",
        "query_datalake",
        "create_dictionary",
        "update_dictionary",
        "get_dictionary",
        "create_schema",
        "update_schema",
        "validate_data",
    ]

    if request.action not in valid_actions:
        return ValidationResult(
            valid=False,
            error=f"Invalid action: {request.action}",
            suggestions=[f"Use one of: {', '.join(valid_actions)}"]
        )

    # 2. æª¢æŸ¥å¿…éœ€åƒæ•¸
    if request.action == "text_to_sql" and not request.natural_language:
        return ValidationResult(
            valid=False,
            error="natural_language is required for text_to_sql action",
            suggestions=["Provide natural_language parameter"]
        )

    if request.action == "execute_query" and not request.sql_query:
        return ValidationResult(
            valid=False,
            error="sql_query is required for execute_query action",
            suggestions=["Provide sql_query parameter"]
        )

    if request.action == "query_datalake":
        if not request.bucket or not request.key:
            return ValidationResult(
                valid=False,
                error="bucket and key are required for query_datalake action",
                suggestions=["Provide bucket and key parameters"]
            )

    return ValidationResult(valid=True)
```

**æ­¥é©Ÿ 2ï¼šéœ€æ±‚æ¾„æ¸…**

ç•¶æŒ‡ä»¤ä¸æ˜ç¢ºæ™‚ï¼ŒData Agent éœ€è¦ä¸»å‹•æ¾„æ¸…ï¼š

```python
async def _clarify_requirements(
    self,
    request: DataAgentRequest
) -> Optional[ClarificationRequest]:
    """éœ€æ±‚æ¾„æ¸…é‚è¼¯"""

    clarifications = []

    # 1. Text-to-SQL éœ€æ±‚æ¾„æ¸…
    if request.action == "text_to_sql":
        if not request.schema_info:
            clarifications.append({
                "field": "schema_info",
                "question": "æ˜¯å¦éœ€è¦æä¾›æ•¸æ“šåº« Schema ä¿¡æ¯ä»¥æé«˜è½‰æ›æº–ç¢ºåº¦ï¼Ÿ",
                "required": False,
            })

        if not request.database_type:
            clarifications.append({
                "field": "database_type",
                "question": "ç›®æ¨™æ•¸æ“šåº«é¡å‹æ˜¯ä»€éº¼ï¼Ÿï¼ˆpostgresql/mysql/sqliteï¼‰",
                "required": True,
                "default": "postgresql",
            })

    # 2. Datalake æŸ¥è©¢éœ€æ±‚æ¾„æ¸…
    if request.action == "query_datalake":
        if not request.query_type:
            clarifications.append({
                "field": "query_type",
                "question": "æŸ¥è©¢é¡å‹æ˜¯ä»€éº¼ï¼Ÿï¼ˆexact: ç²¾ç¢ºåŒ¹é… / fuzzy: æ¨¡ç³ŠæŸ¥è©¢ï¼‰",
                "required": False,
                "default": "exact",
            })

        if not request.filters:
            clarifications.append({
                "field": "filters",
                "question": "æ˜¯å¦éœ€è¦æ·»åŠ æŸ¥è©¢éæ¿¾æ¢ä»¶ï¼Ÿ",
                "required": False,
            })

    # 3. æŸ¥è©¢åŸ·è¡Œéœ€æ±‚æ¾„æ¸…
    if request.action == "execute_query":
        if not request.connection_string:
            clarifications.append({
                "field": "connection_string",
                "question": "æ•¸æ“šåº«é€£æ¥å­—ç¬¦ä¸²æ˜¯ä»€éº¼ï¼Ÿ",
                "required": True,
            })

        if request.max_rows is None or request.max_rows > 10000:
            clarifications.append({
                "field": "max_rows",
                "question": f"æœ€å¤§è¿”å›è¡Œæ•¸æ˜¯å¤šå°‘ï¼Ÿï¼ˆç•¶å‰: {request.max_rows}ï¼Œå»ºè­°: <= 1000ï¼‰",
                "required": False,
                "default": 1000,
            })

    if clarifications:
        return ClarificationRequest(
            clarifications=clarifications,
            message="éœ€è¦ä»¥ä¸‹ä¿¡æ¯ä»¥å®ŒæˆæŸ¥è©¢ï¼š"
        )

    return None
```

**æ­¥é©Ÿ 3ï¼šéœ€æ±‚ç¢ºèª**

```python
async def _confirm_requirements(
    self,
    request: DataAgentRequest
) -> ConfirmationResult:
    """éœ€æ±‚ç¢ºèªé‚è¼¯"""

    confirmation = {
        "action": request.action,
        "parameters": {},
        "warnings": [],
        "suggestions": [],
    }

    # 1. ç¢ºèªæŸ¥è©¢é¡å‹
    if request.action == "text_to_sql":
        confirmation["parameters"] = {
            "natural_language": request.natural_language,
            "database_type": request.database_type or "postgresql",
            "has_schema_info": request.schema_info is not None,
        }
        if not request.schema_info:
            confirmation["warnings"].append(
                "æœªæä¾› Schema ä¿¡æ¯ï¼Œè½‰æ›æº–ç¢ºåº¦å¯èƒ½é™ä½"
            )
            confirmation["suggestions"].append(
                "å»ºè­°æä¾› schema_info ä»¥æé«˜è½‰æ›æº–ç¢ºåº¦"
            )

    # 2. ç¢ºèªæŸ¥è©¢åŸ·è¡Œåƒæ•¸
    elif request.action == "execute_query":
        confirmation["parameters"] = {
            "sql_query": request.sql_query[:100] + "..." if len(request.sql_query) > 100 else request.sql_query,
            "timeout": request.timeout or 30,
            "max_rows": request.max_rows or 1000,
            "has_connection_string": request.connection_string is not None,
        }
        if request.max_rows and request.max_rows > 1000:
            confirmation["warnings"].append(
                f"æœ€å¤§è¿”å›è¡Œæ•¸è¼ƒå¤§ï¼ˆ{request.max_rows}ï¼‰ï¼Œå¯èƒ½å½±éŸ¿æ€§èƒ½"
            )

    # 3. ç¢ºèª Datalake æŸ¥è©¢åƒæ•¸
    elif request.action == "query_datalake":
        confirmation["parameters"] = {
            "bucket": request.bucket,
            "key": request.key,
            "query_type": request.query_type or "exact",
            "has_filters": request.filters is not None,
        }

    return ConfirmationResult(**confirmation)
```

### 3.3 æŒ‡ä»¤è™•ç†æµç¨‹åœ–

```
æ¥æ”¶æŒ‡ä»¤ (AgentServiceRequest)
    â†“
è§£æè«‹æ±‚æ•¸æ“š â†’ DataAgentRequest
    â†“
åŸºæœ¬é©—è­‰
    â”œâ”€ é©—è­‰ action æ˜¯å¦æœ‰æ•ˆ
    â”œâ”€ é©—è­‰å¿…éœ€åƒæ•¸æ˜¯å¦å­˜åœ¨
    â””â”€ é©—è­‰åƒæ•¸é¡å‹æ˜¯å¦æ­£ç¢º
    â†“
éœ€æ±‚æ¾„æ¸…ï¼ˆå¦‚æœéœ€è¦ï¼‰
    â”œâ”€ æª¢æŸ¥ç¼ºå¤±çš„å¯é¸åƒæ•¸
    â”œâ”€ ç”Ÿæˆæ¾„æ¸…å•é¡Œ
    â””â”€ è¿”å› ClarificationRequest
    â†“
éœ€æ±‚ç¢ºèª
    â”œâ”€ ç”Ÿæˆç¢ºèªä¿¡æ¯
    â”œâ”€ é¡¯ç¤ºè­¦å‘Šå’Œå»ºè­°
    â””â”€ è¿”å› ConfirmationResult
    â†“
åŸ·è¡ŒæŸ¥è©¢ï¼ˆè¦‹ç¬¬ 4 ç« ï¼‰
```

---

## 4. æŸ¥è©¢æŒ‡ä»¤è½‰æ›èˆ‡åŸ·è¡Œ

### 4.1 Text-to-SQL è½‰æ›æµç¨‹

#### 4.1.1 è½‰æ›æ­¥é©Ÿ

**æ­¥é©Ÿ 1ï¼šæ§‹å»ºæç¤ºè©**

```python
def _build_prompt(
    self,
    natural_language: str,
    database_type: str,
    schema_info: Optional[Dict[str, Any]],
) -> str:
    """æ§‹å»º LLM æç¤ºè©"""

    prompt = f"""è«‹å°‡ä»¥ä¸‹è‡ªç„¶èªè¨€æŸ¥è©¢è½‰æ›ç‚º {database_type.upper()} SQL æŸ¥è©¢ã€‚

è‡ªç„¶èªè¨€æŸ¥è©¢ï¼š
{natural_language}

"""

    # æ·»åŠ  Schema ä¿¡æ¯ï¼ˆå¦‚æœæä¾›ï¼‰
    if schema_info:
        prompt += f"""æ•¸æ“šåº« Schema ä¿¡æ¯ï¼š
{self._format_schema_info(schema_info)}

"""

    prompt += """è¦æ±‚ï¼š
1. åªè¿”å› SQL æŸ¥è©¢èªå¥ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡‹
2. ä½¿ç”¨åƒæ•¸åŒ–æŸ¥è©¢ï¼ˆä½¿ç”¨ ? æˆ– $1, $2 ç­‰ä½”ä½ç¬¦ï¼‰
3. ç¢ºä¿ SQL èªæ³•æ­£ç¢º
4. åªä½¿ç”¨ SELECT æŸ¥è©¢ï¼ˆä¸å…è¨± DROPã€DELETEã€TRUNCATE ç­‰å±éšªæ“ä½œï¼‰
5. å¦‚æœæŸ¥è©¢æ¶‰åŠå¤šè¡¨ï¼Œä½¿ç”¨é©ç•¶çš„ JOIN
6. å¦‚æœæŸ¥è©¢éœ€è¦èšåˆï¼Œä½¿ç”¨é©ç•¶çš„ GROUP BY

SQL æŸ¥è©¢ï¼š"""

    return prompt
```

**æ­¥é©Ÿ 2ï¼šèª¿ç”¨ LLM ç”Ÿæˆ SQL**

```python
async def convert(
    self,
    natural_language: str,
    database_type: str = "postgresql",
    schema_info: Optional[Dict[str, Any]] = None,
    context: Optional[Dict[str, Any]] = None,
) -> Dict[str, Any]:
    """å°‡è‡ªç„¶èªè¨€è½‰æ›ç‚º SQL"""

    # 1. æ§‹å»ºæç¤ºè©
    prompt = self._build_prompt(natural_language, database_type, schema_info)

    # 2. èª¿ç”¨ LLM
    client = self._get_llm_client()
    result = await client.generate(
        prompt,
        temperature=0.3,  # è¼ƒä½æº«åº¦ä»¥ç²å¾—æ›´ç©©å®šçš„ SQL
        max_tokens=1000,
    )

    # 3. æå– SQL
    sql_text = result.get("text") or result.get("content", "")
    sql_query = self._extract_sql(sql_text)

    # 4. é©—è­‰å’Œå„ªåŒ–
    validated_sql, warnings = self._validate_sql(sql_query, database_type)

    # 5. æå–åƒæ•¸
    parameters = self._extract_parameters(validated_sql)

    # 6. è¨ˆç®—ç½®ä¿¡åº¦
    confidence = self._calculate_confidence(sql_query, natural_language)

    return {
        "sql_query": validated_sql,
        "parameters": parameters,
        "confidence": confidence,
        "explanation": self._generate_explanation(sql_query, natural_language),
        "warnings": warnings,
    }
```

**æ­¥é©Ÿ 3ï¼šSQL æå–èˆ‡é©—è­‰**

```python
def _extract_sql(self, text: str) -> str:
    """å¾ LLM è¼¸å‡ºä¸­æå– SQL æŸ¥è©¢"""

    # ç§»é™¤ä»£ç¢¼å¡Šæ¨™è¨˜
    text = re.sub(r"```sql\s*", "", text, flags=re.IGNORECASE)
    text = re.sub(r"```\s*", "", text)

    # æŸ¥æ‰¾ SQL é—œéµå­—
    sql_keywords = ["SELECT", "WITH", "INSERT", "UPDATE"]
    lines = text.split("\n")
    sql_lines = []

    in_sql = False
    for line in lines:
        line_upper = line.strip().upper()
        if any(line_upper.startswith(kw) for kw in sql_keywords):
            in_sql = True
        if in_sql:
            sql_lines.append(line)
            if line.strip().endswith(";"):
                break

    sql = "\n".join(sql_lines).strip()
    if not sql:
        sql = text.strip()

    # ç§»é™¤æœ«å°¾çš„åˆ†è™Ÿ
    if sql.endswith(";"):
        sql = sql[:-1]

    return sql

def _validate_sql(self, sql: str, database_type: str) -> tuple[str, List[str]]:
    """é©—è­‰å’Œå„ªåŒ– SQL"""

    warnings: List[str] = []
    validated_sql = sql

    # æª¢æŸ¥å±éšªæ“ä½œ
    dangerous_keywords = [
        "DROP", "DELETE", "TRUNCATE", "ALTER",
        "CREATE", "INSERT", "UPDATE", "GRANT", "REVOKE"
    ]
    sql_upper = sql.upper()
    for keyword in dangerous_keywords:
        if keyword in sql_upper:
            warnings.append(f"æª¢æ¸¬åˆ°å±éšªæ“ä½œé—œéµå­—: {keyword}")

    # æª¢æŸ¥ SQL æ³¨å…¥é¢¨éšª
    if "'" in sql or '"' in sql:
        if "?" not in sql and "$" not in sql:
            warnings.append("å»ºè­°ä½¿ç”¨åƒæ•¸åŒ–æŸ¥è©¢ä»¥é˜²æ­¢ SQL æ³¨å…¥")

    # åŸºæœ¬èªæ³•æª¢æŸ¥
    if not sql_upper.strip().startswith("SELECT"):
        warnings.append("åªå…è¨± SELECT æŸ¥è©¢")

    return validated_sql, warnings
```

### 4.2 æŸ¥è©¢åŸ·è¡Œæµç¨‹

#### 4.2.1 å‚³çµ±æ•¸æ“šåº«æŸ¥è©¢åŸ·è¡Œ

```python
async def execute_query(
    self,
    sql_query: str,
    connection_string: Optional[str] = None,
    timeout: int = 30,
    max_rows: int = 1000,
    user_id: Optional[str] = None,
    tenant_id: Optional[str] = None,
) -> Dict[str, Any]:
    """åŸ·è¡Œå®‰å…¨æŸ¥è©¢"""

    start_time = time.time()

    # 1. é©—è­‰æŸ¥è©¢
    validation = self.validate_query(sql_query, user_id=user_id, tenant_id=tenant_id)
    if not validation["valid"]:
        return {
            "success": False,
            "error": validation["error"],
            "details": validation.get("details", []),
        }

    # 2. æª¢æŸ¥æ¬Šé™
    permission_check = self.check_permissions(
        sql_query, user_id=user_id, tenant_id=tenant_id, connection_string=connection_string
    )
    if not permission_check["allowed"]:
        return {
            "success": False,
            "error": "Permission denied",
            "message": permission_check.get("message", ""),
        }

    # 3. åŸ·è¡ŒæŸ¥è©¢
    try:
        # é€£æ¥æ•¸æ“šåº«
        connection = self._get_connection(connection_string)

        # åŸ·è¡ŒæŸ¥è©¢ï¼ˆä½¿ç”¨åƒæ•¸åŒ–æŸ¥è©¢ï¼‰
        cursor = connection.cursor()
        cursor.execute(sql_query, timeout=timeout)

        # ç²å–çµæœ
        rows = cursor.fetchall()
        columns = [desc[0] for desc in cursor.description]

        # è½‰æ›ç‚ºå­—å…¸åˆ—è¡¨
        result_rows = [dict(zip(columns, row)) for row in rows]

        # éæ¿¾çµæœ
        filtered_rows = self.filter_results(result_rows, max_rows=max_rows)

        execution_time = time.time() - start_time

        return {
            "success": True,
            "rows": filtered_rows,
            "row_count": len(filtered_rows),
            "total_count": len(result_rows),
            "execution_time": execution_time,
            "warnings": validation.get("warnings", []),
            "metadata": {
                "query": sql_query,
                "timeout": timeout,
                "max_rows": max_rows,
            },
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "execution_time": time.time() - start_time,
        }
```

#### 4.2.2 Datalake æŸ¥è©¢åŸ·è¡Œ

```python
async def query_datalake(
    self,
    bucket: str,
    key: str,
    query_type: str = "exact",
    filters: Optional[Dict[str, Any]] = None,
    user_id: Optional[str] = None,
    tenant_id: Optional[str] = None,
) -> Dict[str, Any]:
    """æŸ¥è©¢ Datalake æ•¸æ“š"""

    try:
        # 1. ç²å– S3 å­˜å„²å¯¦ä¾‹
        storage = self._get_datalake_storage()

        # 2. æ ¹æ“šæŸ¥è©¢é¡å‹åŸ·è¡ŒæŸ¥è©¢
        if query_type == "exact":
            # ç²¾ç¢ºæŸ¥è©¢ï¼šç›´æ¥è®€å–æ–‡ä»¶
            result = await self._query_exact(storage, bucket, key)
        elif query_type == "fuzzy":
            # æ¨¡ç³ŠæŸ¥è©¢ï¼šåˆ—å‡ºç›®éŒ„ä¸¦éæ¿¾
            result = await self._query_fuzzy(storage, bucket, key, filters)
        else:
            return {
                "success": False,
                "error": f"Unsupported query_type: {query_type}",
            }

        # 3. æ‡‰ç”¨éæ¿¾æ¢ä»¶ï¼ˆå¦‚æœæä¾›ï¼‰
        if filters and result.get("success"):
            result["rows"] = self._apply_filters(result["rows"], filters)
            result["row_count"] = len(result["rows"])

        # 4. é©—è­‰æ•¸æ“šï¼ˆå¦‚æœæä¾› Schemaï¼‰
        if result.get("success"):
            schema = await self._get_schema_for_key(bucket, key)
            if schema:
                validation = self._validate_data_against_schema(
                    result["rows"], schema
                )
                result["validation"] = validation

        return result

    except Exception as e:
        self._logger.error(f"Datalake query failed: {e}")
        return {
            "success": False,
            "error": str(e),
        }

async def _query_exact(
    self,
    storage: S3FileStorage,
    bucket: str,
    key: str,
) -> Dict[str, Any]:
    """ç²¾ç¢ºæŸ¥è©¢ï¼šè®€å–å–®å€‹æ–‡ä»¶"""

    try:
        # å¾ S3 è®€å–æ–‡ä»¶
        content = storage.s3_client.get_object(Bucket=bucket, Key=key)
        data = json.loads(content['Body'].read().decode('utf-8'))

        # å¦‚æœæ˜¯å–®å€‹å°è±¡ï¼Œè½‰æ›ç‚ºåˆ—è¡¨
        if isinstance(data, dict):
            data = [data]

        return {
            "success": True,
            "rows": data,
            "row_count": len(data),
            "query_type": "exact",
            "bucket": bucket,
            "key": key,
        }

    except storage.s3_client.exceptions.NoSuchKey:
        return {
            "success": False,
            "error": f"File not found: {bucket}/{key}",
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
        }

async def _query_fuzzy(
    self,
    storage: S3FileStorage,
    bucket: str,
    key_prefix: str,
    filters: Optional[Dict[str, Any]],
) -> Dict[str, Any]:
    """æ¨¡ç³ŠæŸ¥è©¢ï¼šåˆ—å‡ºç›®éŒ„ä¸¦éæ¿¾"""

    try:
        # åˆ—å‡ºç›®éŒ„ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
        objects = storage.s3_client.list_objects_v2(
            Bucket=bucket,
            Prefix=key_prefix,
        )

        all_rows = []
        for obj in objects.get('Contents', []):
            key = obj['Key']
            # è®€å–æ–‡ä»¶
            content = storage.s3_client.get_object(Bucket=bucket, Key=key)
            data = json.loads(content['Body'].read().decode('utf-8'))

            # å¦‚æœæ˜¯ JSONL æ–‡ä»¶ï¼Œé€è¡Œè§£æ
            if key.endswith('.jsonl'):
                for line in content['Body'].read().decode('utf-8').split('\n'):
                    if line.strip():
                        all_rows.append(json.loads(line))
            else:
                if isinstance(data, dict):
                    all_rows.append(data)
                elif isinstance(data, list):
                    all_rows.extend(data)

        return {
            "success": True,
            "rows": all_rows,
            "row_count": len(all_rows),
            "query_type": "fuzzy",
            "bucket": bucket,
            "key_prefix": key_prefix,
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
        }
```

### 4.3 æŸ¥è©¢è½‰æ›æµç¨‹åœ–

```
æ¥æ”¶æŸ¥è©¢æŒ‡ä»¤
    â†“
åˆ¤æ–·æŸ¥è©¢é¡å‹
    â”œâ”€ text_to_sql â†’ Text-to-SQL è½‰æ›æµç¨‹
    â”œâ”€ execute_query â†’ å‚³çµ±æ•¸æ“šåº«æŸ¥è©¢æµç¨‹
    â””â”€ query_datalake â†’ Datalake æŸ¥è©¢æµç¨‹
    â†“
Text-to-SQL è½‰æ›æµç¨‹ï¼š
    æ§‹å»ºæç¤ºè©
        â†“
    èª¿ç”¨ LLM ç”Ÿæˆ SQL
        â†“
    æå– SQL æŸ¥è©¢
        â†“
    é©—è­‰ SQLï¼ˆèªæ³•ã€å®‰å…¨æ€§ï¼‰
        â†“
    æå–åƒæ•¸
        â†“
    è¨ˆç®—ç½®ä¿¡åº¦
        â†“
    è¿”å›è½‰æ›çµæœ
    â†“
å‚³çµ±æ•¸æ“šåº«æŸ¥è©¢æµç¨‹ï¼š
    é©—è­‰æŸ¥è©¢ï¼ˆSQL æ³¨å…¥ã€å±éšªæ“ä½œï¼‰
        â†“
    æª¢æŸ¥æ¬Šé™
        â†“
    é€£æ¥æ•¸æ“šåº«
        â†“
    åŸ·è¡ŒæŸ¥è©¢ï¼ˆåƒæ•¸åŒ–ï¼‰
        â†“
    ç²å–çµæœ
        â†“
    éæ¿¾çµæœï¼ˆè¡Œæ•¸é™åˆ¶ã€æ•æ„Ÿæ•¸æ“šè„«æ•ï¼‰
        â†“
    è¿”å›æŸ¥è©¢çµæœ
    â†“
Datalake æŸ¥è©¢æµç¨‹ï¼š
    åˆ¤æ–·æŸ¥è©¢é¡å‹ï¼ˆexact/fuzzyï¼‰
        â†“
    ç²¾ç¢ºæŸ¥è©¢ï¼šè®€å–å–®å€‹æ–‡ä»¶
    æ¨¡ç³ŠæŸ¥è©¢ï¼šåˆ—å‡ºç›®éŒ„ä¸¦éæ¿¾
        â†“
    æ‡‰ç”¨éæ¿¾æ¢ä»¶ï¼ˆå¦‚æœæä¾›ï¼‰
        â†“
    é©—è­‰æ•¸æ“šï¼ˆå¦‚æœæä¾› Schemaï¼‰
        â†“
    è¿”å›æŸ¥è©¢çµæœ
```

---

## 5. æ•¸æ“šæª¢æŸ¥èˆ‡é©—è­‰

### 5.1 æŸ¥è©¢çµæœæª¢æŸ¥

#### 5.1.1 çµæœå®Œæ•´æ€§æª¢æŸ¥

```python
def _check_result_completeness(
    self,
    result: Dict[str, Any],
    expected_count: Optional[int] = None,
) -> CheckResult:
    """æª¢æŸ¥çµæœå®Œæ•´æ€§"""

    issues = []
    warnings = []

    # 1. æª¢æŸ¥çµæœæ˜¯å¦ç‚ºç©º
    if not result.get("rows"):
        issues.append("æŸ¥è©¢çµæœç‚ºç©º")

    # 2. æª¢æŸ¥çµæœè¡Œæ•¸
    row_count = result.get("row_count", 0)
    if row_count == 0:
        warnings.append("æŸ¥è©¢è¿”å› 0 è¡Œæ•¸æ“š")
    elif expected_count and row_count < expected_count:
        warnings.append(
            f"è¿”å›è¡Œæ•¸ï¼ˆ{row_count}ï¼‰å°‘æ–¼é æœŸï¼ˆ{expected_count}ï¼‰"
        )

    # 3. æª¢æŸ¥çµæœæ˜¯å¦è¢«æˆªæ–·
    total_count = result.get("total_count")
    if total_count and total_count > row_count:
        warnings.append(
            f"çµæœè¢«æˆªæ–·ï¼šç¸½å…± {total_count} è¡Œï¼Œè¿”å› {row_count} è¡Œ"
        )

    # 4. æª¢æŸ¥åŸ·è¡Œæ™‚é–“
    execution_time = result.get("execution_time", 0)
    if execution_time > 10:
        warnings.append(f"æŸ¥è©¢åŸ·è¡Œæ™‚é–“è¼ƒé•·ï¼š{execution_time:.2f} ç§’")

    return CheckResult(
        passed=len(issues) == 0,
        issues=issues,
        warnings=warnings,
    )
```

#### 5.1.2 æ•¸æ“šè³ªé‡æª¢æŸ¥

```python
def _check_data_quality(
    self,
    rows: List[Dict[str, Any]],
    schema: Optional[Dict[str, Any]] = None,
) -> QualityCheckResult:
    """æª¢æŸ¥æ•¸æ“šè³ªé‡"""

    issues = []
    warnings = []

    if not rows:
        return QualityCheckResult(
            passed=False,
            issues=["æ²’æœ‰æ•¸æ“šå¯æª¢æŸ¥"],
            warnings=[],
        )

    # 1. æª¢æŸ¥æ•¸æ“šçµæ§‹ä¸€è‡´æ€§
    if rows:
        first_row_keys = set(rows[0].keys())
        for i, row in enumerate(rows[1:], 1):
            row_keys = set(row.keys())
            if row_keys != first_row_keys:
                warnings.append(
                    f"ç¬¬ {i+1} è¡Œæ•¸æ“šçµæ§‹ä¸ä¸€è‡´ï¼š"
                    f"ç¼ºå°‘å­—æ®µ {first_row_keys - row_keys}, "
                    f"å¤šé¤˜å­—æ®µ {row_keys - first_row_keys}"
                )

    # 2. æª¢æŸ¥ç©ºå€¼
    for i, row in enumerate(rows):
        for key, value in row.items():
            if value is None:
                warnings.append(f"ç¬¬ {i+1} è¡Œï¼Œå­—æ®µ {key} ç‚ºç©ºå€¼")

    # 3. æ ¹æ“š Schema é©—è­‰ï¼ˆå¦‚æœæä¾›ï¼‰
    if schema:
        validation = self._validate_against_schema(rows, schema)
        issues.extend(validation.get("issues", []))
        warnings.extend(validation.get("warnings", []))

    return QualityCheckResult(
        passed=len(issues) == 0,
        issues=issues,
        warnings=warnings,
    )
```

#### 5.1.3 Schema é©—è­‰

```python
def _validate_against_schema(
    self,
    rows: List[Dict[str, Any]],
    schema: Dict[str, Any],
) -> ValidationResult:
    """æ ¹æ“š Schema é©—è­‰æ•¸æ“š"""

    issues = []
    warnings = []

    json_schema = schema.get("json_schema", {})
    required_fields = json_schema.get("required", [])
    properties = json_schema.get("properties", {})

    for i, row in enumerate(rows):
        # 1. æª¢æŸ¥å¿…å¡«å­—æ®µ
        for field in required_fields:
            if field not in row:
                issues.append(f"ç¬¬ {i+1} è¡Œç¼ºå°‘å¿…å¡«å­—æ®µ: {field}")

        # 2. æª¢æŸ¥å­—æ®µé¡å‹
        for field, value in row.items():
            if field in properties:
                expected_type = properties[field].get("type")
                actual_type = self._get_python_type(value)

                if expected_type and not self._type_matches(actual_type, expected_type):
                    warnings.append(
                        f"ç¬¬ {i+1} è¡Œï¼Œå­—æ®µ {field} é¡å‹ä¸åŒ¹é…ï¼š"
                        f"æœŸæœ› {expected_type}ï¼Œå¯¦éš› {actual_type}"
                    )

        # 3. æª¢æŸ¥å­—æ®µç´„æŸ
        for field, value in row.items():
            if field in properties:
                field_schema = properties[field]

                # æª¢æŸ¥æœ€å°å€¼
                if "minimum" in field_schema and isinstance(value, (int, float)):
                    if value < field_schema["minimum"]:
                        issues.append(
                            f"ç¬¬ {i+1} è¡Œï¼Œå­—æ®µ {field} å€¼ {value} "
                            f"å°æ–¼æœ€å°å€¼ {field_schema['minimum']}"
                        )

                # æª¢æŸ¥æœ€å¤§å€¼
                if "maximum" in field_schema and isinstance(value, (int, float)):
                    if value > field_schema["maximum"]:
                        issues.append(
                            f"ç¬¬ {i+1} è¡Œï¼Œå­—æ®µ {field} å€¼ {value} "
                            f"å¤§æ–¼æœ€å¤§å€¼ {field_schema['maximum']}"
                        )

                # æª¢æŸ¥æšèˆ‰å€¼
                if "enum" in field_schema:
                    if value not in field_schema["enum"]:
                        issues.append(
                            f"ç¬¬ {i+1} è¡Œï¼Œå­—æ®µ {field} å€¼ {value} "
                            f"ä¸åœ¨å…è¨±çš„æšèˆ‰å€¼ä¸­: {field_schema['enum']}"
                        )

    return ValidationResult(
        valid=len(issues) == 0,
        issues=issues,
        warnings=warnings,
    )
```

### 5.2 æ•¸æ“šé©—è­‰æµç¨‹

```
ç²å–æŸ¥è©¢çµæœ
    â†“
çµæœå®Œæ•´æ€§æª¢æŸ¥
    â”œâ”€ æª¢æŸ¥çµæœæ˜¯å¦ç‚ºç©º
    â”œâ”€ æª¢æŸ¥çµæœè¡Œæ•¸
    â”œâ”€ æª¢æŸ¥çµæœæ˜¯å¦è¢«æˆªæ–·
    â””â”€ æª¢æŸ¥åŸ·è¡Œæ™‚é–“
    â†“
æ•¸æ“šè³ªé‡æª¢æŸ¥
    â”œâ”€ æª¢æŸ¥æ•¸æ“šçµæ§‹ä¸€è‡´æ€§
    â”œâ”€ æª¢æŸ¥ç©ºå€¼
    â””â”€ æ ¹æ“š Schema é©—è­‰ï¼ˆå¦‚æœæä¾›ï¼‰
    â†“
ç”Ÿæˆæª¢æŸ¥å ±å‘Š
    â”œâ”€ å•é¡Œåˆ—è¡¨ï¼ˆissuesï¼‰
    â”œâ”€ è­¦å‘Šåˆ—è¡¨ï¼ˆwarningsï¼‰
    â””â”€ æª¢æŸ¥ç‹€æ…‹ï¼ˆpassed/failedï¼‰
    â†“
è¿”å›æª¢æŸ¥çµæœ
```

---

## 6. äº¤ä»˜æ¨™æº–

### 6.1 éŸ¿æ‡‰æ ¼å¼æ¨™æº–

Data Agent çš„éŸ¿æ‡‰å¿…é ˆéµå¾ªçµ±ä¸€çš„æ ¼å¼æ¨™æº–ï¼š

```python
class DataAgentResponse(BaseModel):
    """Data Agent éŸ¿æ‡‰æ¨¡å‹"""

    success: bool  # æ˜¯å¦æˆåŠŸ
    action: str  # æ“ä½œé¡å‹
    result: Optional[Dict[str, Any]] = None  # åŸ·è¡Œçµæœ
    error: Optional[str] = None  # éŒ¯èª¤ä¿¡æ¯
    metadata: Optional[Dict[str, Any]] = None  # å…ƒæ•¸æ“š

    # çµæœè©³æƒ…ï¼ˆå¦‚æœæˆåŠŸï¼‰
    rows: Optional[List[Dict[str, Any]]] = None  # æŸ¥è©¢çµæœè¡Œ
    row_count: Optional[int] = None  # è¿”å›è¡Œæ•¸
    total_count: Optional[int] = None  # ç¸½è¡Œæ•¸ï¼ˆå¦‚æœè¢«æˆªæ–·ï¼‰
    execution_time: Optional[float] = None  # åŸ·è¡Œæ™‚é–“ï¼ˆç§’ï¼‰

    # é©—è­‰ä¿¡æ¯ï¼ˆå¦‚æœé©ç”¨ï¼‰
    validation: Optional[Dict[str, Any]] = None  # æ•¸æ“šé©—è­‰çµæœ
    warnings: Optional[List[str]] = None  # è­¦å‘Šåˆ—è¡¨
    confidence: Optional[float] = None  # ç½®ä¿¡åº¦ï¼ˆText-to-SQLï¼‰
```

### 6.2 æˆåŠŸéŸ¿æ‡‰æ¨™æº–

#### 6.2.1 Text-to-SQL éŸ¿æ‡‰

```python
{
    "success": True,
    "action": "text_to_sql",
    "result": {
        "sql_query": "SELECT part_number, name, current_stock FROM stock WHERE status = ?",
        "parameters": ["param"],
        "confidence": 0.85,
        "explanation": "å°‡è‡ªç„¶èªè¨€æŸ¥è©¢ã€ŒæŸ¥è©¢ç¼ºæ–™çš„æ–™è™Ÿã€è½‰æ›ç‚º SQL",
        "warnings": []
    },
    "metadata": {
        "natural_language": "æŸ¥è©¢ç¼ºæ–™çš„æ–™è™Ÿ",
        "database_type": "postgresql",
        "has_schema_info": True,
    }
}
```

#### 6.2.2 æŸ¥è©¢åŸ·è¡ŒéŸ¿æ‡‰

```python
{
    "success": True,
    "action": "execute_query",
    "result": {
        "rows": [
            {"part_number": "ABC-123", "name": "é›»å­å…ƒä»¶ A", "current_stock": 50},
            {"part_number": "ABC-124", "name": "é›»å­å…ƒä»¶ B", "current_stock": 30},
        ],
        "row_count": 2,
        "total_count": 2,
        "execution_time": 0.15,
        "warnings": [],
        "metadata": {
            "query": "SELECT part_number, name, current_stock FROM stock WHERE status = 'shortage'",
            "timeout": 30,
            "max_rows": 1000,
        }
    }
}
```

#### 6.2.3 Datalake æŸ¥è©¢éŸ¿æ‡‰

```python
{
    "success": True,
    "action": "query_datalake",
    "result": {
        "rows": [
            {
                "part_number": "ABC-123",
                "name": "é›»å­å…ƒä»¶ A",
                "specification": "10x10x5mm",
                "unit": "PCS",
                "supplier": "ä¾›æ‡‰å•† A",
                "category": "é›»å­å…ƒä»¶",
                "safety_stock": 197,
                "unit_price": 56.53,
                "currency": "TWD",
            }
        ],
        "row_count": 1,
        "query_type": "exact",
        "bucket": "bucket-datalake-assets",
        "key": "parts/ABC-123.json",
        "validation": {
            "valid": True,
            "issues": [],
            "warnings": [],
        }
    }
}
```

### 6.3 éŒ¯èª¤éŸ¿æ‡‰æ¨™æº–

#### 6.3.1 é©—è­‰å¤±æ•—éŸ¿æ‡‰

```python
{
    "success": False,
    "action": "execute_query",
    "error": "SQL injection detected",
    "result": {
        "validation": {
            "valid": False,
            "error": "SQL injection detected",
            "details": [
                "SQL injection pattern detected: OR '1'='1"
            ]
        }
    }
}
```

#### 6.3.2 æ¬Šé™æ‹’çµ•éŸ¿æ‡‰

```python
{
    "success": False,
    "action": "execute_query",
    "error": "Permission denied",
    "result": {
        "permission_check": {
            "allowed": False,
            "message": "User does not have permission to query this database"
        }
    }
}
```

#### 6.3.3 æ•¸æ“šä¸å­˜åœ¨éŸ¿æ‡‰

```python
{
    "success": False,
    "action": "query_datalake",
    "error": "File not found: bucket-datalake-assets/parts/ABC-999.json",
    "result": {
        "bucket": "bucket-datalake-assets",
        "key": "parts/ABC-999.json",
    }
}
```

### 6.4 äº¤ä»˜è³ªé‡æ¨™æº–

#### 6.4.1 æ•¸æ“šå®Œæ•´æ€§

- âœ… æ‰€æœ‰æŸ¥è©¢çµæœå¿…é ˆåŒ…å«å®Œæ•´çš„å­—æ®µ
- âœ… å¦‚æœçµæœè¢«æˆªæ–·ï¼Œå¿…é ˆæ˜ç¢ºæ¨™ç¤º `total_count` å’Œ `row_count`
- âœ… å¿…é ˆæä¾›åŸ·è¡Œæ™‚é–“ä¿¡æ¯

#### 6.4.2 æ•¸æ“šæº–ç¢ºæ€§

- âœ… æŸ¥è©¢çµæœå¿…é ˆèˆ‡æŸ¥è©¢æ¢ä»¶ä¸€è‡´
- âœ… å¦‚æœæä¾› Schemaï¼Œçµæœå¿…é ˆé€šé Schema é©—è­‰
- âœ… å¿…é ˆæ¨™ç¤ºæ•¸æ“šé©—è­‰ç‹€æ…‹

#### 6.4.3 éŒ¯èª¤è™•ç†

- âœ… æ‰€æœ‰éŒ¯èª¤å¿…é ˆæä¾›æ¸…æ™°çš„éŒ¯èª¤ä¿¡æ¯
- âœ… å¿…é ˆæä¾›éŒ¯èª¤è©³æƒ…å’Œå»ºè­°
- âœ… å¿…é ˆè¨˜éŒ„éŒ¯èª¤æ—¥èªŒ

#### 6.4.4 æ€§èƒ½æ¨™æº–

- âœ… æŸ¥è©¢åŸ·è¡Œæ™‚é–“æ‡‰ < 10 ç§’ï¼ˆæ­£å¸¸æƒ…æ³ï¼‰
- âœ… æŸ¥è©¢åŸ·è¡Œæ™‚é–“æ‡‰ < 30 ç§’ï¼ˆè¤‡é›œæŸ¥è©¢ï¼‰
- âœ… çµæœè¡Œæ•¸é™åˆ¶ï¼šé»˜èª 1000 è¡Œï¼Œæœ€å¤§ 10000 è¡Œ

---

## 7. å…¶ä»–åŠŸèƒ½

### 7.1 æ•¸æ“šå­—å…¸ç®¡ç†

#### 7.1.1 å‰µå»ºæ•¸æ“šå­—å…¸

```python
async def create_dictionary(
    self,
    dictionary_id: str,
    data: Dict[str, Any],
    user_id: Optional[str] = None,
    tenant_id: Optional[str] = None,
) -> Dict[str, Any]:
    """å‰µå»ºæ•¸æ“šå­—å…¸"""

    # 1. é©—è­‰æ•¸æ“šçµæ§‹
    required_fields = ["dictionary_id", "name", "version", "tables"]
    for field in required_fields:
        if field not in data:
            return {
                "success": False,
                "error": f"Missing required field: {field}",
            }

    # 2. ä¿å­˜åˆ° SeaweedFS
    storage = self._get_datalake_storage()
    key = f"{dictionary_id}.json"

    try:
        storage.s3_client.put_object(
            Bucket="bucket-datalake-dictionary",
            Key=key,
            Body=json.dumps(data, ensure_ascii=False).encode('utf-8'),
            ContentType="application/json",
        )

        return {
            "success": True,
            "dictionary_id": dictionary_id,
            "key": key,
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
        }
```

#### 7.1.2 æŸ¥è©¢æ•¸æ“šå­—å…¸

```python
async def get_dictionary(
    self,
    dictionary_id: str,
) -> Dict[str, Any]:
    """æŸ¥è©¢æ•¸æ“šå­—å…¸"""

    storage = self._get_datalake_storage()
    key = f"{dictionary_id}.json"

    try:
        content = storage.s3_client.get_object(
            Bucket="bucket-datalake-dictionary",
            Key=key,
        )
        data = json.loads(content['Body'].read().decode('utf-8'))

        return {
            "success": True,
            "dictionary": data,
        }

    except storage.s3_client.exceptions.NoSuchKey:
        return {
            "success": False,
            "error": f"Dictionary not found: {dictionary_id}",
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
        }
```

### 7.2 Schema ç®¡ç†

#### 7.2.1 å‰µå»º Schema

```python
async def create_schema(
    self,
    schema_id: str,
    data: Dict[str, Any],
    user_id: Optional[str] = None,
    tenant_id: Optional[str] = None,
) -> Dict[str, Any]:
    """å‰µå»º Schema"""

    # 1. é©—è­‰ JSON Schema æ ¼å¼
    json_schema = data.get("json_schema")
    if not json_schema:
        return {
            "success": False,
            "error": "Missing json_schema field",
        }

    # 2. é©—è­‰ JSON Schema èªæ³•
    try:
        jsonschema.Draft7Validator.check_schema(json_schema)
    except jsonschema.SchemaError as e:
        return {
            "success": False,
            "error": f"Invalid JSON Schema: {e}",
        }

    # 3. ä¿å­˜åˆ° SeaweedFS
    storage = self._get_datalake_storage()
    key = f"{schema_id}.json"

    try:
        storage.s3_client.put_object(
            Bucket="bucket-datalake-schema",
            Key=key,
            Body=json.dumps(data, ensure_ascii=False).encode('utf-8'),
            ContentType="application/json",
        )

        return {
            "success": True,
            "schema_id": schema_id,
            "key": key,
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
        }
```

#### 7.2.2 æ•¸æ“šé©—è­‰

```python
async def validate_data(
    self,
    data: List[Dict[str, Any]],
    schema_id: str,
) -> Dict[str, Any]:
    """æ ¹æ“š Schema é©—è­‰æ•¸æ“š"""

    # 1. ç²å– Schema
    schema_result = await self.get_schema(schema_id)
    if not schema_result.get("success"):
        return {
            "success": False,
            "error": f"Schema not found: {schema_id}",
        }

    schema = schema_result["schema"]
    json_schema = schema.get("json_schema", {})

    # 2. é©—è­‰æ•¸æ“š
    validator = jsonschema.Draft7Validator(json_schema)
    issues = []

    for i, row in enumerate(data):
        errors = list(validator.iter_errors(row))
        if errors:
            for error in errors:
                issues.append({
                    "row": i + 1,
                    "field": ".".join(str(x) for x in error.path),
                    "message": error.message,
                    "value": error.instance,
                })

    return {
        "success": True,
        "valid": len(issues) == 0,
        "issues": issues,
        "validated_count": len(data),
        "invalid_count": len(issues),
    }
```

### 7.3 æŸ¥è©¢å„ªåŒ–å»ºè­°

```python
def _generate_optimization_suggestions(
    self,
    query: str,
    execution_time: float,
    row_count: int,
) -> List[str]:
    """ç”ŸæˆæŸ¥è©¢å„ªåŒ–å»ºè­°"""

    suggestions = []

    # 1. åŸ·è¡Œæ™‚é–“å„ªåŒ–
    if execution_time > 5:
        suggestions.append("æŸ¥è©¢åŸ·è¡Œæ™‚é–“è¼ƒé•·ï¼Œå»ºè­°æ·»åŠ ç´¢å¼•æˆ–å„ªåŒ–æŸ¥è©¢æ¢ä»¶")

    # 2. çµæœè¡Œæ•¸å„ªåŒ–
    if row_count > 1000:
        suggestions.append("è¿”å›è¡Œæ•¸è¼ƒå¤šï¼Œå»ºè­°æ·»åŠ æ›´ç²¾ç¢ºçš„éæ¿¾æ¢ä»¶")

    # 3. SQL å„ªåŒ–å»ºè­°
    sql_upper = query.upper()
    if "SELECT *" in sql_upper:
        suggestions.append("å»ºè­°ä½¿ç”¨å…·é«”çš„åˆ—åè€Œä¸æ˜¯ SELECT *")

    if "LIKE '%" in sql_upper:
        suggestions.append("å‰å°é€šé…ç¬¦ LIKE '%...' ç„¡æ³•ä½¿ç”¨ç´¢å¼•ï¼Œå»ºè­°å„ªåŒ–")

    return suggestions
```

---

## 8. ä»£ç¢¼å¯¦ç¾è¦æ ¼

### 8.1 é¡çµæ§‹è¨­è¨ˆ

```python
class DataAgent(AgentServiceProtocol):
    """Data Agent - æ•¸æ“šæŸ¥è©¢å°ˆå±¬æœå‹™ Agent"""

    def __init__(
        self,
        text_to_sql_service: Optional[TextToSQLService] = None,
        query_gateway_service: Optional[QueryGatewayService] = None,
        datalake_service: Optional[DatalakeService] = None,
        dictionary_service: Optional[DictionaryService] = None,
        schema_service: Optional[SchemaService] = None,
    ):
        """åˆå§‹åŒ– Data Agent"""
        self._text_to_sql_service = text_to_sql_service or TextToSQLService()
        self._query_gateway_service = query_gateway_service or QueryGatewayService()
        self._datalake_service = datalake_service or DatalakeService()
        self._dictionary_service = dictionary_service or DictionaryService()
        self._schema_service = schema_service or SchemaService()
        self._logger = logger

    async def execute(self, request: AgentServiceRequest) -> AgentServiceResponse:
        """åŸ·è¡Œæ•¸æ“šæŸ¥è©¢ä»»å‹™ï¼ˆä¸»å…¥å£ï¼‰"""
        pass

    async def health_check(self) -> AgentServiceStatus:
        """å¥åº·æª¢æŸ¥"""
        pass

    async def get_capabilities(self) -> Dict[str, Any]:
        """ç²å–æœå‹™èƒ½åŠ›"""
        pass
```

### 8.2 æ ¸å¿ƒæ–¹æ³•å¯¦ç¾

#### 8.2.1 æŒ‡ä»¤è™•ç†ä¸»æµç¨‹

```python
async def execute(self, request: AgentServiceRequest) -> AgentServiceResponse:
    """åŸ·è¡Œæ•¸æ“šæŸ¥è©¢ä»»å‹™"""

    try:
        # 1. è§£æè«‹æ±‚æ•¸æ“š
        task_data = request.task_data
        data_request = DataAgentRequest(**task_data)

        # 2. é©—è­‰è«‹æ±‚
        validation = self._validate_request(data_request)
        if not validation.valid:
            return AgentServiceResponse(
                task_id=request.task_id,
                status="failed",
                result=DataAgentResponse(
                    success=False,
                    action=data_request.action,
                    error=validation.error,
                ).model_dump(),
                error=validation.error,
                metadata=request.metadata,
            )

        # 3. éœ€æ±‚æ¾„æ¸…ï¼ˆå¦‚æœéœ€è¦ï¼‰
        clarification = await self._clarify_requirements(data_request)
        if clarification:
            return AgentServiceResponse(
                task_id=request.task_id,
                status="clarification_needed",
                result={
                    "clarification": clarification.model_dump(),
                },
                metadata=request.metadata,
            )

        # 4. éœ€æ±‚ç¢ºèª
        confirmation = await self._confirm_requirements(data_request)

        # 5. åŸ·è¡ŒæŸ¥è©¢
        action = data_request.action
        if action == "text_to_sql":
            result = await self._handle_text_to_sql(data_request)
        elif action == "execute_query":
            result = await self._handle_execute_query(data_request)
        elif action == "validate_query":
            result = await self._handle_validate_query(data_request)
        elif action == "get_schema":
            result = await self._handle_get_schema(data_request)
        elif action == "query_datalake":
            result = await self._handle_query_datalake(data_request)
        elif action == "create_dictionary":
            result = await self._handle_create_dictionary(data_request)
        elif action == "get_dictionary":
            result = await self._handle_get_dictionary(data_request)
        elif action == "create_schema":
            result = await self._handle_create_schema(data_request)
        elif action == "validate_data":
            result = await self._handle_validate_data(data_request)
        else:
            result = DataAgentResponse(
                success=False,
                action=action,
                error=f"Unknown action: {action}",
            )

        # 6. æ§‹å»ºéŸ¿æ‡‰
        return AgentServiceResponse(
            task_id=request.task_id,
            status="completed" if result.success else "failed",
            result=result.model_dump(),
            error=result.error,
            metadata={
                **request.metadata,
                "confirmation": confirmation.model_dump() if confirmation else None,
            },
        )

    except Exception as e:
        self._logger.error(f"Data Agent execution failed: {e}")
        return AgentServiceResponse(
            task_id=request.task_id,
            status="error",
            result=None,
            error=str(e),
            metadata=request.metadata,
        )
```

#### 8.2.2 Datalake æŸ¥è©¢è™•ç†

```python
async def _handle_query_datalake(
    self,
    request: DataAgentRequest,
) -> DataAgentResponse:
    """è™•ç† Datalake æŸ¥è©¢è«‹æ±‚"""

    if not request.bucket or not request.key:
        return DataAgentResponse(
            success=False,
            action="query_datalake",
            error="bucket and key are required for query_datalake action",
        )

    try:
        # èª¿ç”¨ Datalake æœå‹™
        result = await self._datalake_service.query(
            bucket=request.bucket,
            key=request.key,
            query_type=request.query_type or "exact",
            filters=request.filters,
            user_id=request.user_id,
            tenant_id=request.tenant_id,
        )

        if not result.get("success"):
            return DataAgentResponse(
                success=False,
                action="query_datalake",
                error=result.get("error", "Query failed"),
                result=result,
            )

        # æ•¸æ“šæª¢æŸ¥
        check_result = self._check_result_completeness(result)
        quality_result = self._check_data_quality(
            result.get("rows", []),
            schema=result.get("schema"),
        )

        # æ·»åŠ æª¢æŸ¥çµæœåˆ°éŸ¿æ‡‰
        result["completeness_check"] = check_result.model_dump()
        result["quality_check"] = quality_result.model_dump()

        return DataAgentResponse(
            success=True,
            action="query_datalake",
            result=result,
            warnings=check_result.warnings + quality_result.warnings,
        )

    except Exception as e:
        self._logger.error(f"Datalake query failed: {e}")
        return DataAgentResponse(
            success=False,
            action="query_datalake",
            error=str(e),
        )
```

### 8.3 æœå‹™é¡å¯¦ç¾

#### 8.3.1 DatalakeService

```python
class DatalakeService:
    """Datalake æ•¸æ“šæŸ¥è©¢æœå‹™"""

    def __init__(self):
        """åˆå§‹åŒ– Datalake æœå‹™"""
        self._storage = None
        self._logger = logger

    def _get_storage(self) -> S3FileStorage:
        """ç²å– S3 å­˜å„²å¯¦ä¾‹"""
        if self._storage is None:
            import os
            from storage.s3_storage import S3FileStorage, SeaweedFSService

            endpoint = os.getenv("DATALAKE_SEAWEEDFS_S3_ENDPOINT")
            access_key = os.getenv("DATALAKE_SEAWEEDFS_S3_ACCESS_KEY", "")
            secret_key = os.getenv("DATALAKE_SEAWEEDFS_S3_SECRET_KEY", "")

            self._storage = S3FileStorage(
                endpoint=endpoint,
                access_key=access_key,
                secret_key=secret_key,
                use_ssl=False,
                service_type=SeaweedFSService.DATALAKE,
            )

        return self._storage

    async def query(
        self,
        bucket: str,
        key: str,
        query_type: str = "exact",
        filters: Optional[Dict[str, Any]] = None,
        user_id: Optional[str] = None,
        tenant_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """æŸ¥è©¢ Datalake æ•¸æ“š"""
        # å¯¦ç¾è¦‹ 4.2.2 ç¯€
        pass
```

#### 8.3.2 DictionaryService

```python
class DictionaryService:
    """æ•¸æ“šå­—å…¸ç®¡ç†æœå‹™"""

    def __init__(self):
        """åˆå§‹åŒ–æ•¸æ“šå­—å…¸æœå‹™"""
        self._storage = None
        self._logger = logger

    async def create(
        self,
        dictionary_id: str,
        data: Dict[str, Any],
    ) -> Dict[str, Any]:
        """å‰µå»ºæ•¸æ“šå­—å…¸"""
        # å¯¦ç¾è¦‹ 7.1.1 ç¯€
        pass

    async def get(
        self,
        dictionary_id: str,
    ) -> Dict[str, Any]:
        """æŸ¥è©¢æ•¸æ“šå­—å…¸"""
        # å¯¦ç¾è¦‹ 7.1.2 ç¯€
        pass
```

#### 8.3.3 SchemaService

```python
class SchemaService:
    """Schema ç®¡ç†æœå‹™"""

    def __init__(self):
        """åˆå§‹åŒ– Schema æœå‹™"""
        self._storage = None
        self._logger = logger

    async def create(
        self,
        schema_id: str,
        data: Dict[str, Any],
    ) -> Dict[str, Any]:
        """å‰µå»º Schema"""
        # å¯¦ç¾è¦‹ 7.2.1 ç¯€
        pass

    async def validate(
        self,
        data: List[Dict[str, Any]],
        schema_id: str,
    ) -> Dict[str, Any]:
        """é©—è­‰æ•¸æ“š"""
        # å¯¦ç¾è¦‹ 7.2.2 ç¯€
        pass
```

### 8.4 éŒ¯èª¤è™•ç†è¦ç¯„

```python
class DataAgentError(Exception):
    """Data Agent åŸºç¤ç•°å¸¸é¡"""
    pass

class ValidationError(DataAgentError):
    """é©—è­‰éŒ¯èª¤"""
    pass

class PermissionError(DataAgentError):
    """æ¬Šé™éŒ¯èª¤"""
    pass

class QueryExecutionError(DataAgentError):
    """æŸ¥è©¢åŸ·è¡ŒéŒ¯èª¤"""
    pass

class DatalakeError(DataAgentError):
    """Datalake éŒ¯èª¤"""
    pass

# éŒ¯èª¤è™•ç†ç¤ºä¾‹
try:
    result = await self._datalake_service.query(...)
except DatalakeError as e:
    self._logger.error(f"Datalake query failed: {e}")
    return DataAgentResponse(
        success=False,
        action="query_datalake",
        error=str(e),
    )
```

### 8.5 æ—¥èªŒè¨˜éŒ„è¦ç¯„

```python
# ä½¿ç”¨çµæ§‹åŒ–æ—¥èªŒ
self._logger.info(
    "data_agent_query_executed",
    action=request.action,
    user_id=request.user_id,
    tenant_id=request.tenant_id,
    execution_time=execution_time,
    row_count=row_count,
)

self._logger.error(
    "data_agent_query_failed",
    action=request.action,
    error=str(e),
    user_id=request.user_id,
    tenant_id=request.tenant_id,
)
```

---

## 9. èˆ‡å…¶ä»–çµ„ä»¶çš„å”ä½œ

### 9.1 èˆ‡ AI-Box Orchestrator çš„å”ä½œ

Data Agent ä½œç‚º**å¤–éƒ¨ Agent**ï¼Œé€šé **MCP Protocol** èˆ‡ AI-Box Orchestrator å”ä½œï¼š

```python
# AI-Box Orchestrator é€šé MCP Client èª¿ç”¨å¤–éƒ¨ Data Agent
from agents.services.protocol.mcp_client import MCPAgentServiceClient

# å‰µå»º MCP Clientï¼ˆåœ¨ Orchestrator ä¸­ï¼‰
mcp_client = MCPAgentServiceClient(
    server_url="http://localhost:8004/mcp",  # Data Agent MCP Server
    server_name="data-agent",
    api_key="your-api-key",
)

# èª¿ç”¨ Data Agent
response = await mcp_client.execute(
    request=AgentServiceRequest(
        task_id=task_id,
        task_data={
            "action": "query_datalake",
            "bucket": "bucket-datalake-assets",
            "key": "parts/ABC-123.json",
        },
        metadata={
            "user_id": user_id,
            "tenant_id": tenant_id,
        },
    ),
)
```

### 9.2 èˆ‡æ¥­å‹™ Agent çš„å”ä½œ

æ¥­å‹™ Agentï¼ˆå¦‚åº«ç®¡å“¡ Agentï¼‰é€šé AI-Box Orchestrator èª¿ç”¨å¤–éƒ¨ Data Agentï¼š

```python
# åº«ç®¡å“¡ Agent æŸ¥è©¢åº«å­˜æ•¸æ“š
query_request = {
    "action": "query_datalake",
    "bucket": "bucket-datalake-assets",
    "key": "stock/ABC-123.json",
    "query_type": "exact",
}

# é€šé AI-Box Orchestrator èª¿ç”¨å¤–éƒ¨ Data Agent
# Orchestrator æœƒè‡ªå‹•ä½¿ç”¨ MCP Client èª¿ç”¨å¤–éƒ¨æœå‹™
response = await self._orchestrator.call_agent(
    agent_id="data-agent",  # å¤–éƒ¨ Agent ID
    request=AgentServiceRequest(
        task_id=task_id,
        task_data=query_request,
        metadata={"user_id": user_id, "tenant_id": tenant_id},
    ),
)

# Orchestrator å…§éƒ¨æœƒï¼š
# 1. æª¢æŸ¥ Agent Registryï¼Œç™¼ç¾ data-agent æ˜¯å¤–éƒ¨ Agent
# 2. ä½¿ç”¨ MCP Client é€£æ¥åˆ° http://localhost:8004/mcp
# 3. ç™¼é€è«‹æ±‚åˆ°å¤–éƒ¨ Data Agent
# 4. è¿”å›éŸ¿æ‡‰çµ¦æ¥­å‹™ Agent
```

### 9.3 èˆ‡ Security Agent çš„å”ä½œ

Data Agent åœ¨åŸ·è¡ŒæŸ¥è©¢å‰ï¼Œå¯ä»¥é€šé AI-Box Orchestrator èª¿ç”¨ Security Agent é€²è¡Œæ¬Šé™æª¢æŸ¥ï¼š

```python
# æ¬Šé™æª¢æŸ¥ï¼ˆå¯é¸ï¼Œå¦‚æœæŸ¥è©¢æ¶‰åŠæ•æ„Ÿæ•¸æ“šï¼‰
# æ³¨æ„ï¼šData Agent éœ€è¦èƒ½å¤ è¨ªå• AI-Box çš„ Orchestrator API
# å¯ä»¥é€šé HTTP API æˆ–å›èª¿æ©Ÿåˆ¶å¯¦ç¾

import httpx

AI_BOX_API_URL = "http://localhost:8000"

# é€šé HTTP API èª¿ç”¨ Security Agentï¼ˆå¦‚æœ Security Agent ä¹Ÿæ˜¯å¤–éƒ¨æœå‹™ï¼‰
# æˆ–è€…é€šéå›èª¿æ©Ÿåˆ¶è®“ AI-Box Orchestrator é€²è¡Œæ¬Šé™æª¢æŸ¥
security_check = httpx.post(
    f"{AI_BOX_API_URL}/api/v1/agents/execute",
    json={
        "agent_id": "security_agent",
        "task": {
            "task_id": task_id,
            "task_data": {
                "action": "check_permission",
                "resource": f"datalake:{bucket}:{key}",
                "operation": "read",
            },
            "metadata": {"user_id": user_id, "tenant_id": tenant_id},
        },
    },
    headers={"Authorization": f"Bearer {api_key}"},
)

if not security_check.json().get("result", {}).get("allowed"):
    return DataAgentResponse(
        success=False,
        action="query_datalake",
        error="Permission denied",
    )
```

**æ³¨æ„**ï¼šä½œç‚ºå¤–éƒ¨æœå‹™ï¼ŒData Agent å¯ä»¥é¸æ“‡ï¼š

1. **ç›´æ¥é€²è¡Œæ¬Šé™æª¢æŸ¥**ï¼ˆå¦‚æœæ¬Šé™è¦å‰‡ç°¡å–®ï¼‰
2. **é€šé HTTP API èª¿ç”¨ AI-Box Security Agent**ï¼ˆå¦‚æœæ¬Šé™è¦å‰‡è¤‡é›œï¼‰
3. **åœ¨è¨»å†Šæ™‚é…ç½®æ¬Šé™ç­–ç•¥**ï¼ˆç”± AI-Box åœ¨èª¿ç”¨å‰é©—è­‰ï¼‰

---

## 10. å¯¦ç¾è¨ˆåŠƒ

### 10.1 ç¾æœ‰å¯¦ç¾ç‹€æ…‹

- âœ… **æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½å·²å¯¦ç¾**ï¼ˆåœ¨ `datalake-system/` ç›®éŒ„ï¼‰ï¼š
  - âœ… Text-to-SQL è½‰æ›ï¼ˆ`TextToSQLService`ï¼‰- æ”¯æŒç°¡å–®å’Œè¤‡é›œæŸ¥è©¢
  - âœ… å®‰å…¨æŸ¥è©¢é–˜é“ï¼ˆ`QueryGatewayService`ï¼‰- åŒ…å« SQL æ³¨å…¥é˜²è­·ã€èªæ³•é©—è­‰
  - âœ… Datalake æŸ¥è©¢æœå‹™ï¼ˆ`DatalakeService`ï¼‰- æ”¯æŒç²¾ç¢ºå’Œæ¨¡ç³ŠæŸ¥è©¢
  - âœ… æ•¸æ“šå­—å…¸ç®¡ç†ï¼ˆ`DictionaryService`ï¼‰- å‰µå»ºã€ç²å–ã€æ›´æ–°åŠŸèƒ½å®Œæ•´
  - âœ… Schema ç®¡ç†ï¼ˆ`SchemaService`ï¼‰- å‰µå»ºã€ç²å–ã€æ•¸æ“šé©—è­‰åŠŸèƒ½å®Œæ•´
  - âœ… æ•¸æ“šé©—è­‰åŠŸèƒ½ - æ”¯æŒç©ºåˆ—è¡¨å’Œæ‰¹é‡é©—è­‰
  - âœ… MCP Server å¯¦ç¾ï¼ˆ`mcp_server.py`ï¼‰- å¤–éƒ¨æœå‹™æ¥å£
  - âœ… ç¨ç«‹æœå‹™éƒ¨ç½² - FastAPI æœå‹™ï¼Œç«¯å£ 8004

**å¯¦ç¾ä½ç½®**ï¼š`/Users/daniel/GitHub/AI-Box/datalake-system/data_agent/`

**æœå‹™ç®¡ç†è…³æœ¬**ï¼š`/Users/daniel/GitHub/AI-Box/datalake-system/scripts/data_agent/`

- `start.sh` - å•Ÿå‹•æœå‹™
- `stop.sh` - åœæ­¢æœå‹™
- `restart.sh` - é‡å•Ÿæœå‹™
- `status.sh` - æŸ¥çœ‹ç‹€æ…‹
- `view_logs.sh` - æŸ¥çœ‹æ—¥èªŒ
- `quick_start.sh` - å¿«é€Ÿå•Ÿå‹•
- `install_dependencies.sh` - å®‰è£ä¾è³´

### 10.2 å¯¦ç¾ç‹€æ…‹ï¼ˆ2026-01-13 æ›´æ–°ï¼‰

#### âœ… éšæ®µ 1ï¼šå¤–éƒ¨æœå‹™åŒ–ï¼ˆå·²å®Œæˆï¼‰

1. âœ… **MCP Server å¯¦ç¾**
   - æ–‡ä»¶ï¼š`datalake-system/data_agent/mcp_server.py`
   - åŠŸèƒ½ï¼šæä¾› MCP Protocol æ¥å£
   - ç‹€æ…‹ï¼šå·²å®Œæˆ

2. âœ… **ç¨ç«‹æœå‹™å•Ÿå‹•è…³æœ¬**
   - æ–‡ä»¶ï¼š`datalake-system/scripts/start_data_agent_service.py`
   - åŠŸèƒ½ï¼šå•Ÿå‹•ç¨ç«‹ Data Agent æœå‹™ï¼ˆFastAPI + Uvicornï¼‰
   - ç‹€æ…‹ï¼šå·²å®Œæˆ

3. âœ… **æœå‹™ç®¡ç†è…³æœ¬**
   - æ–‡ä»¶ï¼š`datalake-system/scripts/data_agent/*.sh`
   - åŠŸèƒ½ï¼šå®Œæ•´çš„æœå‹™ç®¡ç†ï¼ˆå•Ÿå‹•ã€åœæ­¢ã€é‡å•Ÿã€ç‹€æ…‹ã€æ—¥èªŒï¼‰
   - ç‹€æ…‹ï¼šå·²å®Œæˆ

#### âœ… éšæ®µ 2ï¼šæ“´å±• Datalake æŸ¥è©¢åŠŸèƒ½ï¼ˆå·²å®Œæˆï¼‰

1. âœ… **DatalakeService å¯¦ç¾**
   - æ–‡ä»¶ï¼š`datalake-system/data_agent/datalake_service.py`
   - åŠŸèƒ½ï¼šæŸ¥è©¢ SeaweedFS Datalake ä¸­çš„æ•¸æ“šï¼ˆç²¾ç¢º/æ¨¡ç³ŠæŸ¥è©¢ï¼‰
   - ç‹€æ…‹ï¼šå·²å®Œæˆï¼Œæ”¯æŒéæ¿¾æ¢ä»¶

2. âœ… **DataAgent é¡æ“´å±•**
   - æ·»åŠ  `_handle_query_datalake` æ–¹æ³•
   - é›†æˆ DatalakeService
   - ç‹€æ…‹ï¼šå·²å®Œæˆ

#### âœ… éšæ®µ 3ï¼šæ•¸æ“šå­—å…¸å’Œ Schema ç®¡ç†ï¼ˆå·²å®Œæˆï¼‰

1. âœ… **DictionaryService å¯¦ç¾**
   - æ–‡ä»¶ï¼š`datalake-system/data_agent/dictionary_service.py`
   - åŠŸèƒ½ï¼šå‰µå»ºã€æ›´æ–°ã€æŸ¥è©¢æ•¸æ“šå­—å…¸
   - å­˜å„²ï¼š`bucket-datalake-dictionary`
   - ç‹€æ…‹ï¼šå·²å®Œæˆ

2. âœ… **SchemaService å¯¦ç¾**
   - æ–‡ä»¶ï¼š`datalake-system/data_agent/schema_service.py`
   - åŠŸèƒ½ï¼šå‰µå»ºã€æ›´æ–°ã€æŸ¥è©¢ Schemaï¼Œæ•¸æ“šé©—è­‰
   - å­˜å„²ï¼š`bucket-datalake-schema`
   - ç‹€æ…‹ï¼šå·²å®Œæˆï¼Œæ”¯æŒ JSON Schema Draft 7

#### âœ… éšæ®µ 4ï¼šåŠŸèƒ½æ”¹é€²ï¼ˆå·²å®Œæˆï¼‰

1. âœ… **åƒæ•¸ä¸€è‡´æ€§æ”¹é€²**
   - Schema æœå‹™ï¼šè‡ªå‹•åŒ…è£ `schema_data` ç‚º `{"json_schema": ...}`
   - æ•¸æ“šå­—å…¸æœå‹™ï¼šè‡ªå‹•åˆä½µ `dictionary_id` åˆ° `dictionary_data`
   - ç‹€æ…‹ï¼šå·²å®Œæˆ

2. âœ… **SQL é©—è­‰é‚è¼¯æ”¹é€²**
   - æ·»åŠ  `_check_sql_syntax` æ–¹æ³•
   - æª¢æŸ¥ WHERE å­å¥å®Œæ•´æ€§
   - æª¢æŸ¥æ‹¬è™Ÿå’Œå¼•è™ŸåŒ¹é…
   - ç‹€æ…‹ï¼šå·²å®Œæˆ

3. âœ… **ç©ºåˆ—è¡¨è™•ç†æ”¹é€²**
   - å…è¨±ç©ºåˆ—è¡¨ä½œç‚ºæœ‰æ•ˆè¼¸å…¥
   - ç‹€æ…‹ï¼šå·²å®Œæˆ

4. âœ… **Text-to-SQL è¤‡é›œæŸ¥è©¢æ”¯æŒ**
   - æ”¯æŒå­—å…¸å’Œåˆ—è¡¨å…©ç¨® `schema_info` æ ¼å¼
   - æ”¹é€²åˆ—ä¿¡æ¯è™•ç†
   - ç‹€æ…‹ï¼šå·²å®Œæˆ

#### âœ… éšæ®µ 5ï¼šæ¸¬è©¦å’Œæ–‡æª”ï¼ˆå·²å®Œæˆï¼‰

1. âœ… **å®Œæ•´æ¸¬è©¦å¥—ä»¶**
   - æ–‡ä»¶ï¼š`datalake-system/tests/data_agent/test_data_agent_scenarios.py`
   - æ¸¬è©¦æ•¸ï¼š29 å€‹æ¸¬è©¦å ´æ™¯
   - é€šéç‡ï¼š100.0%
   - ç‹€æ…‹ï¼šå·²å®Œæˆ

2. âœ… **æ¸¬è©¦ä¾è³´é—œä¿‚ç®¡ç†**
   - æŒ‰ä¾è³´é—œä¿‚åˆ†çµ„åŸ·è¡Œæ¸¬è©¦
   - ç¢ºä¿æ¸¬è©¦é †åºåˆç†
   - ç‹€æ…‹ï¼šå·²å®Œæˆ

3. âœ… **æ¸¬è©¦æ–‡æª”**
   - `TEST_REPORT_FINAL_COMPLETE.md` - å®Œæ•´æ¸¬è©¦å ±å‘Š
   - `README.md` - æ¸¬è©¦èªªæ˜æ–‡æª”
   - `QUICK_START.md` - å¿«é€Ÿé–‹å§‹æŒ‡å—
   - ç‹€æ…‹ï¼šå·²å®Œæˆ

### 10.3 æ–‡ä»¶çµæ§‹ï¼ˆå·²å¯¦ç¾ï¼‰

**Datalake System æ–‡ä»¶çµæ§‹**ï¼š

```
datalake-system/
â”œâ”€â”€ data_agent/                      # Data Agent æœå‹™ä»£ç¢¼
â”‚   â”œâ”€â”€ __init__.py                  # âœ… å·²å¯¦ç¾
â”‚   â”œâ”€â”€ agent.py                     # âœ… DataAgent ä¸»é¡ï¼ˆå·²å¯¦ç¾ï¼‰
â”‚   â”œâ”€â”€ mcp_server.py               # âœ… MCP Serverï¼ˆå·²å¯¦ç¾ï¼‰
â”‚   â”œâ”€â”€ models.py                    # âœ… æ•¸æ“šæ¨¡å‹ï¼ˆå·²å¯¦ç¾ï¼‰
â”‚   â”œâ”€â”€ text_to_sql.py              # âœ… Text-to-SQL æœå‹™ï¼ˆå·²å¯¦ç¾ï¼‰
â”‚   â”œâ”€â”€ query_gateway.py            # âœ… æŸ¥è©¢é–˜é“æœå‹™ï¼ˆå·²å¯¦ç¾ï¼‰
â”‚   â”œâ”€â”€ datalake_service.py         # âœ… Datalake æŸ¥è©¢æœå‹™ï¼ˆå·²å¯¦ç¾ï¼‰
â”‚   â”œâ”€â”€ dictionary_service.py       # âœ… æ•¸æ“šå­—å…¸æœå‹™ï¼ˆå·²å¯¦ç¾ï¼‰
â”‚   â”œâ”€â”€ schema_service.py           # âœ… Schema æœå‹™ï¼ˆå·²å¯¦ç¾ï¼‰
â”‚   â”œâ”€â”€ query_gateway.py            # âœ… æŸ¥è©¢é–˜é“æœå‹™ï¼ˆå·²å¯¦ç¾ï¼‰
â”‚   â””â”€â”€ text_to_sql.py              # âœ… Text-to-SQL æœå‹™ï¼ˆå·²å¯¦ç¾ï¼‰
â”œâ”€â”€ scripts/                         # æœå‹™ç®¡ç†è…³æœ¬
â”‚   â”œâ”€â”€ start_data_agent_service.py # âœ… å•Ÿå‹•æœå‹™è…³æœ¬ï¼ˆå·²å¯¦ç¾ï¼‰
â”‚   â”œâ”€â”€ check_environment.py        # âœ… ç’°å¢ƒé…ç½®æª¢æŸ¥ï¼ˆå·²å¯¦ç¾ï¼‰
â”‚   â””â”€â”€ data_agent/                 # âœ… æœå‹™ç®¡ç†è…³æœ¬ï¼ˆå·²å¯¦ç¾ï¼‰
â”‚       â”œâ”€â”€ start.sh                # å•Ÿå‹•æœå‹™
â”‚       â”œâ”€â”€ stop.sh                 # åœæ­¢æœå‹™
â”‚       â”œâ”€â”€ restart.sh              # é‡å•Ÿæœå‹™
â”‚       â”œâ”€â”€ status.sh               # æŸ¥çœ‹ç‹€æ…‹
â”‚       â”œâ”€â”€ view_logs.sh            # æŸ¥çœ‹æ—¥èªŒ
â”‚       â”œâ”€â”€ quick_start.sh          # å¿«é€Ÿå•Ÿå‹•
â”‚       â””â”€â”€ install_dependencies.sh # å®‰è£ä¾è³´
â”œâ”€â”€ tests/                           # æ¸¬è©¦æ–‡ä»¶
â”‚   â””â”€â”€ data_agent/                 # âœ… æ¸¬è©¦å¥—ä»¶ï¼ˆå·²å¯¦ç¾ï¼‰
â”‚       â”œâ”€â”€ test_data_agent_scenarios.py  # 29 å€‹æ¸¬è©¦å ´æ™¯
â”‚       â”œâ”€â”€ run_tests.sh            # æ¸¬è©¦åŸ·è¡Œè…³æœ¬
â”‚       â”œâ”€â”€ TEST_REPORT_FINAL_COMPLETE.md # å®Œæ•´æ¸¬è©¦å ±å‘Š
â”‚       â””â”€â”€ test_results.json       # æ¸¬è©¦çµæœï¼ˆJSONï¼‰
â”œâ”€â”€ logs/                            # æ—¥èªŒæ–‡ä»¶ï¼ˆé‹è¡Œæ™‚å‰µå»ºï¼‰
â”‚   â”œâ”€â”€ data_agent.log
â”‚   â”œâ”€â”€ data_agent_error.log
â”‚   â””â”€â”€ data_agent.pid
â”œâ”€â”€ requirements.txt                 # âœ… Python ä¾è³´ï¼ˆå·²å®šç¾©ï¼‰
â”œâ”€â”€ README.md                        # âœ… èªªæ˜æ–‡æª”ï¼ˆå·²å‰µå»ºï¼‰
â””â”€â”€ QUICK_START.md                   # âœ… å¿«é€Ÿé–‹å§‹æŒ‡å—ï¼ˆå·²å‰µå»ºï¼‰
```

**å¯¦ç¾ç‹€æ…‹**ï¼šâœ… æ‰€æœ‰åŠŸèƒ½å·²å¯¦ç¾ä¸¦é€šéæ¸¬è©¦

---

## é™„éŒ„

### A. æ•¸æ“šæ¨¡å‹å®Œæ•´å®šç¾©

è¦‹ `agents/builtin/data_agent/models.py`

### B. API ç«¯é»å®šç¾©

è¦‹ [æ¨¡æ“¬-Datalake-è¦åŠƒæ›¸.md](./æ¨¡æ“¬-Datalake-è¦åŠƒæ›¸.md) ç¬¬ 7 ç« 

### C. éŒ¯èª¤ä»£ç¢¼è¡¨

| éŒ¯èª¤ä»£ç¢¼ | éŒ¯èª¤ä¿¡æ¯ | èªªæ˜ |
|---------|---------|------|
| DA001 | Invalid action | ç„¡æ•ˆçš„æ“ä½œé¡å‹ |
| DA002 | Missing required parameter | ç¼ºå°‘å¿…éœ€åƒæ•¸ |
| DA003 | SQL injection detected | æª¢æ¸¬åˆ° SQL æ³¨å…¥ |
| DA004 | Permission denied | æ¬Šé™è¢«æ‹’çµ• |
| DA005 | File not found | æ–‡ä»¶ä¸å­˜åœ¨ |
| DA006 | Schema validation failed | Schema é©—è­‰å¤±æ•— |
| DA007 | Query execution timeout | æŸ¥è©¢åŸ·è¡Œè¶…æ™‚ |
| DA008 | Invalid JSON Schema | ç„¡æ•ˆçš„ JSON Schema |

---

## 11. æ¶æ§‹è¨­è¨ˆåŸå‰‡

### 11.1 è·è²¬åˆ†é›¢åŸå‰‡

**æ ¸å¿ƒåŸå‰‡**ï¼š

- âœ… **Datalake è² è²¬æ•¸æ“šç®¡ç†**ï¼šæ•¸æ“šå­˜å„²ã€æ•¸æ“šå­—å…¸ã€Schema ç®¡ç†
- âœ… **AI-Box è² è²¬ AI æ“ä½œ**ï¼šä»»å‹™èª¿åº¦ã€Agent ç®¡ç†ã€å·¥ä½œæµç·¨æ’
- âœ… **Data Agent å±¬æ–¼ Datalake**ï¼šä½œç‚º Datalake çš„æœå‹™æ¥å£ï¼Œä¸å±¬æ–¼ AI-Box

### 11.2 æ¶æ§‹å„ªå‹¢

1. **æ¸…æ™°çš„è·è²¬é‚Šç•Œ**ï¼š
   - Datalakeï¼šæ•¸æ“šå±¤ï¼Œè² è²¬æ•¸æ“šå­˜å„²å’Œç®¡ç†
   - AI-Boxï¼šæ“ä½œç³»çµ±å±¤ï¼Œè² è²¬ AI ä»»å‹™èª¿åº¦å’Œå”èª¿

2. **ç¨ç«‹éƒ¨ç½²å’Œæ“´å±•**ï¼š
   - Datalake å¯ä»¥ç¨ç«‹éƒ¨ç½²ã€æ“´å±•å’Œç¶­è­·
   - AI-Box ä¸ä¾è³´å…·é«”çš„æ•¸æ“šç®¡ç†å¯¦ç¾

3. **å¯ç§»æ¤æ€§**ï¼š
   - Data Agent å¯ä»¥æœå‹™æ–¼å¤šå€‹ AI ç³»çµ±
   - ç¬¦åˆå¾®æœå‹™æ¶æ§‹åŸå‰‡

4. **ç¬¦åˆè¨­è¨ˆåŸå‰‡**ï¼š
   - å–®ä¸€è·è²¬åŸå‰‡ï¼ˆSRPï¼‰
   - é—œæ³¨é»åˆ†é›¢ï¼ˆSoCï¼‰
   - ä¾è³´å€’ç½®åŸå‰‡ï¼ˆDIPï¼‰

---

## 12. æ¸¬è©¦çµæœèˆ‡é©—è­‰

### 12.1 æ¸¬è©¦åŸ·è¡Œæ‘˜è¦

**æ¸¬è©¦æ—¥æœŸ**ï¼š2026-01-13
**æ¸¬è©¦ç‰ˆæœ¬**ï¼š4.0
**æ¸¬è©¦ç‹€æ…‹**ï¼šâœ… **100% é€šéç‡**

#### æ¸¬è©¦çµ±è¨ˆ

- **ç¸½æ¸¬è©¦æ•¸**ï¼š29
- **é€šéæ•¸**ï¼š29 âœ…
- **å¤±æ•—æ•¸**ï¼š0 âŒ
- **é€šéç‡**ï¼š**100.0%** ğŸ‰

#### æ”¹é€²æ­·ç¨‹

| éšæ®µ | é€šéç‡ | é€šéæ•¸ | ä¸»è¦æ”¹é€² |
|------|--------|--------|----------|
| åˆå§‹æ¸¬è©¦ | 51.7% | 15/29 | - |
| ä¿®å¾© Bucket åç¨± | 65.5% | 19/29 | âœ… +13.8% |
| ä¿®å¾©åƒæ•¸ä¸ä¸€è‡´ | 79.3% | 23/29 | âœ… +13.8% |
| æ”¹é€² SQL é©—è­‰å’Œç©ºåˆ—è¡¨ | 89.7% | 26/29 | âœ… +10.4% |
| ä¿®å¾© Text-to-SQL å’Œæ¸¬è©¦ç®¡ç† | 96.6% | 28/29 | âœ… +6.9% |
| **æœ€çµ‚ç‰ˆæœ¬** | **100.0%** | **29/29** | âœ… **+3.4%** |

**ç¸½æå‡**ï¼š**+48.3%** â¬†ï¸

### 12.2 åŠŸèƒ½æ¸¬è©¦çµæœ

#### Datalake æŸ¥è©¢æ¸¬è©¦ï¼ˆ5 å€‹å…¨éƒ¨é€šéï¼‰âœ…

1. âœ… Datalake ç²¾ç¢ºæŸ¥è©¢ - æŸ¥è©¢å–®å€‹æ–‡ä»¶
2. âœ… Datalake æ¨¡ç³ŠæŸ¥è©¢ - æŒ‰å‰ç¶´æŸ¥è©¢
3. âœ… Datalake æŸ¥è©¢ - å¸¶éæ¿¾æ¢ä»¶
4. âœ… Datalake æŸ¥è©¢ - ä¸å­˜åœ¨çš„ bucketï¼ˆéŒ¯èª¤è™•ç†ï¼‰
5. âœ… Datalake æŸ¥è©¢ - å¤§é‡çµæœï¼ˆæ€§èƒ½æ¸¬è©¦ï¼‰

#### æ•¸æ“šå­—å…¸ç®¡ç†æ¸¬è©¦ï¼ˆ5 å€‹å…¨éƒ¨é€šéï¼‰âœ…

6. âœ… å‰µå»ºæ•¸æ“šå­—å…¸
7. âœ… ç²å–æ•¸æ“šå­—å…¸
8. âœ… ç²å–ä¸å­˜åœ¨çš„æ•¸æ“šå­—å…¸ï¼ˆéŒ¯èª¤è™•ç†ï¼‰
9. âœ… å‰µå»ºæ•¸æ“šå­—å…¸ - ç¼ºå°‘æ•¸æ“šï¼ˆéŒ¯èª¤è™•ç†ï¼‰
10. âœ… å‰µå»ºæ•¸æ“šå­—å…¸ - é‡è¤‡ IDï¼ˆå…è¨±è¦†è“‹ï¼‰

#### Schema ç®¡ç†æ¸¬è©¦ï¼ˆ5 å€‹å…¨éƒ¨é€šéï¼‰âœ…

11. âœ… å‰µå»º JSON Schema
12. âœ… ç²å– Schema
13. âœ… ç²å–ä¸å­˜åœ¨çš„ Schemaï¼ˆéŒ¯èª¤è™•ç†ï¼‰
14. âœ… å‰µå»ºç„¡æ•ˆçš„ Schemaï¼ˆéŒ¯èª¤è™•ç†ï¼‰
15. âœ… å‰µå»º Schema - å¸¶å¼•ç”¨ï¼ˆè¤‡é›œçµæ§‹ï¼‰

#### æ•¸æ“šé©—è­‰æ¸¬è©¦ï¼ˆ4 å€‹å…¨éƒ¨é€šéï¼‰âœ…

16. âœ… é©—è­‰æ•¸æ“š - æœ‰æ•ˆæ•¸æ“š
17. âœ… é©—è­‰æ•¸æ“š - ç„¡æ•ˆæ•¸æ“šï¼ˆæ­£ç¢ºæª¢æ¸¬ï¼‰
18. âœ… é©—è­‰æ•¸æ“š - ç¼ºå°‘ Schema IDï¼ˆéŒ¯èª¤è™•ç†ï¼‰
19. âœ… é©—è­‰æ•¸æ“š - ç©ºåˆ—è¡¨ï¼ˆé‚Šç•Œæƒ…æ³ï¼‰

#### Text-to-SQL æ¸¬è©¦ï¼ˆ3 å€‹å…¨éƒ¨é€šéï¼‰âœ…

20. âœ… Text-to-SQL - ç°¡å–®æŸ¥è©¢
21. âœ… Text-to-SQL - è¤‡é›œæŸ¥è©¢ï¼ˆæ”¯æŒå­—å…¸å’Œåˆ—è¡¨æ ¼å¼ï¼‰
22. âœ… Text-to-SQL - ç¼ºå°‘è‡ªç„¶èªè¨€ï¼ˆéŒ¯èª¤è™•ç†ï¼‰

#### æŸ¥è©¢é©—è­‰æ¸¬è©¦ï¼ˆ3 å€‹å…¨éƒ¨é€šéï¼‰âœ…

23. âœ… é©—è­‰æŸ¥è©¢ - æœ‰æ•ˆçš„ SQL
24. âœ… é©—è­‰æŸ¥è©¢ - ç„¡æ•ˆçš„ SQLï¼ˆèªæ³•æª¢æŸ¥ï¼‰
25. âœ… é©—è­‰æŸ¥è©¢ - å±éšªçš„ SQLï¼ˆå®‰å…¨æª¢æŸ¥ï¼‰

#### éŒ¯èª¤è™•ç†æ¸¬è©¦ï¼ˆ4 å€‹å…¨éƒ¨é€šéï¼‰âœ…

26. âœ… Datalake æŸ¥è©¢ - ç¼ºå°‘ bucket åƒæ•¸
27. âœ… Datalake æŸ¥è©¢ - ç¼ºå°‘ key åƒæ•¸
28. âœ… æœªçŸ¥æ“ä½œï¼ˆéŒ¯èª¤è™•ç†ï¼‰
29. âœ… æ‰€æœ‰éŒ¯èª¤è™•ç†æ¸¬è©¦é€šé

### 12.3 åŠŸèƒ½è¦†è“‹ç‡

| åŠŸèƒ½é¡åˆ¥ | æ¸¬è©¦æ•¸ | é€šéæ•¸ | é€šéç‡ |
|---------|--------|--------|--------|
| Datalake æŸ¥è©¢ | 5 | 5 | 100% âœ… |
| æ•¸æ“šå­—å…¸ç®¡ç† | 5 | 5 | 100% âœ… |
| Schema ç®¡ç† | 5 | 5 | 100% âœ… |
| æ•¸æ“šé©—è­‰ | 4 | 4 | 100% âœ… |
| Text-to-SQL | 3 | 3 | 100% âœ… |
| æŸ¥è©¢é©—è­‰ | 3 | 3 | 100% âœ… |
| éŒ¯èª¤è™•ç† | 4 | 4 | 100% âœ… |

### 12.4 å·²å®Œæˆçš„æ”¹é€²

#### 1. ä¿®å¾© Bucket åç¨±å•é¡Œ âœ…

**å•é¡Œ**ï¼šæ¸¬è©¦è…³æœ¬ä½¿ç”¨ä¸å­˜åœ¨çš„ `bucket-datalake-data`
**ä¿®å¾©**ï¼šæ”¹ç‚ºä½¿ç”¨å¯¦éš›å­˜åœ¨çš„ `bucket-datalake-assets`
**çµæœ**ï¼šDatalake æŸ¥è©¢æ¸¬è©¦å¾ 0% æå‡åˆ° 100%

#### 2. ä¿®å¾©åƒæ•¸ä¸ä¸€è‡´å•é¡Œ âœ…

- **Schema æœå‹™**ï¼šè‡ªå‹•åŒ…è£ `schema_data` ç‚º `{"json_schema": schema_data}`
- **æ•¸æ“šå­—å…¸æœå‹™**ï¼šè‡ªå‹•åˆä½µ `dictionary_id` åˆ° `dictionary_data`
- **çµæœ**ï¼šæ‰€æœ‰ Schema å’Œæ•¸æ“šå­—å…¸å‰µå»ºæ¸¬è©¦é€šé

#### 3. æ”¹é€² SQL é©—è­‰é‚è¼¯ âœ…

- æ·»åŠ  `_check_sql_syntax` æ–¹æ³•
- æª¢æŸ¥ WHERE å­å¥å®Œæ•´æ€§
- æª¢æŸ¥æ‹¬è™Ÿå’Œå¼•è™ŸåŒ¹é…
- **çµæœ**ï¼šSQL é©—è­‰æ¸¬è©¦å…¨éƒ¨é€šé

#### 4. æ”¹é€²ç©ºåˆ—è¡¨è™•ç† âœ…

- å…è¨±ç©ºåˆ—è¡¨ä½œç‚ºæœ‰æ•ˆè¼¸å…¥
- **çµæœ**ï¼šç©ºåˆ—è¡¨é©—è­‰æ¸¬è©¦é€šé

#### 5. ä¿®å¾© Text-to-SQL è¤‡é›œæŸ¥è©¢è™•ç† âœ…

- æ”¯æŒå­—å…¸å’Œåˆ—è¡¨å…©ç¨® `schema_info` æ ¼å¼
- æ”¹é€²åˆ—ä¿¡æ¯è™•ç†
- **çµæœ**ï¼šText-to-SQL è¤‡é›œæŸ¥è©¢æ¸¬è©¦é€šé

#### 6. æ”¹é€²æ¸¬è©¦ä¾è³´é—œä¿‚ç®¡ç† âœ…

- æŒ‰ä¾è³´é—œä¿‚åˆ†çµ„åŸ·è¡Œæ¸¬è©¦
- ç¢ºä¿æ¸¬è©¦é †åºåˆç†
- **çµæœ**ï¼šæ¸¬è©¦ä¾è³´é—œä¿‚æ¸…æ™°

#### 7. èª¿æ•´æ¸¬è©¦é‚è¼¯ä»¥åŒ¹é…å¯¦éš›è¡Œç‚º âœ…

- æ›´æ–°æ¸¬è©¦æœŸæœ›å€¼
- æ¸¬è©¦é‚è¼¯èˆ‡å¯¦ç¾ä¸€è‡´
- **çµæœ**ï¼šæ‰€æœ‰æ¸¬è©¦é€šé

#### 8. æ”¹é€² JSON Schema é©—è­‰é‚è¼¯ âœ…

- å¢å¼·åŸºæœ¬çµæ§‹æª¢æŸ¥
- **çµæœ**ï¼šç„¡æ•ˆ Schema æ¸¬è©¦é€šé

### 12.5 æ¸¬è©¦æ–‡ä»¶ä½ç½®

- **æ¸¬è©¦è…³æœ¬**ï¼š`datalake-system/tests/data_agent/test_data_agent_scenarios.py`
- **æ¸¬è©¦å ±å‘Š**ï¼š`datalake-system/tests/data_agent/TEST_REPORT_FINAL_COMPLETE.md`
- **æ¸¬è©¦çµæœ**ï¼š`datalake-system/tests/data_agent/test_results.json`

### 12.6 åŸ·è¡Œæ¸¬è©¦

```bash
cd /Users/daniel/GitHub/AI-Box/datalake-system
python3 tests/data_agent/test_data_agent_scenarios.py
```

æˆ–ä½¿ç”¨æ¸¬è©¦è…³æœ¬ï¼š

```bash
./tests/data_agent/run_tests.sh
```

---

**ç‰ˆæœ¬**: 3.0
**æœ€å¾Œæ›´æ–°æ—¥æœŸ**: 2026-01-13
**ç¶­è­·äºº**: Daniel Chung
**ä¸»è¦è®Šæ›´**:

- å°‡ Data Agent å¾ AI-Box å…§éƒ¨èª¿æ•´ç‚º Datalake å¤–éƒ¨æœå‹™ï¼Œæ˜ç¢ºè·è²¬åˆ†é›¢åŸå‰‡
- å®Œæˆæ‰€æœ‰åŠŸèƒ½å¯¦ç¾å’Œæ¸¬è©¦ï¼Œé€šéç‡ 100%
- æ”¹é€²åƒæ•¸ä¸€è‡´æ€§ã€SQL é©—è­‰ã€ç©ºåˆ—è¡¨è™•ç†ã€Text-to-SQL è¤‡é›œæŸ¥è©¢ç­‰åŠŸèƒ½
