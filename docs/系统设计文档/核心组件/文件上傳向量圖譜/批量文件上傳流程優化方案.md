# 批量文件上傳流程優化方案

**創建日期**: 2026-01-02
**創建人**: Daniel Chung
**最後修改日期**: 2026-01-02

---

## 📋 概述

本文檔分析批量文件上傳時的處理流程優化方案，提出**先異步向量化，後進行知識圖譜提取**的優化策略，以提高批量上傳的處理效率和資源利用率。

---

## 🔍 當前流程分析

### 當前處理流程

**單一文件處理流程**（順序執行）：

```
文件上傳
  ↓
分塊 (Chunking)
  ↓
向量化 (Vectorization)
  ↓
存儲到 ChromaDB (Storage)
  ↓
知識圖譜提取 (KG Extraction)
  ↓
完成
```

**批量文件處理**：

- 每個文件獨立提交到 RQ 隊列
- 每個文件按順序執行上述流程
- 文件之間可以並行處理（通過 RQ Worker 並發）

### 當前實現位置

**主要函數**：`process_file_chunking_and_vectorization()`
- **位置**：`api/routers/file_upload.py:461`
- **流程**：分塊 → 向量化 → 存儲 → 知識圖譜提取（順序執行）

---

## 💡 優化方案分析

### 關鍵發現

1. **知識圖譜提取的依賴關係**：
   - `process_kg_extraction()` 函數只需要 `chunks` 作為參數
   - **不依賴向量化的結果**（embeddings）
   - 知識圖譜提取和向量化可以**並行處理**

2. **狀態管理支持**：
   - 當前已有完善的狀態管理機制
   - 可以獨立追蹤向量化和知識圖譜提取的狀態
   - 支持並行處理的狀態更新

3. **資源利用**：
   - 向量化主要消耗 Embedding 服務資源（Ollama）
   - 知識圖譜提取主要消耗 LLM 服務資源（NER/RE/RT）
   - 兩者可以**並行處理**，提高資源利用率

### 優化方案選項

#### 方案 A：並行處理（推薦）

**流程**：

```
文件上傳
  ↓
分塊 (Chunking)
  ↓
    ├─→ 向量化 (Vectorization) ─→ 存儲到 ChromaDB
    │
    └─→ 知識圖譜提取 (KG Extraction) ─→ 存儲到 ArangoDB
  ↓
完成（兩個分支都完成）
```

**優勢**：
- ✅ **最高效率**：向量化和知識圖譜提取並行執行
- ✅ **資源充分利用**：同時利用 Embedding 和 LLM 服務
- ✅ **總處理時間最短**：總時間 = max(向量化時間, 知識圖譜提取時間)

**挑戰**：
- ⚠️ 需要確保兩個分支都完成後才標記為完成
- ⚠️ 錯誤處理需要考慮部分失敗的情況

#### 方案 B：先向量化後圖譜（用戶建議）

**流程**：

```
文件上傳
  ↓
分塊 (Chunking)
  ↓
向量化 (Vectorization) ─→ 存儲到 ChromaDB
  ↓
知識圖譜提取 (KG Extraction) ─→ 存儲到 ArangoDB
  ↓
完成
```

**優勢**：
- ✅ **邏輯清晰**：先完成向量化，再進行知識圖譜提取
- ✅ **易於實現**：在當前流程基礎上，將知識圖譜提取改為異步任務
- ✅ **狀態管理簡單**：順序執行，狀態更新邏輯清晰

**劣勢**：
- ⚠️ 總處理時間 = 向量化時間 + 知識圖譜提取時間（較長）

#### 方案 C：混合方案（批量優化）

**流程**：

```
批量文件上傳
  ↓
所有文件分塊完成
  ↓
優先級策略：
  - 小文件：並行處理（向量化 + 知識圖譜提取）
  - 大文件：先向量化，後知識圖譜提取（避免資源競爭）
```

**優勢**：
- ✅ **靈活適應**：根據文件大小動態選擇策略
- ✅ **資源平衡**：避免大文件佔用過多資源

**挑戰**：
- ⚠️ 實現複雜度較高
- ⚠️ 需要定義文件大小的閾值

---

## 🎯 推薦方案：方案 A（並行處理）

### 實現策略

#### 1. 修改處理流程函數

**當前函數**：`process_file_chunking_and_vectorization()`

**優化後流程**：

```python
async def process_file_chunking_and_vectorization(
    file_id: str,
    file_path: str,
    file_type: Optional[str],
    user_id: str,
) -> None:
    """
    異步處理文件分塊、向量化和知識圖譜提取（並行處理）
    """
    # 階段1: 文件解析和分塊
    chunks = await process_chunking(file_id, file_path, file_type)
    
    # 階段2: 並行處理向量化和知識圖譜提取
    vectorization_task = process_vectorization_async(
        file_id=file_id,
        chunks=chunks,
        user_id=user_id,
    )
    
    kg_extraction_task = process_kg_extraction_async(
        file_id=file_id,
        chunks=chunks,
        user_id=user_id,
        options=kg_config,
    )
    
    # 等待兩個任務都完成
    await asyncio.gather(
        vectorization_task,
        kg_extraction_task,
        return_exceptions=True,  # 允許部分失敗
    )
    
    # 更新最終狀態
    _update_processing_status(
        file_id=file_id,
        overall_status="completed",
        overall_progress=100,
    )
```

#### 2. 狀態管理更新

**當前狀態結構**：

```python
{
    "chunking": {...},
    "vectorization": {...},
    "storage": {...},
    "kg_extraction": {...},
    "overall_status": "processing",
    "overall_progress": 50,
}
```

**優化後**：

- 向量化和知識圖譜提取可以**獨立更新狀態**
- `overall_progress` 計算方式：
  - 分塊：0-30%
  - 向量化：30-60%（與知識圖譜提取並行）
  - 知識圖譜提取：30-60%（與向量化並行）
  - 完成：100%

#### 3. 錯誤處理策略

**部分失敗處理**：

- **向量化失敗**：知識圖譜提取仍可繼續，但標記向量化狀態為失敗
- **知識圖譜提取失敗**：向量化仍可繼續，但標記知識圖譜提取狀態為失敗
- **最終狀態**：
  - 如果兩個都成功：`overall_status = "completed"`
  - 如果一個失敗：`overall_status = "partial_completed"`（新增狀態）
  - 如果兩個都失敗：`overall_status = "failed"`

---

## 📊 性能預期

### 當前流程（順序執行）

**單一文件處理時間**：
- 分塊：10 秒
- 向量化：30 秒
- 存儲：5 秒
- 知識圖譜提取：60 秒
- **總時間**：105 秒

**批量處理（5個文件並行）**：
- 假設每個文件處理時間相同
- **總時間**：約 105 秒（受最慢文件影響）

### 優化後流程（並行處理）

**單一文件處理時間**：
- 分塊：10 秒
- 向量化 + 知識圖譜提取（並行）：max(30秒, 60秒) = 60 秒
- 存儲：5 秒（向量化完成後）
- **總時間**：75 秒（**節省 30 秒，約 28.6%**）

**批量處理（5個文件並行）**：
- **總時間**：約 75 秒（**節省 30 秒**）

### 資源利用率

**當前流程**：
- Embedding 服務利用率：30/105 = 28.6%
- LLM 服務利用率：60/105 = 57.1%

**優化後流程**：
- Embedding 服務利用率：30/75 = 40%
- LLM 服務利用率：60/75 = 80%
- **資源利用率提升**：約 40%

---

## 🔧 實現細節

### 1. 創建並行處理函數

**新增函數**：`process_vectorization_async()`

```python
async def process_vectorization_async(
    file_id: str,
    chunks: List[Dict[str, Any]],
    user_id: str,
) -> None:
    """
    異步處理向量化（獨立任務）
    """
    try:
        # 向量化處理
        embeddings = await embedding_service.generate_embeddings_batch(...)
        
        # 存儲到 ChromaDB
        vector_store_service.store_vectors(...)
        
        # 更新狀態
        _update_processing_status(
            file_id=file_id,
            vectorization={"status": "completed", ...},
            storage={"status": "completed", ...},
        )
    except Exception as e:
        _update_processing_status(
            file_id=file_id,
            vectorization={"status": "failed", "error": str(e)},
        )
        raise
```

**修改函數**：`process_kg_extraction()` → `process_kg_extraction_async()`

```python
async def process_kg_extraction_async(
    file_id: str,
    chunks: List[Dict[str, Any]],
    user_id: str,
    options: Dict[str, Any],
) -> None:
    """
    異步處理知識圖譜提取（獨立任務）
    """
    # 現有實現保持不變
    # 但改為異步函數，支持並行處理
    ...
```

### 2. 修改主處理函數

**修改**：`process_file_chunking_and_vectorization()`

```python
async def process_file_chunking_and_vectorization(
    file_id: str,
    file_path: str,
    file_type: Optional[str],
    user_id: str,
) -> None:
    """
    異步處理文件分塊、向量化和知識圖譜提取（並行處理）
    """
    # 階段1: 分塊（保持不變）
    chunks = await process_chunking(...)
    
    # 階段2: 並行處理向量化和知識圖譜提取
    vectorization_task = process_vectorization_async(
        file_id=file_id,
        chunks=chunks,
        user_id=user_id,
    )
    
    kg_extraction_task = process_kg_extraction_async(
        file_id=file_id,
        chunks=chunks,
        user_id=user_id,
        options=kg_config,
    )
    
    # 等待兩個任務都完成（允許部分失敗）
    results = await asyncio.gather(
        vectorization_task,
        kg_extraction_task,
        return_exceptions=True,
    )
    
    # 檢查結果並更新最終狀態
    vectorization_success = not isinstance(results[0], Exception)
    kg_extraction_success = not isinstance(results[1], Exception)
    
    if vectorization_success and kg_extraction_success:
        overall_status = "completed"
    elif vectorization_success or kg_extraction_success:
        overall_status = "partial_completed"  # 新增狀態
    else:
        overall_status = "failed"
    
    _update_processing_status(
        file_id=file_id,
        overall_status=overall_status,
        overall_progress=100,
    )
```

### 3. 狀態模型擴展

**新增狀態**：`partial_completed`

```python
class ProcessingStatusModel(BaseModel):
    overall_status: str = Field(
        ...,
        description="總體狀態 (pending, processing, completed, failed, partial_completed)"
    )
    # ... 其他字段
```

---

## 📈 批量上傳優化

### 批量上傳策略

**當前實現**：
- 每個文件獨立提交到 RQ 隊列
- RQ Worker 並發處理多個文件

**優化建議**：

1. **批量提交優化**：
   - 批量上傳時，可以優先處理分塊階段
   - 所有文件分塊完成後，批量進行向量化和知識圖譜提取

2. **資源調度優化**：
   - 根據系統資源動態調整並發數
   - 向量化和知識圖譜提取使用不同的資源池

3. **優先級策略**：
   - 小文件優先處理（快速完成）
   - 大文件使用較低的並發數（避免資源競爭）

---

## ⚠️ 注意事項

### 1. 依賴關係

**確認**：
- ✅ 知識圖譜提取**不依賴**向量化結果
- ✅ 兩者都依賴分塊結果（chunks）
- ✅ 可以安全地並行處理

### 2. 狀態一致性

**確保**：
- ✅ 兩個任務的狀態更新不會衝突
- ✅ 最終狀態正確反映處理結果
- ✅ 部分失敗的情況正確處理

### 3. 錯誤處理

**考慮**：
- ⚠️ 向量化失敗時，知識圖譜提取仍可繼續
- ⚠️ 知識圖譜提取失敗時，向量化仍可繼續
- ⚠️ 需要新增 `partial_completed` 狀態

### 4. 資源限制

**監控**：
- ⚠️ Embedding 服務的並發限制（當前：3）
- ⚠️ LLM 服務的並發限制（當前：5）
- ⚠️ 確保並行處理不會超過資源限制

---

## 🧪 測試建議

### 測試場景

1. **單一文件並行處理**：
   - 驗證向量化和知識圖譜提取可以並行執行
   - 驗證狀態更新正確
   - 驗證錯誤處理機制

2. **批量文件並行處理**：
   - 驗證多個文件的並行處理
   - 驗證資源利用率提升
   - 驗證總處理時間減少

3. **部分失敗場景**：
   - 向量化失敗，知識圖譜提取成功
   - 知識圖譜提取失敗，向量化成功
   - 驗證 `partial_completed` 狀態

4. **資源限制場景**：
   - 驗證並發數不超過資源限制
   - 驗證資源調度正確

---

## 📝 實施計劃

### 階段 1：準備工作（1-2 天）

1. **狀態模型擴展**：
   - 新增 `partial_completed` 狀態
   - 更新狀態更新邏輯

2. **函數重構**：
   - 創建 `process_vectorization_async()` 函數
   - 修改 `process_kg_extraction()` 為異步函數

### 階段 2：實現並行處理（2-3 天）

1. **修改主處理函數**：
   - 修改 `process_file_chunking_and_vectorization()`
   - 實現並行處理邏輯

2. **錯誤處理**：
   - 實現部分失敗處理
   - 更新狀態更新邏輯

### 階段 3：測試與優化（2-3 天）

1. **單元測試**：
   - 測試並行處理邏輯
   - 測試錯誤處理機制

2. **集成測試**：
   - 測試批量文件上傳
   - 驗證性能提升

3. **性能測試**：
   - 對比優化前後的處理時間
   - 驗證資源利用率提升

---

## 📚 相關文檔

- [文件上傳架構說明](./上傳的功能架構說明-v3.0.md) - 當前實現詳解
- [狀態管理系統](./上傳的功能架構說明-v3.0.md#狀態管理系統) - 狀態管理機制
- [向量化系統](./上傳的功能架構說明-v3.0.md#向量化系統) - 向量化處理詳解
- [知識圖譜系統](./上傳的功能架構說明-v3.0.md#知識圖譜系統) - 知識圖譜提取詳解

---

## 🎯 結論

**推薦方案**：**方案 A（並行處理）**

**理由**：
1. ✅ **最高效率**：總處理時間減少約 28.6%
2. ✅ **資源充分利用**：資源利用率提升約 40%
3. ✅ **技術可行**：知識圖譜提取不依賴向量化結果
4. ✅ **狀態管理支持**：當前狀態管理機制已支持並行處理

**實施優先級**：**中高優先級**

**預期收益**：
- 批量文件上傳處理時間減少約 30%
- 系統資源利用率提升約 40%
- 用戶體驗改善（更快的處理速度）

---

**最後更新日期**: 2026-01-02

