# 文件上傳功能架構說明 v3.0

## 文檔信息

- **版本**: 3.0
- **創建日期**: 2025-01-27
- **創建人**: Daniel Chung
- **最後修改日期**: 2026-01-05

**更新記錄**：

- 2025-12-29：添加文件存儲後端說明和 S3 URI 返回格式說明
- 2025-12-31：更新分塊策略說明，添加語義分塊詳細特性（代碼塊/表格保護、質量評估、自適應大小）
- 2026-01-02：v3.0 版本，整合文件管理、狀態管理內容，重新整理文檔結構
- 2026-01-02：添加文件授權管理系統章節，基於 AI 治理原則的分層訪問控制機制
- 2026-01-03：添加 GraphRAG 裁決層（Judgment Layer）說明，包括置信度過濾、核心節點識別和統計信息
- 2026-01-05：添加文件摘要生成功能說明（階段 1.5），包括摘要格式、存儲位置、用途和超時保護機制
- 2026-01-05：添加狀態恢復機制說明，解決 Redis 狀態過期後無法查詢正確狀態的問題，實現從 ArangoDB 自動恢復

---

## 目錄

1. [概述](#概述)
2. [系統功能現況盤點](#系統功能現況盤點)
3. [完整流程追蹤](#完整流程追蹤)
4. [文件管理系統](#文件管理系統)
5. [狀態管理系統](#狀態管理系統)
6. [文件存儲系統](#文件存儲系統)
7. [文件授權管理系統](#文件授權管理系統)
8. [Ontology 系統詳解](#ontology-系統詳解)
9. [向量化系統](#向量化系統)
10. [知識圖譜系統](#知識圖譜系統)
11. [文件上傳後顯示問題分析](#文件上傳後顯示問題分析)
12. [相關服務和依賴](#相關服務和依賴)
13. [文件存儲後端說明](#文件存儲後端說明)
14. [API 端點總結](#api-端點總結)
15. [數據流](#數據流)
16. [已知問題與改進計劃](#已知問題與改進計劃)

---

## 概述

本文檔詳細說明 AI-Box 系統中文件上傳功能的完整架構，包括前端觸發、API 調用、後端處理、異步任務執行，以及 Ontology 在知識圖譜提取中的應用。

### 主要功能

- 多文件上傳（支持拖拽和點擊選擇）
- 文件類型驗證（PDF, Word, Excel, Markdown, CSV, TXT, 圖片等）
- 自動任務創建（首次上傳時）
- 異步處理流程（分塊、向量化、知識圖譜提取）
- Ontology 自動選擇和應用
- 實時進度追蹤

---

## 系統功能現況盤點

本文檔描述的功能架構與實際代碼實現的對比分析，幫助讀者了解系統的實際狀態和待改進點。

### 功能實現狀態總覽

| 功能模塊 | 實現狀態 | 完成度 | 備註 |
|---------|---------|--------|------|
| **文件上傳** | ✅ 已實現 | 100% | API端點、驗證、存儲完整 |
| **文件分塊** | ✅ 已實現 | 100% | 語義分塊、代碼塊/表格保護 |
| **向量化** | ✅ 已實現 | 100% | Embedding服務、批量處理 |
| **向量存儲** | ✅ 已實現 | 100% | ChromaDB集成、ACL支持 |
| **知識圖譜提取** | ✅ 已實現 | 95% | 增量提取、分塊續跑 |
| **Ontology選擇** | ✅ 已實現 | 100% | 自動選擇、優先級降級 |
| **Ontology合併** | ⚠️ 部分實現 | 80% | 全部合併模式，缺少Fallback模式 |
| **狀態管理** | ✅ 已實現 | 100% | Redis+ArangoDB雙寫、狀態恢復 |
| **文件元數據** | ✅ 已實現 | 100% | CRUD操作、多租戶支持 |
| **文件授權管理** | ⏸️ 規劃中 | 0% | 設計完成，待實施 |
| **HybridRAG圖檢索** | ✅ 已實現 | 100% | 完整實現實體識別、匹配、圖遍歷和結果格式化 |

### 核心功能實現詳情

#### ✅ 已完全實現的功能

##### 1. 文件上傳與驗證

**實現位置**: `api/routers/file_upload.py` 第 2051-2564 行

**實現狀態**:
- ✅ 多文件上傳支持（`upload_files` 函數）
- ✅ 文件類型驗證（`FileValidator`）
- ✅ 文件大小限制檢查
- ✅ 自動任務創建邏輯
- ✅ 文件存儲（本地/S3）

**與文檔一致性**: ✅ 完全一致

##### 2. 文件分塊處理

**實現位置**: `services/api/processors/chunk_processor.py`

**實現狀態**:
- ✅ 語義分塊策略（SEMANTIC）
- ✅ 代碼塊保護（單獨成塊）
- ✅ 表格保護（包含上下文）
- ✅ 質量評估和統計
- ✅ ChunkConfig 配置類支持

**與文檔一致性**: ✅ 完全一致

##### 3. 向量化與存儲

**實現位置**: 
- `services/api/services/embedding_service.py` - 向量生成
- `services/api/services/vector_store_service.py` - 向量存儲

**實現狀態**:
- ✅ 批量向量生成（`generate_embeddings_batch`）
- ✅ 並發控制（信號量機制）
- ✅ ChromaDB 存儲（`store_vectors`）
- ✅ 向量查詢（`query_vectors`）
- ✅ ACL 權限過濾（`query_vectors_with_acl`）

**與文檔一致性**: ✅ 完全一致

##### 4. 知識圖譜提取

**實現位置**: `services/api/services/kg_extraction_service.py`

**實現狀態**:
- ✅ 增量提取（`extract_and_build_incremental`）
- ✅ 分塊續跑機制
- ✅ Ontology 自動選擇和應用
- ✅ GraphRAG 裁決層（置信度過濾）
- ✅ 失敗重試機制

**與文檔一致性**: ✅ 完全一致

##### 5. 狀態管理

**實現位置**: `services/api/services/upload_status_service.py`

**實現狀態**:
- ✅ Redis + ArangoDB 雙寫模式
- ✅ 狀態恢復機制（從 ArangoDB 恢復）
- ✅ 上傳進度追蹤
- ✅ 處理狀態追蹤（分塊、向量化、KG提取）

**與文檔一致性**: ✅ 完全一致

#### ⚠️ 部分實現的功能

##### 1. Ontology 合併機制

**實現位置**: `services/api/services/ontology_store_service.py` 第 792-969 行

**實現狀態**:
- ✅ 全部合併模式（Base → Domain → Major）
- ✅ OWL Domain/Range 約束合併
- ✗ 缺少 `mode` 參數（不支持 Fallback 模式）
- ✗ OWL 約束是追加而非替換

**與文檔差異**:
- **文檔描述**: 提到未來改進方向（混合模式、Fallback 模式）
- **實際實現**: 僅實現全部合併模式
- **差異點**: 缺少模式選擇參數，OWL 約束處理方式不同

##### 2. 文件上傳後顯示

**實現位置**: 
- `ai-bot/src/components/FileTree.tsx` 第 2308-2373 行
- `ai-bot/src/pages/Home.tsx` 第 843-882 行

**實現狀態**:
- ✅ `filesUploaded` 事件監聽
- ✅ `fileTree` prop 更新機制
- ✅ 延遲處理（3秒）
- ⚠️ 仍存在跳過事件監聽的問題（有 `fileTree` prop 時）

**與文檔差異**:
- **文檔描述**: 說明問題根因和改進計劃
- **實際實現**: 已部分改進，但仍存在已知問題
- **差異點**: 問題未完全解決，但已有改進措施

#### ✗ 未實現的功能

##### 1. HybridRAGService._graph_retrieval()

**實現位置**: `genai/workflows/rag/hybrid_rag.py` 第 168-176 行

**實現狀態**:
- ✅ 方法框架存在
- ✗ 實際邏輯未實現（返回空列表）
- ✅ 相關基礎設施已具備（NER、KGBuilder、查詢工具）

**與文檔差異**:
- **文檔描述**: [向量與圖檢索混合查詢邏輯](./向量與圖檢索混合查詢邏輯.md) 詳細描述了實現設計
- **實際實現**: 僅有框架，邏輯未實現
- **差異點**: 設計文檔完整，但代碼實現缺失

##### 2. 文件授權管理系統

**實現位置**: 設計文檔存在，代碼實現缺失

**實現狀態**:
- ✅ 設計方案完整（[文件授權管理方案](./文件授權管理方案.md)）
- ✅ 實施計劃詳細（[文件授權管理實施計劃](./文件授權管理實施計劃.md)）
- ✗ 代碼實現未開始

**與文檔差異**:
- **文檔描述**: 完整的授權管理設計方案
- **實際實現**: 僅有設計，無代碼實現
- **差異點**: 規劃階段，待實施

### 實現差異點總結

#### 1. 功能完整性差異

| 功能 | 文檔描述 | 實際實現 | 差異 |
|------|---------|---------|------|
| 文件上傳 | 完整流程 | ✅ 完全實現 | 無差異 |
| 向量化 | 完整流程 | ✅ 完全實現 | 無差異 |
| 知識圖譜 | 完整流程 | ✅ 完全實現 | 無差異 |
| Ontology合併 | 全部合併+改進計劃 | ⚠️ 僅全部合併 | 缺少改進功能 |
| 圖檢索 | 詳細設計 | ✗ 未實現 | 設計與實現不一致 |
| 文件授權 | 完整設計 | ✗ 未實現 | 設計與實現不一致 |

#### 2. 技術實現差異

**Ontology 合併方式**:
- **文檔**: 描述全部合併模式，並說明未來改進方向（Fallback 模式）
- **實現**: 僅實現全部合併模式，OWL 約束使用 `.append()` 追加
- **差異**: 缺少 `mode` 參數，無法切換合併策略

**圖檢索實現**:
- **文檔**: [向量與圖檢索混合查詢邏輯](./向量與圖檢索混合查詢邏輯.md) 提供完整實現設計
- **實現**: `_graph_retrieval()` 方法僅有框架，返回空列表
- **差異**: 設計完整但未實現，相關基礎設施已具備

#### 3. 問題狀態差異

**文件上傳後顯示問題**:
- **文檔**: 標記為"高優先級"問題，說明根因和改進計劃
- **實現**: 已部分改進（事件機制、延遲處理），但仍存在跳過事件監聽的問題
- **差異**: 問題狀態已更新，但未完全解決

**任務ID類型不匹配**:
- **文檔**: 標記為"低優先級"問題
- **實現**: 使用 `String()` 轉換處理，但未在類型定義層面統一
- **差異**: 已部分改進，但未完全解決

### 建議改進優先級

#### 高優先級（影響核心功能）

1. ~~**實現 HybridRAGService._graph_retrieval()**~~ ✅ **已完成**（2026-01-05）
   - ✅ 基礎設施已整合
   - ✅ 實體識別、匹配、圖遍歷和結果格式化已實現
   - 參考：[向量與圖檢索混合查詢邏輯](./向量與圖檢索混合查詢邏輯.md)

2. **修復文件上傳後顯示問題**
   - 移除跳過事件監聽的邏輯
   - 改進 prop 更新機制
   - 預計工作量：3-5 天

#### 中優先級（功能增強）

3. **Ontology 合併模式改進**
   - 添加 `mode` 參數支持 Fallback 模式
   - OWL 約束改為替換而非追加
   - 預計工作量：1-2 週

4. **統一任務ID類型**
   - 在 TypeScript 類型定義中統一使用字符串
   - 預計工作量：2-3 天

#### 低優先級（規劃功能）

5. **文件授權管理系統實施**
   - 按照實施計劃逐步實現
   - 預計工作量：2-3 個月

---

## 完整流程追蹤

### 1. 前端觸發階段

#### 1.1 組件位置

- **文件**: `ai-bot/src/components/ChatInput.tsx`
- **上傳按鈕**: 第 1433-1439 行

#### 1.2 點擊處理

```typescript
// 第 754-756 行
const handlePaperclipClick = () => {
  setShowFileUploadModal(true);
};
```

#### 1.3 文件上傳模態框

- **組件**: `FileUploadModal`
- **文件**: `ai-bot/src/components/FileUploadModal.tsx`
- **功能**:
  - 文件選擇和驗證
  - 拖拽上傳支持
  - 圖片預覽
  - 任務工作區選擇

#### 1.4 文件上傳處理

- **函數**: `handleFileUpload`
- **位置**: `ChatInput.tsx` 第 758-1012 行
- **關鍵邏輯**:
  - 任務創建檢查（新任務自動創建）
  - 調用 `uploadFiles` API
  - 進度更新
  - 結果處理和事件觸發

---

### 2. API 調用階段

#### 2.1 API 函數

- **文件**: `ai-bot/src/lib/api.ts`
- **函數**: `uploadFiles`
- **位置**: 第 509-651 行

#### 2.2 API 端點

- **URL**: `POST /api/v1/files/upload`
- **Content-Type**: `multipart/form-data`
- **參數**:
  - `files`: File[] (多個文件)
  - `task_id`: string (可選，任務ID)
  - `target_folder_id`: string (可選，目標資料夾ID)

#### 2.3 請求實現

使用 `XMLHttpRequest` 以支持進度追蹤：

```typescript
const xhr = new XMLHttpRequest();
xhr.upload.addEventListener('progress', (e) => {
  if (e.lengthComputable && onProgress) {
    const percentComplete = Math.round((e.loaded / e.total) * 100);
    onProgress(percentComplete);
  }
});
```

#### 2.4 響應格式

```typescript
interface FileUploadResponse {
  success: boolean;
  data?: {
    uploaded: Array<{
      file_id: string;
      filename: string;
      file_type: string;
      file_size: number;
      file_path: string;
    }>;
    errors: Array<{
      filename: string;
      error: string;
    }>;
    total: number;
    success_count: number;
    error_count: number;
  };
}
```

---

### 3. 後端處理階段

#### 3.1 路由定義

- **文件**: `api/routers/file_upload.py`
- **路由**: `@router.post("/upload")`
- **位置**: 第 1624-2064 行

#### 3.2 處理流程

##### 3.2.1 權限檢查

- **服務**: `FilePermissionService`
- **方法**: `check_upload_permission(current_user)`
- **位置**: 第 1679-1680 行

##### 3.2.2 任務處理邏輯

- **服務**: `UserTaskService`
- **邏輯**:
  1. 如果提供了 `task_id`，檢查任務是否存在
  2. 如果任務不存在，自動創建新任務（使用第一個文件名作為任務標題）
  3. 如果未提供 `task_id`，創建新任務並生成新的 `task_id`
- **位置**: 第 1685-1807 行

##### 3.2.3 文件驗證

- **服務**: `FileValidator`
- **方法**: `validate_upload_file(file_content, filename)`
- **驗證內容**:
  - 文件類型（MIME 類型和擴展名）
  - 文件大小（默認最大 50MB）
- **位置**: 第 1809 行、第 1849-1860 行

##### 3.2.4 文件存儲

- **服務**: `FileStorage`
- **方法**: `save_file(file_content, filename, task_id)`
- **存儲位置**: 任務工作區目錄（`data/tasks/{task_id}/workspace/`）
- **位置**: 第 1810 行、第 1881-1883 行

##### 3.2.5 元數據創建

- **服務**: `FileMetadataService`
- **方法**: `create(FileMetadataCreate(...))`
- **存儲位置**: ArangoDB `file_metadata` collection
- **位置**: 第 1892-1910 行

##### 3.2.6 異步處理任務提交

- **隊列**: `FILE_PROCESSING_QUEUE`
- **任務**: `process_file_chunking_and_vectorization_task`
- **位置**: 第 1986-2009 行

```python
queue = get_task_queue(FILE_PROCESSING_QUEUE)
job = queue.enqueue(
    process_file_chunking_and_vectorization_task,
    file_id=file_id,
    file_path=file_path,
    file_type=file_type,
    user_id=current_user.user_id,
)
```

---

### 4. 異步處理階段

#### 4.1 處理任務定義

- **文件**: `workers/tasks.py`
- **任務名**: `process_file_chunking_and_vectorization_task`

#### 4.2 處理流程函數

- **文件**: `api/routers/file_upload.py`
- **函數名**: `process_file_chunking_and_vectorization`
- **位置**: 第 401-839 行

#### 4.3 處理階段詳解

##### 階段 1: 文件解析和分塊 (0-50%)

- **進度**: 0-50%
- **功能**:
  - 解析文件內容（根據文件類型選擇對應的解析器）
  - 分塊處理（文本文件）或生成描述（圖片文件）
- **服務**:
  - `ParserFactory` - 根據文件類型獲取解析器
  - `ChunkProcessor` - 文本分塊處理（使用語義分塊策略）
- **位置**: 第 432-560 行

**分塊策略詳解**:

- **策略**: `SEMANTIC`（語義分塊，基於段落、句子邊界）
- **默認 chunk_size**: 768 字符（約 15-25 行，取決於每行長度）
- **特殊內容保護**:
  - **代碼塊**：每個代碼塊（包括 Mermaid 圖表）單獨成塊，不會被切斷
  - **表格**：每個表格單獨成塊，並自動包含前後上下文（默認前後各 3 行）
  - **文本段落**：可以組合多個段落，但不超過 chunk_size 限制
- **質量評估**：
  - 每個 chunk 都會進行質量評估（大小、類型、質量分數等）
  - 記錄質量統計（平均質量分數、過小/過大 chunk 數量等）
- **自適應大小**：
  - 根據內容類型自動調整 chunk 大小
  - 代碼塊可以更大（最大 2000 字符）
  - 文本和表格使用標準大小（768 字符）
- **配置類**：`ChunkConfig` 支持長期可配置策略
  - `chunk_size`: 默認分塊大小（768）
  - `max_code_block_size`: 代碼塊最大大小（2000）
  - `table_context_lines`: 表格上下文行數（3）
  - `enable_quality_check`: 啟用質量檢查（True）
  - `enable_adaptive_size`: 啟用自適應大小（True）
- **實現位置**: `services/api/processors/chunk_processor.py`

**圖片文件特殊處理**:

- 使用視覺模型（Vision Model）生成圖片描述
- 描述文本作為單個 chunk，不需要分塊
- 跳過知識圖譜提取階段

**文件摘要生成**（階段 1.5，在分塊完成後）:

- **進度**: 50% (與分塊階段並行)
- **功能**: 使用 LLM 生成文件摘要，用於後續 Ontology 語義匹配
- **服務**: `LLMMoEManager`
- **方法**: `_generate_file_summary_for_metadata()`
- **位置**: 第 462-560 行（函數定義），第 697-744 行（調用）
- **超時保護**: 30 秒超時，失敗不阻塞處理流程
- **摘要格式**:
  ```json
  {
    "domain": "領域名稱",
    "summary": "核心主題摘要",
    "key_concepts": ["概念1", "概念2", ...],
    "application_scenarios": ["場景1", "場景2", ...]
  }
  ```
- **存儲位置**: `file_metadata.custom_metadata.file_summary`
- **用途**:
  - 用於 Ontology 語義匹配選擇（優先使用預存摘要）
  - 提升 Ontology 選擇的準確性
  - 支持未來基於摘要的智能推薦功能

##### 階段 2: 向量化 (50-90%)

- **進度**: 50-90%
- **服務**: `EmbeddingService`
- **方法**: `generate_embeddings_batch(chunk_texts, progress_callback)`
- **位置**: 第 568-618 行

##### 階段 3: 存儲到 ChromaDB (90-100%)

- **進度**: 90-100%
- **服務**: `VectorStoreService`
- **方法**: `store_vectors(file_id, chunks, embeddings, user_id)`
- **位置**: 第 620-675 行

##### 階段 4: 知識圖譜提取 (90-100%)

- **進度**: 90-100%
- **服務**: `KGExtractionService`
- **方法**: `extract_and_build_incremental(...)`
- **位置**: 第 677-797 行
- **注意**: 圖片文件跳過此階段

**Ontology 應用**:

- 自動選擇合適的 Ontology（基於文件名、內容、元數據）
- 合併 Base、Domain、Major 三層 Ontology
- 生成 Prompt 模板（用於 LLM 調用）
- 詳細說明見 [Ontology 系統詳解](#ontology-系統詳解)

#### 4.4 狀態更新

- **存儲位置**: Redis + ArangoDB（雙寫模式）
- **函數**: `_update_processing_status`
- **位置**: 第 272-398 行
- **更新內容**:
  - 總體狀態和進度
  - 各階段狀態（chunking, vectorization, storage, kg_extraction）
  - 錯誤信息（如有）

---

### 5. 前端響應處理

#### 5.1 上傳成功處理

- **位置**: `ChatInput.tsx` 第 870-923 行
- **功能**:
  - 更新文件狀態為 `success`
  - 觸發 `fileUploaded` 事件
  - 觸發 `filesUploaded` 事件（通知文件樹更新）

```typescript
// 觸發文件上傳完成事件
window.dispatchEvent(new CustomEvent('fileUploaded', {
  detail: { fileIds: response.data.uploaded?.map((u: any) => u.file_id) || [] }
}));

// 觸發文件樹更新事件
window.dispatchEvent(new CustomEvent('filesUploaded', {
  detail: {
    taskId: finalTaskId,
    files: response.data.uploaded.map((u: any) => ({
      file_id: u.file_id,
      filename: u.filename,
      file_type: u.file_type,
      file_size: u.file_size,
    }))
  }
}));
```

#### 5.2 錯誤處理

- **位置**: `ChatInput.tsx` 第 934-1011 行
- **功能**:
  - 處理網絡錯誤
  - 嘗試使用模擬文件上傳（fallback）
  - 如果上傳失敗且是新任務，清除任務

---

## 文件管理系統

### 概述

文件管理系統提供完整的文件操作功能，包括文件上傳、下載、刪除、重命名、移動、複製等操作，以及文件夾（任務）管理功能。

### 文件操作功能

#### 文件右鍵選單操作

在文件項目上點擊右鍵，可執行以下操作：

1. **重新命名** - 修改文件名（待實現）
2. **移動目錄** - 將文件移動到其他資料夾（待實現）
3. **刪除文件** - 刪除文件及相關數據（待實現）
4. **複製** - 複製文件到剪貼板（待實現）
5. **複製路徑** - 複製文件路徑到剪貼板（待實現）
6. **剪下** - 剪下文件準備移動（待實現）
7. **貼上** - 貼上已剪下或複製的文件（待實現）
8. **標註到AI任務指令區** - 將文件附加到AI聊天輸入框（待實現）
9. **查看向量資料** - 查看文件的向量化數據（✅ 已實現，預覽頁籤）
10. **查看圖譜資料** - 查看文件的知識圖譜數據（✅ 已實現，預覽頁籤）
11. **查看文件信息** - 查看文件的詳細信息（✅ 已實現）

#### 資料夾右鍵選單操作

在資料夾（任務節點）上點擊右鍵，可執行以下操作：

1. **新增資料夾** - 在當前資料夾下創建新的子資料夾（待實現）
2. **新增檔案** - 上傳新文件到當前資料夾（待實現）

#### Header 工具欄操作

在右側文件瀏覽區域的 header 工具欄中，提供以下快捷操作：

1. **新增資料夾** - 創建新的資料夾（任務）（✅ 已實現 UI，⏸️ 待實現功能邏輯）
2. **新增檔案** - 上傳新文件（✅ 已實現 UI，⏸️ 待實現功能邏輯）
3. **搜尋檔案** - 搜尋檔案和文件內容（✅ 已實現）
4. **其他選項** - 顯示更多操作選單（✅ 已實現 UI，⏸️ 待實現功能邏輯）

### 文件操作技術實現

#### 錯誤處理

所有文件操作都包含完善的錯誤處理機制：

- **網絡錯誤處理**：連接失敗、請求超時、服務器錯誤
- **文件操作錯誤處理**：上傳失敗、刪除失敗、移動失敗
- **用戶提示**：成功提示、失敗提示、進行中提示

#### 權限檢查

所有文件操作都需要進行權限檢查：

- **文件讀取權限**：查看文件、預覽文件、下載文件
- **文件寫入權限**：上傳文件、修改文件、重新命名文件
- **文件刪除權限**：刪除文件
- **資料夾創建權限**：創建新資料夾（任務）
- **資料夾管理權限**：刪除資料夾、移動資料夾

#### 事務處理

對於涉及多個數據源的操作，需要保證事務一致性：

- **文件刪除**：文件系統 + ArangoDB（元數據）+ ChromaDB（向量數據）+ ArangoDB（知識圖譜）
- **資料夾刪除**：文件系統 + ArangoDB（元數據）+ ChromaDB（向量數據）+ ArangoDB（知識圖譜）+ 任務記錄
- **文件移動**：ArangoDB（更新元數據中的 task_id）

#### 異步處理模式（RQ）

文件處理採用 **RQ 背景任務** 模式（非同步），前端可即時看到『產生中』與分塊進度。

**流程概覽**：

1. **上傳**：前端上傳文件後，後端建立 `file_metadata`，並將處理任務送入 RQ
2. **分塊 / 向量化 / 存儲**：背景任務依序處理 chunking、embedding、向量存儲
3. **圖譜提取（KG）**：圖譜採 **分塊可續跑**：每個 chunk 完成就寫入 ArangoDB，並更新進度；若尚未全部完成，會自動排程下一輪續跑

**相關 API**：

- **上傳文件**：`POST /api/v1/files/upload`
- **查詢處理狀態**：`GET /api/v1/files/{file_id}/processing-status`
- **查詢 KG 分塊狀態**：`GET /api/v1/files/{file_id}/kg/chunk-status`
- **重新生成（向量/圖譜）**：`POST /api/v1/files/{file_id}/regenerate`

**前端顯示規則**：

- **向量 / 圖譜尚未生成**：若 `processing-status` 顯示 `pending / processing / in_progress`，UI 顯示『產生中』與刷新按鈕
- **圖譜分塊可視化**：在「圖譜」預覽視圖中顯示 chunk grid（綠：完成，灰：待處理，橘：可重試失敗，紅：永久失敗）
- **重新生成按鈕**：僅在任務 **失敗（failed）或判定超時** 時顯示

### 快捷鍵列表

#### 全局快捷鍵

- `Cmd/Ctrl + P`: 打開搜尋檔案對話框
- `Esc`: 關閉當前對話框或取消操作

#### 文件操作快捷鍵

- `F2`: 重新命名選中的文件或資料夾
- `Delete`: 刪除選中的文件或資料夾（需要確認）
- `Cmd/Ctrl + C`: 複製選中的文件或資料夾
- `Cmd/Ctrl + X`: 剪下選中的文件或資料夾
- `Cmd/Ctrl + V`: 貼上已複製或剪下的文件或資料夾

### 批量操作

- **批量選擇**：`Ctrl/Cmd + 點擊` 選擇多個項目，`Shift + 點擊` 選擇範圍
- **批量操作功能**：批量刪除、批量移動、批量複製、批量下載（待實現）
- **批量操作限制**：單次最多選擇 100 個項目，操作前需要確認對話框

### 數據驗證規則

#### 文件名規則

- **長度限制**：文件名長度不超過 255 個字符
- **字符限制**：不能包含以下字符：`/ \ : * ? " < > |`
- **保留名稱**：不能使用系統保留名稱（如 `CON`, `PRN`, `AUX` 等）

#### 文件大小限制

- **單個文件**：最大 100MB
- **批量上傳**：單次上傳總大小不超過 500MB
- **文件數量**：單次上傳最多 50 個文件

---

## 狀態管理系統

### 概述

狀態管理系統負責追蹤文件上傳、處理（分塊、向量化、知識圖譜提取）的完整生命週期，提供實時狀態查詢和進度追蹤功能。

### 狀態記錄架構

#### 1. 上傳狀態記錄

**存儲位置**：

- **Redis**: `upload:progress:{file_id}` (TTL: 1小時)
- **ArangoDB**: `upload_progress` collection (TTL索引: 1小時)

**記錄字段**：

```python
{
    "file_id": str,
    "status": str,              # "uploading", "completed", "failed"
    "progress": int,            # 0-100
    "file_size": int,          # 文件大小（字節）
    "uploaded_bytes": int,     # 已上傳字節數
    "updated_at": datetime      # 更新時間
}
```

**更新函數**：

- `_update_upload_progress()` - `api/routers/file_upload.py:299`

#### 2. 處理狀態記錄

**存儲位置**：

- **Redis**: `processing:status:{file_id}` (TTL: 2小時，用於實時查詢)
- **ArangoDB**: `processing_status` collection (持久化存儲，TTL索引: 24小時)

**記錄字段**：

```python
{
    "file_id": str,
    "overall_status": str,      # "pending", "processing", "completed", "failed"
    "overall_progress": int,    # 0-100
    "message": str,            # 狀態消息
    "chunking": {              # 分塊階段狀態
        "status": str,
        "progress": int,
        "message": str,
        "chunk_count": int      # 分塊數量
    },
    "vectorization": {         # 向量化階段狀態
        "status": str,
        "progress": int,
        "message": str
    },
    "storage": {               # 存儲階段狀態
        "status": str,
        "progress": int,
        "message": str,
        "collection_name": str, # ChromaDB collection名稱
        "vector_count": int     # 向量數量
    },
    "kg_extraction": {         # 知識圖譜提取階段狀態
        "status": str,
        "progress": int,
        "message": str,
        "entities_count": int,  # 實體數量（NER）
        "relations_count": int,  # 關係數量（RE）
        "triples_count": int,   # 三元組數量
        "mode": str,            # "all_chunks", "incremental"
        "job_id": str,          # RQ job ID
        "remaining_chunks": List, # 剩餘分塊（如果未完成）
        "failed_chunks": List,    # 失敗的分塊
        "failed_permanent_chunks": List # 永久失敗的分塊
    },
    "created_at": datetime,
    "updated_at": datetime
}
```

**更新函數**：

- `_update_processing_status()` - `api/routers/file_upload.py:334`（雙寫模式：Redis + ArangoDB）
- `UploadStatusService.create_processing_status()` - `services/api/services/upload_status_service.py:257`
- `UploadStatusService.update_processing_status()` - `services/api/services/upload_status_service.py:320`

#### 3. 文件元數據記錄

**存儲位置**：

- **ArangoDB**: `file_metadata` collection (永久存儲)

**記錄字段**：

```python
{
    "_key": str,                # file_id
    "file_id": str,
    "filename": str,
    "file_type": str,           # MIME類型
    "file_size": int,
    "user_id": str,
    "task_id": str,
    "folder_id": Optional[str],
    "storage_path": str,        # 文件存儲路徑（本地路徑或S3 URI）
    "tags": List[str],
    "description": Optional[str],
    "custom_metadata": Dict,     # 包含 file_summary（文件摘要）
    "status": str,              # "uploaded", "generated", etc.
    "processing_status": Optional[str], # 處理狀態摘要
    "chunk_count": Optional[int],       # 分塊數量
    "vector_count": Optional[int],     # 向量數量
    "kg_status": Optional[str],        # KG狀態（字符串，如"completed"）
    "upload_time": datetime,           # 上傳時間
    "created_at": datetime,
    "updated_at": datetime
}
```

**注意**：

- `file_metadata` **沒有**直接記錄 `entities_count` 和 `relations_count`，這些信息存儲在 `processing_status.kg_extraction` 中
- `custom_metadata` 中可能包含 `file_summary`（文件摘要），格式為 JSON 字符串，包含領域、摘要、關鍵概念和應用場景等信息

**更新函數**：

- `FileMetadataService.create()` - `services/api/services/file_metadata_service.py:52`
- `FileMetadataService.update()` - `services/api/services/file_metadata_service.py:121`

### 狀態轉換函數

#### 上傳進度更新

**函數**：`_update_upload_progress()`

- **位置**：`api/routers/file_upload.py:299`
- **功能**：更新文件上傳進度
- **存儲**：Redis + ArangoDB (`upload_progress` collection)

#### 處理狀態更新

**函數**：`_update_processing_status()`

- **位置**：`api/routers/file_upload.py:334`
- **功能**：更新處理狀態（雙寫模式：Redis + ArangoDB）
- **參數**：
  - `file_id`: 文件ID
  - `chunking`: 分塊狀態字典（可選）
  - `vectorization`: 向量化狀態字典（可選）
  - `storage`: 存儲狀態字典（可選）
  - `kg_extraction`: KG提取狀態字典（可選）
  - `overall_status`: 總體狀態（可選）
  - `overall_progress`: 總體進度（可選）
  - `message`: 狀態消息（可選）

#### 處理狀態服務

**類**：`UploadStatusService`

- **位置**：`services/api/services/upload_status_service.py:97`

**主要方法**：

1. **`create_processing_status()`** - 創建處理狀態記錄
2. **`get_processing_status()`** - 獲取處理狀態記錄
3. **`update_processing_status()`** - 更新處理狀態記錄
4. **`delete_processing_status()`** - 刪除處理狀態記錄

#### 狀態恢復機制

**問題背景**：

- Redis 中的處理狀態記錄 TTL 為 2 小時（進行中）或 24 小時（已完成）
- 當 Redis 狀態過期後，API 查詢可能返回錯誤的 "pending" 狀態
- 實際處理已完成，但狀態顯示錯誤

**解決方案**：

- **實現位置**：`api/routers/file_upload.py:get_processing_status()` (第 2663-2700 行)
- **恢復流程**：
  1. 優先從 Redis 讀取狀態（快速響應）
  2. 如果 Redis 中沒有狀態，從 ArangoDB 讀取持久化狀態
  3. 將恢復的狀態同步回 Redis（已完成：TTL 24 小時，進行中：TTL 2 小時）
  4. 返回恢復的狀態給客戶端

**優勢**：

- ✅ 提高系統可靠性（不因 Redis 過期而丟失狀態）
- ✅ 保持查詢性能（恢復後同步回 Redis）
- ✅ 支持長時間狀態查詢（已完成狀態 TTL 24 小時）

**實現細節**：

```python
# 從 Redis 讀取處理狀態
status_data_str = redis_client.get(status_key)

if status_data_str:
    # Redis 中有狀態，直接返回
    return status_data
else:
    # Redis 中沒有狀態，從 ArangoDB 恢復
    status_service = get_upload_status_service()
    processing_status = status_service.get_processing_status(file_id)
  
    if processing_status:
        # 轉換為 API 響應格式
        status_data = convert_to_api_format(processing_status)
      
        # 同步回 Redis
        ttl = 86400 if completed else 7200
        redis_client.setex(status_key, ttl, json.dumps(status_data))
      
        return status_data
```

### 狀態記錄完整性

#### 上傳階段記錄

| 項目     | 記錄位置                      | 字段            | 狀態 |
| -------- | ----------------------------- | --------------- | ---- |
| 上傳時間 | `file_metadata.upload_time` | `datetime`    | ✅   |
| 文件大小 | `file_metadata.file_size`   | `int`         | ✅   |
| 上傳進度 | `upload_progress.progress`  | `int (0-100)` | ✅   |
| 上傳狀態 | `upload_progress.status`    | `str`         | ✅   |

#### 向量化階段記錄

| 項目                | 記錄位置                                                                     | 字段            | 狀態 |
| ------------------- | ---------------------------------------------------------------------------- | --------------- | ---- |
| 分塊數量            | `file_metadata.chunk_count<br>``processing_status.chunking.chunk_count`  | `int`         | ✅   |
| 向量數量            | `file_metadata.vector_count<br>``processing_status.storage.vector_count` | `int`         | ✅   |
| 向量化狀態          | `processing_status.vectorization.status`                                   | `str`         | ✅   |
| 向量化進度          | `processing_status.vectorization.progress`                                 | `int (0-100)` | ✅   |
| ChromaDB Collection | `processing_status.storage.collection_name`                                | `str`         | ✅   |

#### 知識圖譜提取階段記錄

| 項目            | 記錄位置                                                                  | 字段            | 狀態 |
| --------------- | ------------------------------------------------------------------------- | --------------- | ---- |
| 實體數量（NER） | `processing_status.kg_extraction.entities_count`                        | `int`         | ✅   |
| 關係數量（RE）  | `processing_status.kg_extraction.relations_count`                       | `int`         | ✅   |
| 三元組數量      | `processing_status.kg_extraction.triples_count`                         | `int`         | ✅   |
| KG提取狀態      | `processing_status.kg_extraction.status<br>``file_metadata.kg_status` | `str`         | ✅   |
| KG提取進度      | `processing_status.kg_extraction.progress`                              | `int (0-100)` | ✅   |
| 剩餘分塊        | `processing_status.kg_extraction.remaining_chunks`                      | `List`        | ✅   |
| 失敗分塊        | `processing_status.kg_extraction.failed_chunks`                         | `List`        | ✅   |

---

## 文件存儲系統

### 概述

文件存儲系統負責文件的物理存儲，支持本地文件系統和 SeaweedFS/S3 兩種存儲後端。系統採用**單一存儲後端機制**，根據配置選擇使用其中一個，**不是同時備份到兩個地方**。

### 存儲後端選擇

**系統支持兩種存儲後端**：

1. **本地文件系統** (`LocalFileStorage`)：

   - 用於開發和測試環境
   - 文件存儲在 `./data/datasets/files` 或 `data/tasks/{task_id}/workspace/`
   - `file_path` 返回本地文件路徑
2. **SeaweedFS/S3** (`S3FileStorage`)：

   - 用於生產環境，支持 Kubernetes 無狀態擴展
   - 文件存儲在 SeaweedFS 分布式文件系統
   - `file_path` 返回 S3 URI（格式：`s3://bucket/key`）

### 配置優先級

存儲後端的選擇通過配置決定，優先級如下：

1. **明確指定**：如果明確指定 `storage_backend="local"` → 使用本地文件系統
2. **明確指定**：如果明確指定 `storage_backend="s3"` → 使用 SeaweedFS/S3
3. **環境自動選擇**：如果未指定，根據環境自動選擇：
   - 生產環境 (`ENV=production`) → 優先使用 SeaweedFS
   - 開發環境 → 優先使用本地文件系統

**實現位置**：

- `create_storage_from_config()` - `storage/file_storage.py:560`
- `get_storage()` - `api/routers/file_upload.py:135`

### 本地文件系統存儲

**使用條件**：

- `storage_backend="local"` 或未配置且 S3 不可用

**存儲路徑**：

1. **任務工作區模式**（優先）：

   ```
   data/tasks/{task_id}/workspace/{file_id}.{ext}
   ```
2. **傳統模式**（向後兼容）：

   ```
   ./data/datasets/files/{file_id[:2]}/{file_id}.{ext}
   ```

**實現**：

- `LocalFileStorage` - `storage/file_storage.py:125`
- `_get_file_path()` - `storage/file_storage.py:159`
- `save_file()` - `storage/file_storage.py:206`

**storage_path 字段**：

- 存儲在 `file_metadata.storage_path` 中
- 格式：本地文件路徑（如 `data/tasks/{task_id}/workspace/{file_id}.{ext}`）

### SeaweedFS/S3 存儲

**使用條件**：

- `storage_backend="s3"` 或生產環境且 S3 配置可用

**存儲位置**：

1. **AI-Box 服務**（默認）：

   - **Bucket**: `bucket-ai-box-assets`
   - **Key**: `tasks/{task_id}/workspace/{file_id}.{ext}`
   - **S3 URI格式**: `s3://bucket-ai-box-assets/tasks/{task_id}/workspace/{file_id}.{ext}`
2. **DataLake 服務**（可選，用於 DataLake 項目）：

   - **Bucket**: `bucket-datalake-assets`
   - **Key**: `tasks/{task_id}/workspace/{file_id}.{ext}`
   - **S3 URI格式**: `s3://bucket-datalake-assets/tasks/{task_id}/workspace/{file_id}.{ext}`

**實現**：

- `S3FileStorage` - `storage/s3_storage.py:30`
- `SeaweedFSService` enum - `storage/s3_storage.py:23`

**配置**：

- 環境變數：
  - `AI_BOX_SEAWEEDFS_S3_ENDPOINT`
  - `AI_BOX_SEAWEEDFS_S3_ACCESS_KEY`
  - `AI_BOX_SEAWEEDFS_S3_SECRET_KEY`
- 配置文件：`config/config.json` → `file_upload.storage_backend = "s3"`

**storage_path 字段**：

- 存儲在 `file_metadata.storage_path` 中
- 格式：`s3://{bucket}/{key}`（如 `s3://bucket-ai-box-assets/tasks/{task_id}/workspace/{file_id}.{ext}`）

### 文件遷移機制

**遷移腳本**：`scripts/migration/migrate_files_to_seaweedfs.py`

**用途**：

- 一次性將文件從本地文件系統遷移到 SeaweedFS
- 更新 `file_metadata.storage_path` 為 S3 URI
- **不是持續的雙重備份機制**

**遷移後**：

- 文件從本地遷移到 SeaweedFS
- `storage_path` 更新為 S3 URI
- 本地文件可選刪除（需手動備份）

### 文件讀取

**實現**：

- `LocalFileStorage.read_file()` - 從本地文件系統讀取
- `S3FileStorage.read_file()` - 從 SeaweedFS 讀取

**使用場景**：

- 文件編輯時讀取原始文件
- 向量化和圖譜提取時讀取文件內容
- 文件預覽和下載

---

## 文件授權管理系統

### 概述

文件授權管理系統基於 AI 治理原則，實現分層訪問控制機制，確保文件數據的安全性和合規性。系統支持四種訪問級別：全局公開（PUBLIC）、組織級（ORGANIZATION）、安全組級（SECURITY_GROUP）和私有（PRIVATE）。

### 核心特性

1. **分層授權機制**：

   - **PUBLIC**：全公司可見，適用於公開文檔
   - **ORGANIZATION**：授權組織部分可見，適用於部門共享文檔
   - **SECURITY_GROUP**：特定安全組授權，適用於項目文檔
   - **PRIVATE**：只有授權用戶可見（默認），適用於個人文檔
2. **數據分類與敏感性標籤**：

   - 結合 `DataClassification`（PUBLIC / INTERNAL / CONFIDENTIAL / RESTRICTED）
   - 支持 `SensitivityLabel`（PII, PHI, FINANCIAL, IP, CUSTOMER, PROPRIETARY）
   - 用戶權限級別必須匹配或高於文件分類級別
3. **最小權限原則**：

   - 默認私有訪問級別
   - 按需授權，明確授權列表
   - 支持臨時授權（過期時間）
4. **訪問審計**：

   - 記錄所有訪問嘗試（授權和拒絕）
   - 存儲到 `audit_logs` collection
   - 支持合規性檢查和審計報告

### 權限檢查流程

**檢查順序**（按優先級）：

1. **訪問權限過期檢查**：如果設置了過期時間，檢查是否已過期
2. **數據分類級別檢查**：用戶權限級別必須匹配或高於文件分類級別
3. **敏感性標籤檢查**：用戶必須擁有所有所需標籤的訪問權限
4. **訪問級別檢查**：
   - PUBLIC：檢查用戶是否有基本文件讀取權限
   - ORGANIZATION：檢查用戶是否屬於授權組織
   - SECURITY_GROUP：檢查用戶是否屬於授權安全組
   - PRIVATE：檢查用戶是否為文件所有者或在授權用戶列表中

### 向量和知識圖譜的訪問控制

**向量檢索權限過濾**：

- 在向量檢索時，自動過濾用戶無權訪問的文件向量
- 只返回通過權限檢查的檢索結果
- 確保 RAG 檢索結果符合訪問控制

**知識圖譜查詢權限過濾**：

- 在知識圖譜查詢時，自動過濾用戶無權訪問的文件知識圖譜數據
- 只返回通過權限檢查的實體和關係
- 確保圖查詢結果符合訪問控制

### 實施狀態

**當前狀態**：⏸️ **規劃中**

**實施階段**：

- **階段一**：基礎模型擴展（優先級：高）
- **階段二**：權限檢查邏輯（優先級：高）
- **階段三**：向量和圖譜權限過濾（優先級：中）
- **階段四**：審計和合規（優先級：中）

### 相關文檔

詳細的設計方案和實施建議請參閱：

- [文件授權管理方案](./文件授權管理方案.md) - 完整的授權管理設計方案
- [文件授權管理實施計劃](./文件授權管理實施計劃.md) - 詳細的實施計劃、時間表和檢查清單

---

## Ontology 系統詳解

### 實現狀態總覽

| 功能模塊 | 實現狀態 | 完成度 | 備註 |
|---------|---------|--------|------|
| **Base Layer** | ✅ 已實現 | 100% | 5W1H 基礎 Ontology |
| **Domain Layer** | ✅ 已實現 | 100% | Enterprise 等領域 Ontology |
| **Major Layer** | ✅ 已實現 | 100% | Manufacture、NotionEditor 等專業 Ontology |
| **ArangoDB 存儲** | ✅ 已實現 | 100% | OntologyStoreService |
| **Ontology 合併** | ⚠️ 部分實現 | 80% | 全部合併模式，缺少 Fallback 模式 |
| **自動選擇機制** | ✅ 已實現 | 100% | OntologySelector + 優先級降級 Fallback |
| **多租戶支持** | ✅ 已實現 | 100% | 租戶專屬 Ontology |
| **優先級降級策略** | ✅ 已實現 | 100% | Tier 1-4 自動降級機制 |

**相關文檔**: [Ontology 系統架構文檔](./Ontology系统.md) - 完整的 Ontology 系統架構說明

### 1. Ontology 概述

Ontology（本體）是知識圖譜的結構化定義，用於約束實體類型和關係類型。AI-Box 系統使用三層 Ontology 架構：

- **Base Layer（基礎層）**: 通用實體和關係定義（如 Person, Organization, TimePoint 等）
- **Domain Layer（領域層）**: 特定領域的實體和關係（如 Enterprise, Administration 等）
- **Major Layer（專業層）**: 特定專業的實體和關係（如 Manufacture, NotionEditor 等）

### 2. Ontology 存儲架構

#### 2.1 存儲位置

**ArangoDB Collection**: `ontologies`

**數據結構**:

```python
{
  "_key": "{type}-{name}-{version}" 或 "{type}-{name}-{version}-{tenant_id}",
  "tenant_id": Optional[str],  # null 表示全局共享
  "type": "base" | "domain" | "major",
  "name": str,  # Ontology 名稱
  "version": str,  # 語義化版本（如 "1.0.0"）
  "default_version": bool,
  "ontology_name": str,
  "entity_classes": List[EntityClass],
  "object_properties": List[ObjectProperty],
  "is_active": bool,
  "created_at": str,
  "updated_at": str,
  # ... 其他元數據
}
```

#### 2.2 存儲服務

**服務**: `OntologyStoreService`

- **文件**: `services/api/services/ontology_store_service.py`
- **功能**:
  - Ontology CRUD 操作
  - 多租戶支持（租戶專屬 Ontology）
  - 版本管理
  - Ontology 合併

#### 2.3 查詢優先級

**方法**: `get_ontology_with_priority`

- **優先級**: 租戶專屬 > 全局共享
- **位置**: `ontology_store_service.py` 第 221-283 行

```python
# 1. 先查詢租戶專屬的默認版本
if tenant_id:
    filters = {
        "tenant_id": tenant_id,
        "type": type,
        "name": name,
        "default_version": True,
        "is_active": True,
    }
    results = self._collection.find(filters, limit=1, sort=["-created_at"])
    if results:
        return _document_to_model(results[0])

# 2. 再查詢全局共享的默認版本
filters = {
    "tenant_id": None,
    "type": type,
    "name": name,
    "default_version": True,
    "is_active": True,
}
results = self._collection.find(filters, limit=1, sort=["-created_at"])
if results:
    return _document_to_model(results[0])
```

### 3. Ontology 在知識圖譜提取中的應用

#### 3.1 自動選擇機制（優先級降級 Fallback）

**實現狀態**: ✅ **已實現**

**選擇器**: `OntologySelector`

- **文件**: `kag/ontology_selector.py`
- **方法**: `select_auto(file_name, file_content, file_metadata)`
- **選擇策略**:
  1. 從文件名提取關鍵字
  2. 從文件內容預覽（前1000字符）提取關鍵字
  3. 從元數據提取文檔類型
  4. 匹配 `ontology_list.json` 中的關鍵字索引
  5. 驗證 Major 與 Domain 的兼容性

**位置**: `kg_extraction_service.py` 第 199-216 行

**優先級降級策略**（已實現）:

系統採用優先級降級 fallback 機制，從最精確的 Major Ontology 逐步降級到 Domain、Base，最終允許 LLM 自由發揮：

1. **Tier 1: Major Ontology（優先嘗試）** - 最精確的專業層 Ontology
2. **Tier 2: Domain Ontology（如果 major 無法匹配）** - 領域層 Ontology
3. **Tier 3: Base 5W1H Ontology（如果 domain 找不到）** - 基礎層 Ontology
4. **Tier 4: LLM 自由發揮（如果都沒有）** - 允許 LLM 自由提取，不施加 Ontology 約束

**實現位置**: `kg_extraction_service.py` 第 226-292 行

**詳細說明**: [Ontology选择策略-优先级降级fallback实现说明](./Ontology选择策略-优先级降级fallback实现说明.md)

```python
selection = self.ontology_selector.select_auto(
    file_name=file_name,
    file_content=file_content_preview,
    file_metadata=file_metadata,
)
domain_files = selection.get("domain", [])
major_file = selection.get("major", [None])[0] if selection.get("major") else None
```

#### 3.2 合併機制

**實現狀態**: ⚠️ **部分實現**（全部合併模式已實現，Fallback 模式未實現）

**當前實現**: 全部合併模式（Base → Domain → Major）

**合併順序**:

1. **Base Layer**: 載入基礎 Ontology
2. **Domain Layer**: 載入領域 Ontology（擴展 Base）
3. **Major Layer**: 載入專業 Ontology（擴展 Domain）

**合併邏輯**:

- **文件系統模式**: `kag/kag_schema_manager.py` 第 102-197 行
- **ArangoDB 模式**: `ontology_store_service.py` 第 523-643 行

```python
# 合併順序：base → domain → major
# 1. 載入 base ontology
base_ontology = self.get_ontology_with_priority("5W1H_Base_Ontology_OWL", "base", tenant_id)

# 2. 載入 domain ontologies
for domain_file in domain_files:
    domain_ontology = self.get_matching_ontology(domain_file, "domain", tenant_id)
    # 合併實體和關係...

# 3. 載入 major ontology
if major_file:
    major_ontology = self.get_matching_ontology(major_file, "major", tenant_id)
    # 合併實體和關係...
```

**合併結果**:

- 所有層的實體和關係都合併到一個統一的規則集中
- 後載入的層可以擴展或覆蓋前面的定義
- 最終結果包含所有層的定義

#### 3.3 Prompt 生成

**方法**: `OntologyManager.generate_prompt`

- **位置**: `kag_schema_manager.py` 第 207-272 行
- **功能**:
  - 根據合併後的 Ontology 規則生成 Prompt 模板
  - 包含實體列表、關係列表、OWL Domain/Range 約束
  - 用於 LLM 調用，指導三元組提取

```python
prompt_template = self.ontology_manager.generate_prompt(
    text_chunk=sample_text,
    ontology_rules=ontology_rules,
    include_owl_constraints=True,
)
```

#### 3.4 在文件上傳流程中的傳遞

**位置**: `api/routers/file_upload.py` 第 696-725 行

```python
# 獲取文件元數據用於 Ontology 選擇
file_metadata_obj = metadata_service.get(file_id)
file_metadata_dict = {
    "file_name": file_metadata_obj.filename,
    "file_type": file_metadata_obj.file_type,
    "file_size": file_metadata_obj.file_size,
}

# 將文件信息添加到 KG 配置中
kg_config_with_metadata = {
    **kg_config,
    "file_name": file_metadata_obj.filename,
    "file_metadata": file_metadata_dict,
}

# 傳遞給 KG 提取服務
await process_kg_extraction(
    file_id=file_id,
    chunks=chunks,
    user_id=user_id,
    options=kg_config_with_metadata,  # 包含 file_name 和 file_metadata
)
```

### 4. Ontology 合併方式分析

#### 4.1 Ontology 合併的目的

**核心目的**:

1. **統一規則集**: 將 Base、Domain、Major 三層 Ontology 合併為單一規則集，用於生成 Prompt
2. **指導 LLM 提取**: 為 NER/RE/RT 提取提供實體類型列表和關係類型列表，約束 LLM 的提取範圍
3. **提供驗證約束**: 通過 OWL Domain/Range 約束驗證提取的三元組合法性
4. **支持圖檢索**: 定義實體類型和關係類型，用於圖檢索時的類型過濾和匹配

**設計理念**:

- **分層架構**: Base（通用）→ Domain（領域）→ Major（專業），從通用到專業
- **組合使用**: 合併後提供完整的實體和關係類型選項，LLM 可以根據文檔內容選擇最合適的類型
- **向後兼容**: 即使沒有匹配的 Domain/Major Ontology，也能使用 Base Ontology 進行提取

#### 4.2 當前實現：全部合併模式

**實現位置**: `services/api/services/ontology_store_service.py` 第 792-969 行

**合併邏輯**:

```python
# 1. 載入 base ontology（必需）
base_ontology = self.get_ontology_with_priority("5W1H_Base_Ontology_OWL", "base", tenant_id)

# 2. 載入 domain ontologies（可多個）
for domain_file in domain_files:
    domain_ontology = self._find_ontology_by_file_or_name(...)
    # 合併實體和關係（追加到列表）
    merged_rules["entity_classes"].append(entity_name)
    merged_rules["relationship_types"].append(rel_name)
    # OWL 約束追加（使用 .append()）
    merged_rules["owl_domain_range"][rel_name].append((domain_type, range_type))

# 3. 載入 major ontology（一個）
if major_file:
    major_ontology = self._find_ontology_by_file_or_name(...)
    # 合併實體和關係（追加到列表）
    # OWL 約束追加（使用 .append()）
```

**優點**:

- ✅ **語義完整**: 所有層的定義都可用，LLM 有更多選擇
- ✅ **性能好**: 一次合併，O(1) 查詢，無需逐層查找
- ✅ **實現簡單**: 邏輯直觀，易於維護
- ✅ **靈活性高**: 支持跨層組合，適應不同文檔類型
- ✅ **Prompt 生成簡單**: 直接使用合併後的完整列表生成 Prompt

**缺點**:

- ⚠️ **可能過於寬鬆**: 所有層的實體/關係都可用，可能導致提取不夠精確
- ⚠️ **規則衝突處理不清晰**: 後載入覆蓋，但覆蓋策略不明確
- ⚠️ **OWL Domain/Range 約束是追加而非替換**: 可能產生約束衝突，影響驗證準確性
- ⚠️ **類型過濾不夠精確**: 圖檢索時類型列表包含所有層，可能包含不相關的類型

#### 4.3 對 NER/RE/RT 提取的影響

**全部合併模式的影響**:

##### 優點

1. **提供完整選項**: 合併後的 Ontology 提供所有層的實體類型和關係類型，LLM 有更多選擇
   - **示例**: 文檔中可能同時包含通用概念（Person, Organization）和專業概念（生產線、質量標準）
   - **效果**: LLM 可以根據上下文選擇最合適的實體類型

2. **支持跨領域提取**: 可以同時識別通用實體（Base）和專業實體（Major）
   - **示例**: 製造業文檔可能包含"張三（Person）"和"生產線（Manufacture 專業實體）"
   - **效果**: 提取結果更全面，覆蓋通用和專業概念

3. **靈活性高**: 適合處理混合領域的文檔
   - **示例**: 企業管理文檔可能涉及多個領域（Enterprise、Administration）
   - **效果**: 無需預先確定文檔領域，系統自動適應

##### 缺點

1. **可能過於寬鬆**: 所有層的實體/關係都可用，可能導致提取不夠精確
   - **問題**: LLM 可能選擇通用類型而非更精確的專業類型
   - **示例**: 選擇 "Product"（Base）而非 "預製菜產品"（Major 專業實體）

2. **噪聲增加**: 通用實體類型可能干擾專業領域的提取
   - **問題**: Prompt 中包含過多選項，可能分散 LLM 注意力
   - **影響**: 提取準確率可能下降

3. **OWL 約束衝突**: 追加模式可能導致約束衝突，影響驗證準確性
   - **問題**: 同一關係類型在不同層可能有不同的 Domain/Range 約束
   - **影響**: 驗證階段可能無法正確判斷三元組的合法性

**實際使用場景**:

```207:268:kag/kag_schema_manager.py
def generate_prompt(
    self,
    text_chunk: str,
    ontology_rules: Optional[Dict[str, Any]] = None,
    include_owl_constraints: bool = True,
) -> str:
    """
    根據合併後的 Ontology 規則生成提示詞
    
    生成實體列表字符串（entity_classes）
    生成關係列表字符串（relationship_types）
    生成 OWL Domain/Range 約束說明（owl_domain_range）
    """
```

合併後的 Ontology 用於：
- 生成實體類型列表（`entity_classes`）- 指導 NER 提取
- 生成關係類型列表（`relationship_types`）- 指導 RE 提取
- 生成 OWL 約束說明（`owl_domain_range`）- 指導 RT 提取和驗證

#### 4.4 對圖檢索的幫助

**全部合併模式的影響**:

##### 有幫助的方面

1. **實體類型過濾**: 在實體匹配時，可以使用 Ontology 定義的實體類型進行過濾
   ```aql
   FOR doc IN entities
       FILTER doc.type IN @ontology_entity_types
       AND doc.name == @entity_name
   ```
   - **優勢**: 可以快速過濾出相關類型的實體
   - **限制**: 由於合併了所有層，類型列表可能包含不相關的類型

2. **關係類型過濾**: 在圖遍歷時，可以使用 Ontology 定義的關係類型進行過濾
   ```aql
   FOR v, e IN 1..1 ANY @start_vertex @@edge_collection
       FILTER e.type IN @ontology_relation_types
   ```
   - **優勢**: 可以只查詢相關類型的關係
   - **限制**: 類型列表可能過於寬泛，包含不相關的關係類型

3. **類型驗證**: 可以使用 OWL Domain/Range 約束驗證查詢結果的合法性
   - **優勢**: 確保查詢結果符合 Ontology 定義的約束
   - **限制**: 約束衝突可能導致驗證不準確

##### 當前實現的限制

1. **類型過濾不夠精確**: 由於合併了所有層，類型列表可能包含不相關的類型
   - **問題**: 圖檢索時可能返回過多不相關的結果
   - **影響**: 檢索精度可能下降

2. **約束驗證可能衝突**: OWL 約束的追加模式可能導致驗證不準確
   - **問題**: 同一關係類型在不同層可能有不同的約束
   - **影響**: 驗證階段可能無法正確判斷結果的合法性

**改進方向**:

- 在圖檢索時，優先使用專業層（Major）的類型進行過濾
- 如果結果不足，再使用通用層（Base）的類型
- OWL 約束驗證時，優先使用專業層的約束

#### 4.5 未來改進方向：Fallback 模式（預計下個迭代）

**設計理念**: 優先使用專業層定義，類似類繼承，子類優先於父類

**優點**:

- ✅ **語義更嚴格**: 優先使用專業層定義，提取結果更精確
- ✅ **規則清晰**: 優先級明確（Major > Domain > Base）
- ✅ **更符合 OWL 繼承**: 類似類繼承，子類優先於父類
- ✅ **圖檢索更精確**: 類型過濾更精確，減少不相關結果
- ✅ **約束驗證更準確**: OWL 約束優先使用專業層，避免衝突

**缺點**:

- ⚠️ **實現複雜**: 需要實現查詢邏輯，逐層查找
- ⚠️ **性能開銷**: 查詢時需要逐層查找，可能影響性能
- ⚠️ **Prompt 生成複雜**: 需要動態決定哪些實體/關係可用

#### 4.6 建議的混合方案（推薦）

**設計理念**: 結合全部合併和 Fallback 模式的優點，在不同階段使用不同策略

**實現策略**:

1. **Prompt 生成階段**: 使用全部合併（提供所有選項給 LLM）
   - **目的**: 提供靈活性，讓 LLM 根據上下文選擇最合適的類型
   - **優勢**: LLM 有更多選擇，適合處理混合領域文檔
   - **實現**: `merge_ontologies(mode="merge")`

2. **驗證階段**: 使用 Fallback（驗證提取的三元組是否符合專業層約束）
   - **目的**: 提高驗證準確性，優先使用專業層約束
   - **優勢**: 驗證結果更精確，符合專業層定義
   - **實現**: `merge_ontologies(mode="fallback")` 用於驗證

3. **OWL Domain/Range 約束**: 使用 Fallback（優先使用專業層定義）
   - **目的**: 避免約束衝突，優先使用專業層約束
   - **優勢**: 約束清晰，避免衝突
   - **實現**: OWL 約束改為替換而非追加

4. **圖檢索階段**: 使用分層查詢（優先專業層，降級到通用層）
   - **目的**: 提高檢索精度，減少不相關結果
   - **優勢**: 檢索結果更精確
   - **實現**: 優先使用 Major 類型過濾，結果不足時使用 Base 類型

**改進計劃**:

- 在 `merge_ontologies` 方法中添加 `mode` 參數（"merge" 或 "fallback"）
- 在 Prompt 生成時使用 "merge" 模式
- 在驗證階段使用 "fallback" 模式
- OWL Domain/Range 約束改為替換而非追加
- 圖檢索時實現分層查詢邏輯

**預期效果**:

- ✅ **提取準確率提升**: 驗證階段使用專業層約束，提高提取準確性
- ✅ **檢索精度提升**: 圖檢索時優先使用專業層類型，減少不相關結果
- ✅ **保持靈活性**: Prompt 生成時仍提供所有選項，保持靈活性
- ✅ **避免約束衝突**: OWL 約束優先使用專業層，避免衝突

#### 4.7 總結對比

| 方面 | 全部合併模式 | Fallback 模式 | 混合方案（推薦） |
|------|------------|--------------|----------------|
| **NER/RE/RT 提取** | ✅ 靈活但可能不夠精確 | ✅ 精確但可能過於嚴格 | ✅ 平衡靈活性和精確性 |
| **圖檢索** | ⚠️ 類型過濾不夠精確 | ✅ 類型過濾精確 | ✅ 分層查詢，結果更準確 |
| **OWL 約束驗證** | ⚠️ 可能衝突 | ✅ 約束清晰 | ✅ 專業層優先，避免衝突 |
| **性能** | ✅ O(1) 查詢 | ⚠️ 需要逐層查找 | ✅ 大部分情況 O(1) |
| **實現複雜度** | ✅ 簡單 | ⚠️ 複雜 | ⚠️ 中等複雜度 |
| **Prompt 生成** | ✅ 簡單 | ⚠️ 複雜 | ✅ 簡單（使用 merge 模式） |

**建議**: 採用混合方案，在 Prompt 生成時使用全部合併（提供靈活性），在驗證和圖檢索時使用 Fallback（提高精確性）。這樣可以在保持靈活性的同時提高提取和檢索的準確性。

---

## 向量化系統

### 概述

向量化系統是強化 RAG 系統的核心組件，通過語義理解切片技術與 ChromaDB 向量存儲，實現精準的文檔檢索與知識增強。系統避免了傳統 RAG 系統中完整段落被切割的問題，提供了更高質量的知識檢索能力。

### 核心設計理念

**問題**：傳統 RAG 系統在文檔切片時，可能會將完整的段落、句子切割，導致語義不完整，影響檢索質量。

**解決方案**：

1. **語義理解切片**：通過大模型理解文意，識別語義邊界
2. **AST 驅動切片**：基於文檔結構（標題層級）進行切片
3. **智能分塊策略**：結合語義與結構，避免切割完整段落

### 分塊策略詳解

#### 語義分塊（SEMANTIC）

**策略**：`SEMANTIC`（語義分塊，基於段落、句子邊界）

**默認 chunk_size**：768 字符（約 15-25 行，取決於每行長度）

**特殊內容保護**：

- **代碼塊**：每個代碼塊（包括 Mermaid 圖表）單獨成塊，不會被切斷
- **表格**：每個表格單獨成塊，並自動包含前後上下文（默認前後各 3 行）
- **文本段落**：可以組合多個段落，但不超過 chunk_size 限制

**質量評估**：

- 每個 chunk 都會進行質量評估（大小、類型、質量分數等）
- 記錄質量統計（平均質量分數、過小/過大 chunk 數量等）

**自適應大小**：

- 根據內容類型自動調整 chunk 大小
- 代碼塊可以更大（最大 2000 字符）
- 文本和表格使用標準大小（768 字符）

**配置類**：`ChunkConfig` 支持長期可配置策略

- `chunk_size`: 默認分塊大小（768）
- `max_code_block_size`: 代碼塊最大大小（2000）
- `table_context_lines`: 表格上下文行數（3）
- `enable_quality_check`: 啟用質量檢查（True）
- `enable_adaptive_size`: 啟用自適應大小（True）

**實現位置**：`services/api/processors/chunk_processor.py`

### 向量生成

**服務**：`EmbeddingService`

- **位置**：`services/api/services/embedding_service.py`
- **方法**：`generate_embeddings_batch(chunk_texts, progress_callback)`

**特性**：

- **並發控制**：使用全局信號量控制並發請求數量
- **批量處理**：支持批量生成向量，提高效率
- **部分失敗容錯**：單個向量生成失敗不影響整個批次
- **重試機制**：支持自動重試失敗的請求

**配置**：

- `concurrency_limit`: 並發請求數量限制（默認 3）
- `batch_size`: 批量大小（默認 50，但不會超過 `concurrency_limit`）
- `max_retries`: 最大重試次數（默認 3）

### 向量存儲

**服務**：`VectorStoreService`

- **位置**：`services/api/services/vector_store_service.py`
- **方法**：`store_vectors(file_id, chunks, embeddings, user_id)`

**存儲位置**：ChromaDB

**特性**：

- **Collection 管理**：每個文件使用獨立的 collection（`file_{file_id}`）
- **元數據存儲**：存儲 chunk 文本、文件ID、用戶ID等元數據
- **失敗過濾**：自動過濾失敗的向量（空列表），確保數據一致性

### 相關文檔

- [強化 RAG 系統](./强化RAG系统.md) - 詳細的 RAG 系統架構說明
- [Embedding 服務並發控制修復報告](../備份與歸檔/文件管理歸檔/Embedding服務並發控制修復報告.md) - 並發控制實現細節

---

## 知識圖譜系統

### 概述

知識圖譜系統是 AI-Box 的核心知識表示架構，通過 NER/RE/RT 三元組提取技術，從文檔中提取結構化知識，存儲到 ArangoDB 圖數據庫中。系統支持圖查詢與推理，與向量檢索協同工作，提供深度的知識理解與關聯能力。

### 核心設計理念

**三元組提取**：

- **NER（Named Entity Recognition）**：命名實體識別
- **RE（Relation Extraction）**：關係抽取
- **RT（Relation Type）**：關係類型識別

**圖存儲**：ArangoDB 圖數據庫存儲實體與關係

**圖推理**：利用圖的邏輯關係進行多跳推理

### Ontology 約束

**Ontology 選擇策略**：採用優先級降級 fallback 機制

1. **Tier 1: Major Ontology**（優先嘗試）- 最精確的專業層 Ontology
2. **Tier 2: Domain Ontology**（如果 major 無法匹配）- 領域層 Ontology
3. **Tier 3: Base 5W1H Ontology**（如果 domain 找不到）- 基礎層 Ontology
4. **Tier 4: LLM 自由發揮**（如果都沒有）- 允許 LLM 自由提取，不施加 Ontology 約束

**詳細說明**：見 [Ontology 選擇策略](./Ontology选择策略-优先级降级fallback实现说明.md)

### 增量提取機制

**分塊可續跑**：

- 每個 chunk 完成就寫入 ArangoDB，並更新進度
- 若尚未全部完成，會自動排程下一輪續跑
- 支持失敗重試機制（每個 chunk 最多重試 3 次）

**狀態追蹤**：

- `remaining_chunks`: 剩餘待處理的分塊
- `failed_chunks`: 失敗的分塊（可重試）
- `failed_permanent_chunks`: 永久失敗的分塊（達到重試上限）

### 圖譜存儲

**存儲位置**：ArangoDB

**Collections**：

- `entities`: 實體集合（Vertex）
- `relations`: 關係集合（Edge）

**數據結構**：

- **實體**：包含 `file_id`, `name`, `type`, `metadata` 等字段
- **關係**：包含 `_from`, `_to`, `type`, `file_id`, `metadata` 等字段

### GraphRAG 裁決層（Judgment Layer）

**概述**：GraphRAG 裁決層是知識圖譜構建過程中的質量控制機制，負責評估和過濾候選三元組，確保只有高質量的知識被寫入圖譜。

**實現位置**：

- `genai/api/services/kg_builder_service.py` - `_judge_triples()` 方法
- `genai/api/services/kg_builder_service.py` - `build_from_triples()` 方法

**裁決規則**：

1. **置信度過濾**：

   - 低於 `min_confidence` 閾值（默認 0.5）的三元組不入圖
   - 避免證據不足或推測性的知識污染圖譜
2. **核心節點識別**：

   - 高於 `core_node_threshold` 閾值（默認 0.9）的三元組標記為核心節點
   - 核心節點通常是文檔的核心概念（主要人物、關鍵設備、重要流程等）
3. **置信度分佈統計**：

   - **高置信度**（>= 0.9）：文本中明確提及，證據充分
   - **中置信度**（0.7-0.9）：文本中提及，但需要一定推斷
   - **低置信度**（0.5-0.7）：文本中隱含，需要較多推斷
   - **被拒絕**（< 0.5）：證據不足，不入圖

**配置參數**：

- `min_confidence`：最小置信度閾值（默認 0.5）
- `core_node_threshold`：核心節點閾值（默認 0.9）
- `enable_judgment`：是否啟用裁決層（默認 True）

**配置方式**：

```python
# 在 kg_extraction_service 的 options 中配置
options = {
    "min_confidence": 0.5,          # 最小置信度閾值
    "core_node_threshold": 0.9,     # 核心節點閾值
    "enable_judgment": True,        # 啟用裁決層
}
```

**統計信息**：

裁決層會返回詳細的統計信息：

```python
{
    "judgment_stats": {
        "total": 100,              # 總三元組數量
        "filtered": 15,            # 被過濾的三元組數量
        "accepted": 85,            # 接受的三元組數量
        "core_nodes": 30,          # 核心節點數量
        "confidence_distribution": {
            "high": 30,            # >= 0.9
            "medium": 40,          # 0.7-0.9
            "low": 15,             # 0.5-0.7
            "rejected": 15         # < 0.5
        },
        "filter_rate": 0.15        # 過濾率
    }
}
```

**Prompt 層支持**：

裁決層的規則也在 Prompt 模板中體現（`kag/ontology/Prompt-Template.json`），要求模型：

- 對每個三元組給出置信度評估
- 標記核心節點（高置信度通常表示核心節點）
- 保守處理證據不足的情況

**詳細說明**：見 [GraphRAG Prompt 優化評估與建議](../../../GraphRAG_Prompt优化评估与建议.md)

### 圖譜查詢與推理

**圖查詢**：使用 AQL（ArangoDB Query Language）進行圖查詢

**多跳推理**：利用圖的邏輯關係進行多跳推理，發現隱藏的知識關聯

**與向量檢索協同**：

- 向量檢索：快速找到相關文檔和段落
- 圖譜檢索：發現實體和關係的深層關聯
- 混合檢索：結合向量和圖譜檢索結果，提供更全面的知識檢索

### 相關文檔

- [知識圖譜系統](./知识图谱系统.md) - 詳細的知識圖譜系統架構說明
- [Ontology 系統](./Ontology系统.md) - Ontology 系統架構詳解（包含合併機制、對提取和檢索的影響分析）
- [向量與圖檢索混合查詢邏輯](./向量與圖檢索混合查詢邏輯.md) - 基於 HybridRAGService 的向量與圖檢索混合查詢邏輯詳解

---

## 文件上傳後顯示問題分析

### 問題描述

文件上傳成功後，文件未及時顯示在「任務工作區」的文件樹中，必須手動刷新頁面才會正常顯示。

### 問題追蹤

#### 1. 事件觸發流程

**上傳成功後的事件觸發**:

- **位置**: `ChatInput.tsx` 第 900-918 行
- **事件**: `fileUploaded` 和 `filesUploaded`

```typescript
// 觸發文件上傳完成事件
window.dispatchEvent(new CustomEvent('fileUploaded', {
  detail: { fileIds: response.data.uploaded?.map((u: any) => u.file_id) || [] }
}));

// 觸發文件樹更新事件
window.dispatchEvent(new CustomEvent('filesUploaded', {
  detail: {
    taskId: finalTaskId,
    files: response.data.uploaded.map((u: any) => ({
      file_id: u.file_id,
      filename: u.filename,
      file_type: u.file_type,
      file_size: u.file_size,
    }))
  }
}));
```

#### 2. Home 組件的事件監聽

**位置**: `Home.tsx` 第 775-892 行

**監聽事件**: `filesUploaded`, `mockFilesUploaded`

**處理邏輯**:

```typescript
const handleFilesUploadedEvent = (event: CustomEvent) => {
  const { taskId, files } = event.detail;

  setSelectedTask((currentTask) => {
    // 檢查任務ID是否匹配
    const taskIdMatch = String(currentTask.id) === String(taskId);

    if (taskIdMatch) {
      // 將文件轉換為 FileNode 格式
      const newFileNodes: FileNode[] = files.map((file: any) => ({
        id: file.file_id,
        name: file.filename,
        type: 'file' as const,
      }));

      // 更新任務的文件樹
      const updatedFileTree = currentTask.fileTree
        ? [...currentTask.fileTree, ...newFileNodes]
        : newFileNodes;

      const updatedTask = {
        ...currentTask,
        fileTree: updatedFileTree,
      };

      // 保存到 localStorage 並同步到後台
      saveTask(updatedTask, true).catch((error) => {
        console.error('[Home] Failed to save task:', error);
      });

      return updatedTask;
    }
    return currentTask;
  });
};
```

**問題點**:

1. 只更新了 `selectedTask.fileTree`，但 FileTree 組件可能沒有及時響應
2. 如果 `selectedTask` 為 `undefined`，事件不會觸發更新
3. 任務ID匹配可能失敗（字符串 vs 數字類型問題）

#### 3. FileTree 組件的事件監聽

**位置**: `FileTree.tsx` 第 2238-2303 行

**關鍵邏輯**:

```typescript
useEffect(() => {
  const currentFileTree = fileTreeRef_current.current;

  // 如果有 fileTree prop，不監聽上傳事件（由父組件管理）
  if (currentFileTree && currentFileTree.length > 0) {
    console.log('[FileTree] Has fileTree prop, skipping upload event listeners');
    return;  // ⚠️ 問題：跳過事件監聽
  }

  const handleFilesUploaded = (event: CustomEvent) => {
    const detail = event.detail;
    if (detail.taskId) {
      if (taskId && detail.taskId === taskId) {
        // 延遲 500ms 後重新加載
        setTimeout(() => {
          loadTree();
        }, 500);
      }
    }
  };

  window.addEventListener('filesUploaded', handleFilesUploaded as EventListener);
  // ...
}, [taskId, loadTree]);
```

**問題點**:

1. **如果 FileTree 使用 `fileTree` prop，會跳過事件監聽**（第 2243-2248 行）
2. **依賴於父組件（Home）更新 `fileTree` prop**，但更新可能不夠及時
3. **延遲 500ms 可能不夠**，後端可能還沒完全保存文件元數據

#### 4. 問題根因分析

**根本原因**:

1. **雙重更新機制衝突**:

   - Home 組件通過 `filesUploaded` 事件更新 `selectedTask.fileTree`
   - FileTree 組件如果有 `fileTree` prop，會跳過事件監聽，依賴 prop 更新
   - 但 prop 更新可能不夠及時，導致文件樹未刷新
2. **任務ID類型不匹配**:

   - 前端使用數字類型（`task.id: number`）
   - 後端返回字符串類型（`task_id: string`）
   - 字符串比較可能失敗：`String(currentTask.id) === String(taskId)`
3. **時序問題**:

   - 文件上傳成功後立即觸發事件
   - 但後端可能還沒完全保存文件元數據到 ArangoDB
   - FileTree 重新加載時可能查詢不到新文件
4. **新任務創建時機**:

   - 如果上傳時創建了新任務，`selectedTask` 可能還沒更新
   - `filesUploaded` 事件處理時，`currentTask` 可能為 `undefined` 或舊任務

### 解決方案建議

#### 方案 1: 強制刷新機制（推薦）

在 `filesUploaded` 事件處理中，強制觸發 FileTree 重新加載：

```typescript
// Home.tsx
const handleFilesUploadedEvent = (event: CustomEvent) => {
  const { taskId, files } = event.detail;

  // 更新 selectedTask.fileTree
  setSelectedTask((currentTask) => {
    // ... 現有邏輯 ...
  });

  // 強制觸發 FileTree 更新事件
  window.dispatchEvent(new CustomEvent('fileTreeUpdated', {
    detail: {
      taskId: taskId,
      forceReload: true,  // 強制重新加載
      newFiles: files
    }
  }));
};
```

#### 方案 2: 增加延遲時間

將 FileTree 的延遲從 500ms 增加到 1000-1500ms：

```typescript
// FileTree.tsx
setTimeout(() => {
  loadTree();
}, 1500);  // 增加到 1.5 秒
```

#### 方案 3: 輪詢機制

在文件上傳成功後，輪詢檢查文件是否已出現在文件樹中：

```typescript
// 輪詢檢查文件是否已存在
const pollFileExists = async (fileId: string, maxAttempts = 10) => {
  for (let i = 0; i < maxAttempts; i++) {
    await new Promise(resolve => setTimeout(resolve, 500));
    const exists = await checkFileExists(fileId);
    if (exists) {
      // 觸發文件樹刷新
      window.dispatchEvent(new CustomEvent('fileTreeUpdated', {
        detail: { forceReload: true }
      }));
      break;
    }
  }
};
```

#### 方案 4: 統一事件處理（長期方案）

統一使用 `fileTreeUpdated` 事件，而不是多個不同的事件：

```typescript
// 統一的事件格式
window.dispatchEvent(new CustomEvent('fileTreeUpdated', {
  detail: {
    taskId: finalTaskId,
    action: 'upload',  // 'upload' | 'delete' | 'move' | 'rename'
    files: uploadedFiles,
    forceReload: true,
  }
}));
```

### 當前臨時解決方案

**用戶操作**: 手動刷新頁面（F5 或 Cmd+R）

**開發建議**:

1. 在文件上傳成功後，顯示提示信息："文件上傳成功，正在刷新文件樹..."
2. 自動觸發一次文件樹刷新（延遲 1-2 秒）
3. 如果刷新後仍看不到文件，提示用戶手動刷新

---

## 相關服務和依賴

### 前端服務

1. **FileUploadModal** (`ai-bot/src/components/FileUploadModal.tsx`)

   - 文件選擇和驗證
   - 拖拽上傳支持
   - 圖片預覽
2. **UploadProgress** (`ai-bot/src/components/UploadProgress.tsx`)

   - 上傳進度顯示
3. **API Client** (`ai-bot/src/lib/api.ts`)

   - `uploadFiles` 函數
   - 進度回調支持
4. **FileTree** (`ai-bot/src/components/FileTree.tsx`)

   - 文件樹顯示
   - 文件操作（重命名、移動、刪除等）
5. **Home** (`ai-bot/src/pages/Home.tsx`)

   - 任務管理
   - 文件樹狀態管理
   - 事件監聽和處理

### 後端服務

1. **FileValidator** (`services/api/utils/file_validator.py`)

   - 文件類型驗證
   - 文件大小驗證
2. **FileStorage** (`storage/file_storage.py`)

   - 文件物理存儲
   - 支持多種存儲後端（本地、S3等）
3. **FileMetadataService** (`services/api/services/file_metadata_service.py`)

   - 文件元數據管理
   - ArangoDB 存儲
4. **UserTaskService** (`services/api/services/user_task_service.py`)

   - 任務管理
   - 任務工作區創建
5. **TaskWorkspaceService** (`services/api/services/task_workspace_service.py`)

   - 任務工作區管理
6. **FilePermissionService** (`services/api/services/file_permission_service.py`)

   - 文件權限檢查
7. **ChunkProcessor** (`services/api/processors/chunk_processor.py`)

   - 文本分塊處理
   - 支持多種分塊策略（SEMANTIC, AST_DRIVEN, FIXED_SIZE, SLIDING_WINDOW）
   - 代碼塊和表格保護
   - 質量評估和統計
   - ChunkConfig 配置類支持
8. **EmbeddingService** (`services/api/services/embedding_service.py`)

   - 向量生成
9. **VectorStoreService** (`services/api/services/vector_store_service.py`)

   - 向量存儲到 ChromaDB
10. **KGExtractionService** (`services/api/services/kg_extraction_service.py`)

- 知識圖譜提取
- Ontology 載入和應用

11. **OntologyStoreService** (`services/api/services/ontology_store_service.py`)

    - Ontology CRUD 操作
    - Ontology 合併
    - 多租戶支持
12. **OntologyManager** (`kag/kag_schema_manager.py`)

    - Ontology 載入和合併（文件系統模式）
    - Prompt 生成
13. **OntologySelector** (`kag/ontology_selector.py`)

    - Ontology 自動選擇
    - 關鍵字匹配
14. **UploadStatusService** (`services/api/services/upload_status_service.py`)

    - 上傳和處理狀態管理

---

## 文件存儲後端說明

### 存儲後端選擇

系統支持兩種存儲後端：

1. **本地文件系統** (`LocalFileStorage`)：

   - 用於開發和測試環境
   - 文件存儲在 `./data/datasets/files`
   - `file_path` 返回本地文件路徑
2. **SeaweedFS/S3** (`S3FileStorage`)：

   - 用於生產環境，支持 Kubernetes 無狀態擴展
   - 文件存儲在 SeaweedFS 分布式文件系統
   - `file_path` 返回 S3 URI（格式：`s3://bucket/key`）

### 配置優先級

存儲後端的選擇通過配置決定，優先級如下：

1. **S3/SeaweedFS**（如果配置了 SeaweedFS 環境變數）
2. **本地文件系統**（fallback）

### S3 URI 格式說明

當使用 SeaweedFS 存儲時，`file_path` 字段返回 S3 URI：

- **格式**: `s3://{bucket}/{key}`
- **示例**: `s3://bucket-ai-box-assets/tasks/task-123/file-id.pdf`
- **Bucket 選擇**:
  - AI-Box 服務：`bucket-ai-box-assets`（默認）
  - DataLake 服務：`bucket-datalake-assets`（用於文件備份）

### 響應格式示例

**使用 SeaweedFS 時的響應**：

```json
{
  "success": true,
  "message": "所有文件上傳成功（1 個文件）",
  "data": {
    "uploaded": [
      {
        "file_id": "file-uuid-123",
        "filename": "document.pdf",
        "file_type": "application/pdf",
        "file_size": 1024000,
        "file_path": "s3://bucket-ai-box-assets/tasks/task-456/file-uuid-123.pdf",
        "task_id": "task-456",
        "folder_id": null
      }
    ],
    "errors": [],
    "total": 1,
    "success_count": 1,
    "error_count": 0,
    "task_id": "task-456"
  }
}
```

**使用本地文件系統時的響應**：

```json
{
  "success": true,
  "message": "所有文件上傳成功（1 個文件）",
  "data": {
    "uploaded": [
      {
        "file_id": "file-uuid-123",
        "filename": "document.pdf",
        "file_type": "application/pdf",
        "file_size": 1024000,
        "file_path": "./data/datasets/files/tasks/task-456/file-uuid-123.pdf",
        "task_id": "task-456",
        "folder_id": null
      }
    ],
    "errors": [],
    "total": 1,
    "success_count": 1,
    "error_count": 0,
    "task_id": "task-456"
  }
}
```

---

## API 端點總結

### 主要端點

1. **POST `/api/v1/files/upload`**
   - 文件上傳
   - 參數: `files` (multipart), `task_id` (form), `target_folder_id` (form)
   - 返回: 上傳結果和文件ID，包含 S3 URI（如果使用 SeaweedFS）或本地路徑（如果使用本地存儲）
   - 位置: `api/routers/file_upload.py` 第 1624-2064 行
   - **存儲後端**: 支持本地文件系統（LocalFileStorage）和 SeaweedFS（S3FileStorage）
   - **返回格式**: `file_path` 字段為 S3 URI（格式：`s3://bucket/key`）或本地文件路徑

### 輔助端點

2. **GET `/api/v1/files/upload/{file_id}/progress`**

   - 查詢上傳進度
   - 位置: `file_upload.py` 第 2112-2152 行
3. **GET `/api/v1/files/{file_id}/processing-status`**

   - 查詢處理狀態（分塊、向量化、KG提取）
   - 位置: `file_upload.py` 第 2155-2259 行
4. **GET `/api/v1/files/{file_id}/kg/chunk-status`**

   - 查詢 KG 分塊續跑狀態
   - 位置: `file_upload.py` 第 2262-2311 行
5. **GET `/api/v1/files/tree`**

   - 獲取文件樹結構
   - 參數: `user_id`, `task_id`
   - 位置: `api/routers/file_management.py`

---

## 數據流

### 請求流程

```
前端 FormData
  ↓
FastAPI multipart 解析
  ↓
文件驗證 (FileValidator)
  ↓
文件存儲 (FileStorage)
  ↓
元數據創建 (FileMetadataService → ArangoDB)
  ↓
異步任務提交 (RQ Queue)
  ↓
返回響應（包含 file_id）
  ↓
前端觸發 filesUploaded 事件
  ↓
Home 組件更新 selectedTask.fileTree
  ↓
FileTree 組件接收 fileTree prop 更新（或重新加載）
```

### 異步處理流程

```
RQ Worker 接收任務
  ↓
文件解析和分塊
  ↓
向量化 (EmbeddingService)
  ↓
存儲向量 (VectorStoreService → ChromaDB)
  ↓
Ontology 自動選擇 (OntologySelector)
  ↓
Ontology 載入和合併 (OntologyManager/OntologyStoreService)
  ↓
知識圖譜提取 (KGExtractionService)
  ↓
更新處理狀態 (Redis + ArangoDB)
```

---

## 已知問題與改進計劃

### 已知問題

#### 1. 文件上傳後未及時顯示（高優先級）

**問題**: 文件上傳成功後，文件未及時顯示在「任務工作區」的文件樹中，必須手動刷新頁面才會正常顯示。

**當前狀態**: ⚠️ **部分改進**

**已實現的改進**:

- ✅ FileTree 組件已監聽 `filesUploaded` 事件（`FileTree.tsx` 第 2345-2363 行）
- ✅ Home 組件已實現 `filesUploaded` 事件處理，更新 `fileTree` prop（`Home.tsx` 第 843-882 行）
- ✅ 支持 `fileTreeUpdated` 事件和 `forceReload` 機制（`FileTree.tsx` 第 2511-2518 行）
- ✅ 延遲時間已增加到 3 秒（`FileTree.tsx` 第 2352-2354 行，由 500ms 改為 3000ms）

**仍存在的問題**:

- ⚠️ FileTree 組件如果有 `fileTree` prop，仍會跳過事件監聽（`FileTree.tsx` 第 2313-2317 行）
- ⚠️ 依賴於父組件（Home）更新 `fileTree` prop，但更新可能不夠及時

**改進計劃**:

- 移除跳過事件監聽的邏輯，或改進 prop 更新機制
- 實現輪詢機制檢查文件是否存在
- 統一事件處理機制

#### 2. Ontology 合併方式（中優先級）

**當前實現**: 全部合併模式（Base → Domain → Major）

**當前狀態**: ✗ **未解決**

**實現位置**: `services/api/services/ontology_store_service.py` 第 792-969 行

**問題**:

- ⚠️ OWL Domain/Range 約束是追加而非替換（使用 `.append()`，第 845-847、888-890、932-934 行），可能產生衝突
- ⚠️ `merge_ontologies` 方法沒有 `mode` 參數，不支持不同的合併策略
- ⚠️ 規則衝突處理不清晰

**改進計劃**（預計下個迭代）:

- 在 `merge_ontologies` 方法中添加 `mode` 參數（"merge" 或 "fallback"）
- 實現混合模式：Prompt 生成使用全部合併，驗證使用 Fallback
- OWL Domain/Range 約束改為替換而非追加
- 明確同名定義的覆蓋策略

#### 3. 任務ID類型不匹配（低優先級）

**問題**: 前端使用數字類型，後端返回字符串類型，可能導致匹配失敗。

**當前狀態**: ⚠️ **部分改進**

**已實現的改進**:

- ✅ 使用 `String()` 轉換處理類型不匹配（`Home.tsx` 第 854 行：`String(currentTask.id) === String(taskId)`）
- ✅ 在多處使用 `String()` 轉換確保類型一致（共 6 處）

**仍存在的問題**:

- ⚠️ 未完全統一類型定義，前端仍使用數字類型（`task.id: number`）
- ⚠️ 後端返回字符串類型（`task_id: string`）
- ⚠️ 需要在類型定義層面統一，而不是依賴運行時轉換

**改進計劃**:

- 統一使用字符串類型（在 TypeScript 類型定義中）
- 改進類型轉換邏輯，或在 API 層面統一類型

#### 4. HybridRAGService._graph_retrieval() 實現（已完成）

**問題**: `HybridRAGService._graph_retrieval()` 方法只有框架，沒有實際實現，返回空列表。

**當前狀態**: ✅ **已實現**（2026-01-05）

**實現位置**: `genai/workflows/rag/hybrid_rag.py` 第 176-240 行

**實現說明**:

該方法已完整實現，包括以下功能：

1. ✅ **實體識別**：使用 `_extract_entities_from_query()` 從查詢中提取實體
2. ✅ **實體匹配**：使用 `_find_matching_entities()` 在 ArangoDB 中查找匹配的實體（支持精確匹配、LIKE 匹配、CONTAINS 匹配）
3. ✅ **圖遍歷**：使用 `KGBuilderService.get_entity_neighbors()` 和 `get_entity_subgraph()` 獲取實體的鄰居節點和子圖
4. ✅ **結果格式化**：使用 `_format_graph_results()` 將圖譜數據轉換為 Memory 格式

**已具備的基礎設施**:

- ✅ `NERService.extract_entities()` - 實體識別服務（`genai/api/services/ner_service.py`）
- ✅ `KGBuilderService.list_entities()` - 實體查詢服務（`genai/api/services/kg_builder_service.py` 第 686-711 行）
- ✅ `KGBuilderService.get_entity_neighbors()` - 獲取鄰居節點（`kg_builder_service.py` 第 712-723 行）
- ✅ `KGBuilderService.get_entity_subgraph()` - 獲取子圖（`kg_builder_service.py` 第 725-732 行）
- ✅ `fetch_neighbors()` - 圖查詢工具函數（`database/arangodb/queries.py` 第 25-62 行）
- ✅ `fetch_subgraph()` - 子圖查詢工具函數（`database/arangodb/queries.py` 第 65-103 行）

**輔助方法**:

- `_get_ner_service()` - 獲取 NER 服務實例（懶加載）
- `_get_kg_service()` - 獲取圖譜構建服務實例（懶加載）
- `_extract_entities_from_query(query)` - 從查詢中提取實體（第 251-282 行）
- `_find_matching_entities(entities, limit)` - 在 ArangoDB 中查找匹配的實體（第 284-346 行）
- `_format_graph_results(graph_results, query, limit)` - 將圖譜數據轉換為 Memory 格式（第 351-463 行）

**待完成任務**:

- ⏸️ 添加單元測試和集成測試（建議優先級：中）

**相關文檔**: [向量與圖檢索混合查詢邏輯](./向量與圖檢索混合查詢邏輯.md) - 詳細的實現設計方案和實現狀態

### 改進計劃

#### 短期改進（1-2 週）

1. **文件上傳後顯示問題**

   - 增加延遲時間
   - 實現強制刷新機制
   - 添加用戶提示
2. **錯誤處理改進**

   - 更詳細的錯誤信息
   - 重試機制

#### 中期改進（1-2 個月）

1. **批量上傳流程優化**

   - 實現向量化和知識圖譜提取並行處理
   - 優化批量上傳的資源利用率
   - 預期處理時間減少約 30%，資源利用率提升約 40%
   - 詳細方案見：[批量文件上傳流程優化方案](./批量文件上傳流程優化方案.md)
2. **Ontology 合併方式優化**

   - 實現混合模式
   - OWL 約束處理改進
   - 規則衝突處理
3. **性能優化**

   - 文件樹緩存機制
   - 增量更新機制

#### 長期改進（3-6 個月）

1. **統一事件系統**

   - 統一事件格式
   - 事件總線機制
2. **實時更新機制**

   - WebSocket 支持
   - 服務器推送更新

---

## 更新記錄

- **2025-01-27**: 初始版本，追蹤完整文件上傳流程
- **2025-12-08**: 添加文件創建操作日誌
- **2025-12-12**: 改進文件讀取邏輯，支持從元數據獲取 task_id 和 storage_path
- **2025-12-13**: 添加 KG 分塊續跑功能
- **2025-12-14**: 添加空白 Markdown 文件創建端點
- **2025-12-18**: Ontology 遷移到 ArangoDB 存儲
- **2025-12-19**: v2.0 版本，強化 Ontology 說明，添加文件上傳後顯示問題分析
- **2025-12-29**: 添加文件存儲後端說明和 S3 URI 返回格式說明
- **2025-12-31**: 更新分塊策略說明，詳細描述語義分塊特性（代碼塊/表格保護、質量評估、自適應大小、ChunkConfig 配置類）
- **2026-01-03**: 添加 GraphRAG 裁決層（Judgment Layer）說明，包括置信度過濾、核心節點識別和統計信息
- **2026-01-05**: 添加文件摘要生成功能說明，包括摘要格式、存儲位置和用途；添加狀態恢復機制說明，解決 Redis 狀態過期問題；添加向量與圖檢索混合查詢邏輯文檔鏈接；更新已知問題狀態，反映當前實際改進情況；添加 HybridRAGService._graph_retrieval() 未實現問題說明；添加系統功能現況盤點章節，對比文檔描述與實際實現的差異；完善 Ontology 合併方式分析，添加合併目的、對 NER/RE/RT 提取的影響、對圖檢索的幫助等詳細說明

---

## 附錄

### A. 相關文件列表

#### 前端文件

- `ai-bot/src/components/ChatInput.tsx` - 聊天輸入框組件
- `ai-bot/src/components/FileUploadModal.tsx` - 文件上傳模態框
- `ai-bot/src/components/UploadProgress.tsx` - 上傳進度組件
- `ai-bot/src/components/FileTree.tsx` - 文件樹組件
- `ai-bot/src/pages/Home.tsx` - 主頁組件（任務和文件樹管理）
- `ai-bot/src/lib/api.ts` - API 客戶端

#### 後端文件

- `api/routers/file_upload.py` - 文件上傳路由
- `api/main.py` - FastAPI 主入口（路由註冊）
- `workers/tasks.py` - RQ 任務定義
- `services/api/services/file_metadata_service.py` - 文件元數據服務
- `services/api/services/user_task_service.py` - 用戶任務服務
- `services/api/services/task_workspace_service.py` - 任務工作區服務
- `services/api/services/file_permission_service.py` - 文件權限服務
- `services/api/processors/chunk_processor.py` - 文件分塊處理器（語義分塊策略）
- `services/api/services/embedding_service.py` - 向量化服務
- `services/api/services/vector_store_service.py` - 向量存儲服務
- `services/api/services/kg_extraction_service.py` - 知識圖譜提取服務
- `services/api/services/ontology_store_service.py` - Ontology 存儲服務
- `services/api/services/upload_status_service.py` - 上傳狀態服務
- `storage/file_storage.py` - 文件存儲抽象層
- `services/api/utils/file_validator.py` - 文件驗證工具
- `kag/kag_schema_manager.py` - Ontology 管理器（文件系統模式）
- `kag/ontology_selector.py` - Ontology 選擇器

### B. 關鍵配置

#### 前端配置

- **API Base URL**: `VITE_API_BASE_URL` 或默認 `http://localhost:8000`
- **API Prefix**: `VITE_API_PREFIX` 或默認 `/api/v1`

#### 後端配置

- **文件上傳配置**: `config/config.json` → `file_upload` 區塊
- **分塊處理配置**: `config/config.json` → `chunk_processing` 區塊
  - `chunk_size`: 分塊大小（字符數，默認 768）
  - `strategy`: 分塊策略（`semantic`, `ast_driven`, `fixed_size`, `sliding_window`，默認 `semantic`）
  - `overlap`: 重疊比例（0-1之間，默認 0.2）
- **服務配置**: `config/config.json` → `services` 區塊
  - `kg_extraction.enabled`: 是否啟用知識圖譜提取
  - `kg_extraction.mode`: 提取模式（`all_chunks`, `selected_chunks`, `entire_file`）
  - `kg_extraction.min_confidence`: 最小置信度閾值（默認 0.5）
  - `kg_extraction.core_node_threshold`: 核心節點閾值（默認 0.9）
  - `kg_extraction.enable_judgment`: 是否啟用 GraphRAG 裁決層（默認 True）
- **存儲配置**: `config/config.json` → `storage` 區塊
- **ArangoDB 配置**: `.env` → `ARANGODB_*` 環境變數

### C. 注意事項

1. **任務關聯**: 所有文件必須關聯到任務工作區（不再支持 `temp-workspace`）
2. **異步處理**: 文件上傳成功後，處理任務在後台異步執行
3. **進度追蹤**: 上傳進度由前端 XMLHttpRequest 追蹤，處理進度由 Redis 存儲
4. **圖片文件**: 圖片文件使用視覺模型生成描述，跳過知識圖譜提取
5. **多文件上傳**: 支持一次上傳多個文件，每個文件獨立處理
6. **Ontology 支持**: 如果 Ontology 模組不可用，會降級為不使用 Ontology 的模式
7. **多租戶**: Ontology 支持多租戶隔離，租戶專屬 Ontology 優先於全局共享
8. **分塊策略**: 默認使用語義分塊策略（SEMANTIC），自動保護代碼塊和表格完整性
9. **分塊大小**: 默認 chunk_size 為 768 字符（約 15-25 行），可通過配置調整
10. **質量評估**: 分塊處理會自動進行質量評估和統計，記錄在日誌中

---

## 參考文檔

### 核心架構文檔

- [Ontology 系統](./Ontology系统.md) - Ontology 系統架構詳解
- [強化 RAG 系統](./强化RAG系统.md) - RAG 系統架構詳解
- [知識圖譜系統](./知识图谱系统.md) - 知識圖譜系統架構詳解
- [Ontology 選擇策略](./Ontology选择策略-优先级降级fallback实现说明.md) - Ontology 選擇策略實現說明
- [文件上傳向量圖譜化測試計劃](./文件上傳向量圖譜化測試計劃.md) - 測試計劃和驗證方法
- [批量文件上傳流程優化方案](./批量文件上傳流程優化方案.md) - 批量上傳並行處理優化方案
- [向量化與圖譜提取獨立執行優化報告](./向量化與圖譜提取獨立執行優化報告.md) - 向量化和圖譜提取獨立執行優化
- [文件授權管理方案](./文件授權管理方案.md) - 基於 AI 治理原則的文件授權管理設計方案
- [文件授權管理實施計劃](./文件授權管理實施計劃.md) - 文件授權管理功能的詳細實施計劃

### 技術實現文檔

- ArangoDB 數據存儲規範: `.cursor/rules/develop-rule.mdc` → ArangoDB 數據存儲規範
- Ontology 合併邏輯: `kag/kag_schema_manager.py` 第 102-197 行
- Ontology 存儲服務: `services/api/services/ontology_store_service.py`
- 知識圖譜提取服務: `services/api/services/kg_extraction_service.py`
- 文件分塊處理器: `services/api/processors/chunk_processor.py`
  - ChunkConfig 配置類（長期可配置策略）
  - 語義分塊策略（SEMANTIC）
  - 代碼塊和表格保護機制
  - 質量評估和統計
- 向量化服務: `services/api/services/embedding_service.py`
- 向量存儲服務: `services/api/services/vector_store_service.py`
- 狀態管理服務: `services/api/services/upload_status_service.py`
- 文件元數據服務: `services/api/services/file_metadata_service.py`

### 歸檔文檔

開發過程中的問題分析、測試報告等文檔已移至：

- `docs/備份與歸檔/文件管理歸檔/`
