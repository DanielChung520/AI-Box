# 向量化與圖譜提取獨立執行優化報告

**創建日期**: 2026-01-02
**創建人**: Daniel Chung
**最後修改日期**: 2026-01-21

---

## 📋 優化概述

本次優化解決了向量化和知識圖譜提取之間的依賴問題，實現了兩個階段的獨立執行和錯誤處理，支持部分完成狀態，並確保重新生成時正確清理舊數據。

**重要更新** (2026-01-21):

- ✅ 向量數據庫從 ChromaDB 遷移到 **Qdrant**
- ✅ 實現**雙軌 RAG 解析架構**（Stage 1 快速軌 + Stage 2 深度軌）
- ✅ Stage 1 和 Stage 2 的獨立執行與錯誤處理

---

## 🎯 優化目標

1. **獨立執行**：向量化失敗不影響知識圖譜提取，反之亦然
2. **清晰狀態**：支持部分完成狀態（`partial_completed`），明確標識哪些階段成功
3. **重新生成**：重新生成向量或圖譜時，正確清理舊數據
4. **文件記錄**：完整的狀態管理和日誌記錄
5. **雙軌架構**：Stage 1（快速軌）和 Stage 2（深度軌）的獨立執行與錯誤處理

---

## 🔧 實施內容

### 1. 狀態模型擴展

**文件**：`services/api/models/upload_status.py`

**修改**：

- 擴展 `ProcessingStatusModel.overall_status` 字段，新增 `partial_completed` 狀態

**狀態說明**：

- `pending`: 等待處理
- `processing`: 處理中
- `completed`: 全部完成（向量化和知識圖譜提取都成功）
- `partial_completed`: 部分完成（向量化或知識圖譜提取其中一個成功）
- `failed`: 全部失敗（向量化和知識圖譜提取都失敗）

### 2. 分離錯誤處理

**文件**：`api/routers/file_upload.py`

**函數**：`process_file_chunking_and_vectorization()`

**修改內容**：

#### 2.1 向量化階段（獨立錯誤處理）

**雙軌架構說明**：

- **Stage 1（快速軌）**: 快速完成基礎向量索引，立即提供檢索能力
- **Stage 2（深度軌）**: 背景任務，生成摘要和 Contextual Header，提升檢索精度

```python
# ========== Stage 1: 快速軌（基礎索引）(50-90%) ==========
vectorization_success = False
stats = None
try:
    # Stage 1: 快速向量化
    embeddings = await embedding_service.generate_embeddings_batch(...)
    vector_store_service.store_vectors(...)  # 基礎 Payload
    stats = vector_store_service.get_collection_stats(...)
    vectorization_success = True

    # Stage 2: 深度軌（背景任務）
    queue = get_task_queue(FILE_PROCESSING_QUEUE)
    job = queue.enqueue(
        process_dual_track_stage2_task,  # 背景任務
        file_id=file_id,
        ...
    )
except Exception as e:
    logger.error("向量化失敗（不影響知識圖譜提取）", ...)
    _update_processing_status(
        file_id=file_id,
        vectorization={"status": "failed", "error": str(e)},
    )
    # ⚠️ 不拋出異常，繼續執行知識圖譜提取
```

**關鍵點**：

- ✅ Stage 1 快速完成，立即提供檢索能力
- ✅ Stage 2 在背景任務中執行，不影響 Stage 1 的檢索功能
- ✅ 向量化失敗不拋出異常
- ✅ 記錄錯誤但不阻止後續處理
- ✅ 設置 `vectorization_success = False`

**詳細說明**: 請參閱 [AI-Box 雙軌 RAG 解析規格書](./AI-Box雙軌RAG解析規格書.md)

#### 2.2 知識圖譜提取階段（獨立錯誤處理）

```python
# ========== 階段4: 知識圖譜提取（獨立錯誤處理）(90-100%) ==========
kg_extraction_success = False
if not is_image_file:
    kg_enabled = kg_config.get("enabled", True)
    if kg_enabled:
        try:
            await process_kg_extraction(
                file_id=file_id,
                chunks=chunks,  # ✅ 使用分塊結果，不依賴向量化
                user_id=user_id,
                options=kg_config_with_metadata,
            )
            kg_extraction_success = True
        except Exception as e:
            logger.error("知識圖譜提取失敗（不影響向量化）", ...)
            _update_processing_status(
                file_id=file_id,
                kg_extraction={"status": "failed", "error": str(e)},
            )
            # ⚠️ 不拋出異常，繼續執行
```

**關鍵點**：

- ✅ 知識圖譜提取失敗不拋出異常
- ✅ 使用 `chunks` 進行提取，不依賴向量化結果
- ✅ 設置 `kg_extraction_success = False`

#### 2.3 最終狀態更新

```python
# ========== 更新最終狀態 ==========
if vectorization_success and kg_extraction_success:
    overall_status = "completed"
    final_message = "文件處理完成"
elif vectorization_success:
    overall_status = "partial_completed"
    final_message = "向量化完成，知識圖譜提取失敗"
elif kg_extraction_success:
    overall_status = "partial_completed"
    final_message = "知識圖譜提取完成，向量化失敗"
else:
    overall_status = "failed"
    final_message = "文件處理失敗（向量化和知識圖譜提取都失敗）"
```

**關鍵點**：

- ✅ 根據兩個階段的成功狀態決定最終狀態
- ✅ 支持 `partial_completed` 狀態
- ✅ 提供清晰的消息說明

### 3. 重新生成向量清理

**文件**：`api/routers/file_upload.py`

**函數**：`process_vectorization_only()`

**修改內容**：

```python
# ========== 階段2: 清理舊向量（重新生成時）==========
vector_store_service = get_vector_store_service()
try:
    # 檢查是否存在舊向量
    existing_stats = vector_store_service.get_collection_stats(file_id, user_id)
    if existing_stats.get("vector_count", 0) > 0:
        logger.info("清理舊向量以重新生成", ...)
        vector_store_service.delete_vectors_by_file_id(file_id, user_id)
        logger.info("舊向量清理完成", ...)
except Exception as e:
    logger.warning("清理舊向量時發生錯誤（繼續執行）", ...)
    # 不阻止重新生成流程
```

**關鍵點**：

- ✅ 重新生成前檢查是否存在舊向量
- ✅ 如果存在，先清理再重新生成
- ✅ 清理失敗不阻止重新生成流程

### 4. 重新生成圖譜清理

**文件**：`api/routers/file_upload.py`

**函數**：`process_kg_extraction_only()`

**修改內容**：

```python
# ========== 清理舊圖譜數據（重新生成時）==========
try:
    kg_builder_service = KGBuilderService()
    cleanup_result = kg_builder_service.remove_file_associations(file_id)
    if (
        cleanup_result.get("relations_deleted", 0) > 0
        or cleanup_result.get("entities_deleted", 0) > 0
    ):
        logger.info("清理舊圖譜數據以重新生成", ...)
    # 清理 chunk 狀態（重置續跑狀態）
    redis_client = get_redis_client()
    chunk_state_key = f"kg:chunk_state:{file_id}"
    redis_client.delete(chunk_state_key)
    logger.info("舊圖譜數據和狀態清理完成", ...)
except Exception as e:
    logger.warning("清理舊圖譜數據時發生錯誤（繼續執行）", ...)
    # 不阻止重新生成流程
```

**關鍵點**：

- ✅ 重新生成前清理舊的圖譜關聯（entities 和 relations）
- ✅ 清理 Redis 中的 chunk 狀態（重置續跑狀態）
- ✅ 清理失敗不阻止重新生成流程

---

## 📊 優化效果

### 1. 獨立執行能力

**優化前**：

- ❌ 向量化失敗會導致整個函數退出
- ❌ 知識圖譜提取永遠不會執行
- ❌ 即使技術上不依賴，實現上存在順序依賴

**優化後**：

- ✅ 向量化失敗不影響知識圖譜提取
- ✅ 知識圖譜提取失敗不影響向量化
- ✅ 兩個階段可以獨立執行

### 2. 狀態管理清晰

**優化前**：

- ❌ 只有 `completed` 和 `failed` 兩種狀態
- ❌ 無法區分部分完成的情況

**優化後**：

- ✅ 支持 `partial_completed` 狀態
- ✅ 明確標識哪些階段成功，哪些失敗
- ✅ 提供清晰的消息說明

### 3. 重新生成可靠性

**優化前**：

- ❌ 重新生成向量時，舊向量可能殘留
- ❌ 重新生成圖譜時，舊圖譜數據可能殘留
- ❌ 可能導致數據不一致

**優化後**：

- ✅ 重新生成前自動清理舊數據
- ✅ 確保數據一致性
- ✅ 清理失敗不阻止重新生成（記錄警告）

---

## 🔍 技術細節

### 依賴關係確認

| 階段 | 依賴 | 說明 |
|------|------|------|
| 分塊 (Chunking) | 無 | 只需要原始文件內容 |
| Stage 1: 快速向量化 | 分塊結果 (`chunks`) | 需要 `chunks` 中的 `text` 字段 |
| Stage 2: 深度軌 | 分塊結果 (`chunks`) | Prompt A/B/C 需要 `chunks` |
| 知識圖譜提取 (KG Extraction) | 分塊結果 (`chunks`) | 需要 `chunks` 中的 `text` 字段 |
| 存儲向量 (Storage) | 向量化結果 (`embeddings`) | 需要 `embeddings` 和 `chunks` |
| 更新 Payload | Stage 2 結果 | 需要 Prompt A/B/C 的結果 |

**結論**：

- ✅ **知識圖譜提取不依賴向量化結果**
- ✅ **Stage 1 和 Stage 2 可以獨立執行**
- ✅ **Stage 2 失敗不影響 Stage 1 的檢索功能**
- ✅ **兩者都只依賴分塊結果**
- ✅ **可以獨立執行或並行執行**

### 清理機制

#### 向量清理

**方法**：`QdrantVectorStoreService.delete_vectors_by_file_id()`

**實現**：

```python
# Qdrant 刪除向量
collection.delete(
    points_selector=Filter(
        must=[
            FieldCondition(key="file_id", match=MatchValue(value=file_id))
        ]
    )
)
```

**效果**：

- 刪除 Qdrant 中該文件的所有向量
- 保留 collection 結構（如果沒有其他文件使用）

#### 圖譜清理

**方法**：`KGBuilderService.remove_file_associations()`

**實現**：

- 清理 relations：將 `file_id` 從 `file_ids` 移除；若移除後 `file_ids` 為空則刪除該 edge
- 清理 entities：將 `file_id` 從 `file_ids` 移除；若移除後 `file_ids` 為空且不再有任何關聯 edge，則刪除該 vertex

**效果**：

- 移除文件與圖譜的關聯
- 保留其他文件共享的實體和關係
- 清理孤立的實體和關係

---

## 📝 使用場景

### 場景 1：向量化失敗，圖譜提取成功

**情況**：

- 向量化服務暫時不可用（如 Ollama 服務中斷）
- 知識圖譜提取服務正常

**結果**：

- ✅ 知識圖譜提取成功執行
- ✅ 狀態：`partial_completed`
- ✅ 消息：「知識圖譜提取完成，向量化失敗」
- ✅ 可以後續單獨重新生成向量

### 場景 2：圖譜提取失敗，向量化成功

**情況**：

- 向量化服務正常
- 知識圖譜提取服務暫時不可用（如 LLM 服務中斷）

**結果**：

- ✅ 向量化成功執行
- ✅ 狀態：`partial_completed`
- ✅ 消息：「向量化完成，知識圖譜提取失敗」
- ✅ 可以後續單獨重新生成圖譜

### 場景 3：重新生成向量

**情況**：

- 文件已存在向量和圖譜數據
- 用戶要求重新生成向量（如更換嵌入模型）

**結果**：

- ✅ 自動清理舊向量
- ✅ 重新生成新向量
- ✅ 圖譜數據不受影響

### 場景 4：重新生成圖譜

**情況**：

- 文件已存在向量和圖譜數據
- 用戶要求重新生成圖譜（如更換 Ontology 或 LLM 模型）

**結果**：

- ✅ 自動清理舊圖譜關聯
- ✅ 清理 chunk 狀態（重置續跑）
- ✅ 重新生成新圖譜
- ✅ 向量數據不受影響

---

## ✅ 驗證檢查清單

- [x] 狀態模型支持 `partial_completed` 狀態
- [x] 向量化失敗不影響知識圖譜提取
- [x] 知識圖譜提取失敗不影響向量化
- [x] 重新生成向量前清理舊向量
- [x] 重新生成圖譜前清理舊圖譜數據
- [x] 清理失敗不阻止重新生成流程
- [x] 日誌記錄完整
- [x] 狀態更新準確

---

## 📚 相關文檔

- [AI-Box 雙軌 RAG 解析規格書](./AI-Box雙軌RAG解析規格書.md) - 雙軌架構詳細說明
- [AI-Box 雙軌 RAG 解析實施計劃書](./AI-Box雙軌RAG解析實施計劃書.md) - 實施計劃和進度管控
- [文件上傳架構說明](./上傳的功能架構說明-v4.0.md) - 當前實現詳解
- [VectorDB.md](./VectorDB.md) - Qdrant 向量數據庫架構
- [批量文件上傳流程優化方案](./批量文件上傳流程優化方案.md) - 並行處理優化方案

---

## 🎯 後續優化建議

### 短期（已完成）

1. ✅ 分離錯誤處理
2. ✅ 支持部分完成狀態
3. ✅ 重新生成時清理舊數據

### 中期（可選）

1. **並行處理**：向量化和知識圖譜提取並行執行（參考批量文件上傳流程優化方案）
2. **增量更新**：支持只更新部分 chunks 的向量或圖譜
3. **狀態查詢 API**：提供詳細的狀態查詢接口，支持前端展示部分完成狀態
4. **Stage 2 進度追蹤**：追蹤 Stage 2 背景任務的進度（Prompt A/B/C 的完成狀態）

### 長期（可選）

1. **智能重試**：自動重試失敗的階段
2. **質量評估**：評估向量和圖譜的質量，自動觸發重新生成
3. **版本管理**：支持向量和圖譜的版本管理

---

**最後更新日期**: 2026-01-21
