# 文件上傳向量圖譜化測試計劃

**创建日期**: 2026-01-01
**创建人**: Daniel Chung
**最后修改日期**: 2026-01-02 18:50:00 (UTC+8)

---

## 📋 测试计划概述

本测试计划旨在验证 AI-Box 系统的文件上傳、向量化和知識圖譜提取功能，確保系統能夠：
1. 正確上傳文件並生成向量嵌入
2. 基於 Ontology 生成知識節點和關係
3. RQ 任務排程能夠正常運作（支持並發處理）
4. 大規模文檔處理的穩定性和性能

---

## 🎯 測試階段

### 第一階段：單一文件測試

#### 測試目標

1. **文件上傳功能驗證**
   - 文件能夠成功上傳到系統
   - 文件元數據正確存儲

2. **向量化功能驗證**
   - 文件能夠正確解析和分塊
   - 生成向量嵌入並存儲到 ChromaDB
   - 向量質量符合預期
   - **獨立執行能力**：向量化失敗不影響知識圖譜提取

3. **知識圖譜提取功能驗證**
   - 基於 Ontology 正確提取實體（NER）
   - 正確提取關係（RE）
   - 正確識別關係類型（RT）
   - 知識圖譜節點和關係正確存儲到 ArangoDB
   - **獨立執行能力**：知識圖譜提取失敗不影響向量化

4. **模型對比測試**
   - 使用 Ollama 模型（當前配置）進行 NER/RE/RT
   - 使用 Gemini 模型進行 NER/RE/RT
   - 對比兩種模型的知識圖譜生成質量

#### 測試文件

選擇一個較小的系統設計文檔作為測試文件：

**推薦文件**：`docs/系统设计文档/统一服务指南.md` 或類似的較小文件

**文件選擇標準**：
- 文件大小適中（建議 < 50KB）
- 包含清晰的實體和關係內容
- 能夠匹配到現有的 Ontology（AI-Box Domain/Major）

#### 測試步驟

1. **準備測試環境**
   ```bash
   # 1. 確保所有服務運行正常
   ./scripts/start_services.sh status
   
   # 2. 清理測試數據（可選，首次測試建議清理）
   # 使用清理腳本清理階段二測試數據
   python scripts/cleanup_phase2_data.py
   
   # 或手動清理：
   # - 清理 RQ 任務隊列
   # - 清理 Redis 狀態記錄
   # - 清理 ChromaDB 中的測試 collection
   # - 清理 ArangoDB 中的測試實體和關係
   # - 清理文件存儲（本地或 SeaweedFS）
   ```

2. **執行單一文件上傳測試（使用 Ollama 模型）**
   ```bash
   # 使用現有測試腳本
   python scripts/kg_extract_test_file.py
   
   # 或手動上傳文件並監控處理過程
   ```

3. **記錄測試結果（Ollama 模型）**
   - 文件上傳狀態：✅/❌
   - 向量化時間：___ 秒
   - 分塊數量：___ 個
   - 知識圖譜提取時間：___ 秒
   - 實體數量（NER）：___ 個
   - 關係數量（RE）：___ 個
   - 關係類型數量（RT）：___ 個
   - 存儲位置：
     - ChromaDB collection: `___`
     - ArangoDB entities: `___` 個
     - ArangoDB relations: `___` 個

4. **配置 Gemini 模型並重複測試**
   ```bash
   # 修改 .env 文件或 ArangoDB system_configs，將 NER/RE/RT 模型改為 Gemini
   # 或修改測試腳本直接使用 Gemini 客戶端
   ```

5. **執行單一文件上傳測試（使用 Gemini 模型）**
   ```bash
   # 使用相同的測試文件，但配置使用 Gemini 模型
   python scripts/kg_extract_test_file.py --model gemini
   ```

6. **記錄測試結果（Gemini 模型）**
   - 文件上傳狀態：✅/❌
   - 向量化時間：___ 秒
   - 分塊數量：___ 個
   - 知識圖譜提取時間：___ 秒
   - 實體數量（NER）：___ 個
   - 關係數量（RE）：___ 個
   - 關係類型數量（RT）：___ 個

7. **質量對比分析**
   - 對比兩種模型的實體提取準確性
   - 對比兩種模型的關係提取準確性
   - 對比兩種模型的處理時間
   - 評估 Ontology 約束的符合程度

#### 驗證點

- [ ] 文件能夠成功上傳
- [ ] 向量嵌入正確生成並存儲
- [ ] 知識圖譜實體和關係正確提取
- [ ] Ontology 約束正確應用（實體類型、關係類型符合 Ontology 定義）
- [ ] 兩種模型的結果可以進行對比分析

#### 預期結果

- 文件上傳成功率：100%
- 向量化成功率：100%
- 知識圖譜提取成功率：100%
- 實體和關係數量 > 0
- 實體類型符合 Ontology 定義
- 關係類型符合 Ontology 定義

---

### 第二階段：批量文件測試（RQ 任務排程驗證）

#### 測試目標

1. **RQ 任務排程功能驗證**
   - RQ Worker 能夠正常接收任務
   - 任務能夠正確排隊和執行
   - 支持多個任務並發處理（5個任務並發）

2. **並發處理能力驗證**
   - 5個文件同時上傳和處理
   - 任務不會相互干擾
   - 資源使用合理（CPU、內存）

3. **任務狀態追蹤驗證**
   - 任務狀態能夠正確更新
   - 進度追蹤功能正常
   - 錯誤處理機制正常
   - **部分完成狀態**：支持 `partial_completed` 狀態（向量化或圖譜提取其中一個成功）

#### 測試文件

選擇約 **20個文件** 進行測試：

**文件選擇標準**：
- 涵蓋不同類型的系統設計文檔
- 文件大小適中（建議每個文件 < 100KB）
- 包含多樣化的內容（架構文檔、API文檔、流程文檔等）

**推薦文件列表**：
1. `docs/系统设计文档/统一服务指南.md`
2. `docs/系统设计文档/核心组件/文件上傳向量圖譜/上傳的功能架構說明-v3.0.md`
3. `docs/系统设计文档/核心组件/文件上傳向量圖譜/Ontology系统.md`
4. `docs/系统设计文档/核心组件/文件上傳向量圖譜/知识图谱系统.md`
5. `docs/系统设计文档/核心组件/文件上傳向量圖譜/强化RAG系统.md`
6. ... (其他15個文件)

#### 測試步驟

1. **準備測試環境**
   ```bash
   # 1. 確保所有服務運行正常
   ./scripts/start_services.sh status
   
   # 2. 確認 RQ Worker 正在運行
   # 檢查 RQ Worker 進程
   ps aux | grep rq_worker
   
   # 3. 確認 RQ Worker 配置
   # - 確認 worker 數量配置
   # - 確認 job_timeout 配置（建議：900秒）
   # - 確認 queue 配置
   ```

2. **清理階段二測試數據**
   ```bash
   # 清理階段二產生的測試數據
   python scripts/cleanup_phase2_data.py
   ```

3. **執行批量測試（5個任務並發）**
   ```bash
   # 使用批量測試腳本（如果存在）
   # 或使用現有的批量處理腳本
   python scripts/kg_extract_batch_test.py \
     --file-list <文件列表> \
     --max-files 20 \
     --concurrent 5
   ```

4. **監控任務執行**
   ```bash
   # 使用監控腳本監控處理進度
   python scripts/monitor_kg_extract.py
   
   # 或直接查看 RQ Dashboard
   # http://localhost:9181 (如果配置了RQ Dashboard)
   ```

5. **記錄測試結果**
   - 總文件數：20 個
   - 成功處理：___ 個
   - 失敗處理：___ 個
   - 並發任務數：5 個
   - 總處理時間：___ 秒
   - 平均處理時間：___ 秒/文件
   - 並發效率：___ （實際處理時間 vs 順序處理時間預估）

#### 驗證點

- [ ] 所有20個文件都能正確上傳
- [ ] RQ Worker 能夠同時處理5個任務
- [ ] 任務狀態能夠正確追蹤
- [ ] 沒有任務死鎖或超時
- [ ] 資源使用合理（CPU、內存不會過載）
- [ ] 錯誤處理機制正常（失敗任務不會影響其他任務）
- [ ] 支持部分完成狀態（`partial_completed`）：向量化或圖譜提取其中一個成功
- [ ] 向量化和知識圖譜提取可以獨立執行（一個失敗不影響另一個）

#### 預期結果

- 文件上傳成功率：≥ 95% (19/20)
- 向量化成功率：≥ 95%
- 知識圖譜提取成功率：≥ 90%
- 並發處理正常，沒有死鎖
- 平均處理時間符合預期

#### 問題排查

如果遇到問題：

1. **任務超時**
   - 檢查 `worker.job_timeout` 配置
   - 檢查文件大小和處理複雜度
   - 考慮增加超時時間或優化處理邏輯

2. **任務失敗**
   - 查看 RQ Worker 日誌：`logs/rq_worker_rq_worker_ai_box.log`
   - 檢查 ArangoDB、ChromaDB 連接
   - 檢查 Ontology 配置

3. **並發問題**
   - 檢查 RQ Worker 數量配置
   - 檢查數據庫連接池配置
   - 檢查資源使用情況

---

### 第三階段：正式系統設計文檔處理

#### 測試目標

1. **大規模文件處理驗證**
   - 處理所有系統設計文檔（**85 個文件**，總大小 **1.46 MB**）
   - 確保系統穩定性和可靠性

2. **數據完整性驗證**
   - 所有文檔的向量化記錄完整
   - 所有文檔的知識圖譜提取記錄完整
   - 數據能夠正確查詢和檢索

3. **性能驗證**
   - 處理速度符合預期
   - 資源使用合理
   - 系統能夠穩定運行

#### 測試範圍

處理 `docs/系统设计文档/` 目錄下的所有 Markdown 文件：

**文件數量統計**（2026-01-02 重新盤點）：
- 總文件數：**74 個** Markdown 文件
- 總文件大小：**1.5 MB** (約 1,500,000 bytes)
- 平均文件大小：**約 20 KB**
- 最大文件：**132.03 KB** (`代碼管制表.md`)
- 最小文件：**0.49 KB** (`datasets/Agent Platform/Migration/PHASE2_SECRET_MANAGEMENT.md`)

**文件類型**：
- 系統架構文檔
- 核心組件文檔
- API 文檔
- 流程文檔
- 其他技術文檔

**文件授權管理要求**（2026-01-02 新增）：
- ✅ 所有系統設計文檔上傳時，自動設置 **SystemSecurity** 安全組授權
- ✅ 訪問級別：`SECURITY_GROUP`
- ✅ 授權安全組：`["SystemSecurity"]`
- ✅ 數據分類：`INTERNAL`
- ✅ 只有屬於 SystemSecurity 安全組的用戶可以訪問這些文件

#### 測試步驟

1. **統計文件數量**
   ```bash
   # 統計需要處理的文件數量
   find docs/系统设计文档 -type f -name "*.md" | wc -l
   
   # 列出所有文件列表
   find docs/系统设计文档 -type f -name "*.md" > file_list.txt
   ```

2. **準備測試環境**
   ```bash
   # 1. 確保所有服務運行正常
   ./scripts/start_services.sh status
   
   # 2. 清理階段二測試數據
   python scripts/cleanup_phase2_data.py
   
   # 3. 檢查文件存儲配置
   # 確認存儲後端配置（本地或 SeaweedFS）
   # 當前配置：config.json → file_upload.storage_backend
   # 或環境變數：ENV=production 時優先使用 SeaweedFS
   
   # 4. 確認有足夠的存儲空間
   # - ChromaDB 存儲空間
   # - ArangoDB 存儲空間
   # - 文件存儲空間（本地或 SeaweedFS）
   
   # 5. 備份現有數據（可選，建議生產環境執行）
   ```

3. **執行批量處理**
   ```bash
   # 使用批量測試腳本處理所有文件
   # 方法1：使用批量測試腳本（推薦）
   python scripts/kg_extract_batch_test_100.py \
     --file-list <文件列表> \
     --max-files 85 \
     --concurrent 5 \
     --output system_docs_processing_results.json \
     --progress system_docs_processing_progress.json
   
   # 方法2：使用現有的批量處理腳本（如果存在）
   # python scripts/kg_extract_all_with_progress.py \
   #   --input-dir "docs/系统设计文档" \
   #   --concurrent 5 \
   #   --output-json "system_docs_processing_results.json"
   ```

4. **監控處理進度**
   ```bash
   # 使用監控腳本實時監控
   bash scripts/monitor_batch_test.sh system_docs_processing_progress.json
   
   # 或定期檢查進度文件
   cat system_docs_processing_progress.json | jq
   ```

5. **驗證處理結果**
   ```bash
   # 驗證所有文件都已處理
   python scripts/verify_kg_extraction_results.py \
     --input-dir "docs/系统设计文档" \
     --progress-json "scripts/kg_extract_progress.json"
   ```

#### 記錄要求

所有文檔上傳記錄必須包含以下信息：

1. **文件基本信息**
   - 文件名稱
   - 文件路徑
   - 文件大小（字節）
   - 文件類型（MIME type）
   - 上傳時間
   - 處理開始時間
   - 處理結束時間
   - **文件授權設置**（2026-01-02 新增）：
     - 訪問級別：`SECURITY_GROUP`
     - 授權安全組：`["SystemSecurity"]`
     - 數據分類：`INTERNAL`
     - 所有者 ID：上傳用戶 ID

2. **向量化記錄**
   - 向量化狀態：✅/❌/`partial_completed`（部分完成）
   - 向量化時間：___ 秒
   - 分塊數量：___ 個
   - 分塊策略：`SEMANTIC` / `AST_DRIVEN` / 其他
   - ChromaDB collection 名稱
   - 向量嵌入維度：___ 維
   - **獨立執行**：向量化失敗時，是否繼續執行知識圖譜提取

3. **知識圖譜提取記錄**
   - 提取狀態：✅/❌/`partial_completed`（部分完成）
   - 提取時間：___ 秒
   - 使用的 Ontology：
     - Base Ontology：✅/❌
     - Domain Ontology：___ 
     - Major Ontology：___
   - NER 記錄：
     - 實體數量：___ 個
     - 實體類型列表：___
   - RE 記錄：
     - 關係數量：___ 個
     - 關係類型列表：___
   - RT 記錄：
     - 關係類型識別數量：___ 個
   - ArangoDB 存儲：
     - 實體集合：`entities`
     - 關係集合：`relations`
     - 實體文檔數：___ 個
     - 關係文檔數：___ 個

4. **錯誤記錄（如果失敗）**
   - 錯誤類型：___ 
   - 錯誤消息：___
   - 錯誤堆棧：___
   - 失敗階段：`上傳` / `向量化` / `知識圖譜提取`
   - **部分完成狀態**：如果只有一個階段失敗，記錄 `partial_completed` 狀態
   - **獨立執行驗證**：確認一個階段失敗不影響另一個階段

#### 數據存儲

所有記錄存儲在以下位置：

1. **進度追蹤文件**
   - 路徑：`system_docs_processing_progress.json`（可配置）
   - 格式：JSON
   - 內容：所有文件的處理進度和結果
   - **狀態字段**：包含 `overall_status`（`completed` / `partial_completed` / `failed`）

2. **詳細結果文件**
   - 路徑：`system_docs_processing_results.json`（可配置）
   - 格式：JSON
   - 內容：每個文件的詳細處理記錄
   - **狀態字段**：包含各階段的獨立狀態（向量化、知識圖譜提取）

3. **數據庫記錄**
   - ArangoDB：`file_metadata` collection
   - ArangoDB：`entities` collection
   - ArangoDB：`relations` collection
   - ChromaDB：向量集合

#### 驗證點

- [ ] 所有文件都已成功上傳
- [ ] 所有文件的向量化記錄完整（包括部分完成狀態）
- [ ] 所有文件的知識圖譜提取記錄完整（包括部分完成狀態）
- [ ] 數據能夠正確查詢（向量檢索、圖查詢）
- [ ] 實體和關係數據質量符合預期
- [ ] Ontology 約束正確應用
- [ ] **獨立執行能力**：向量化和知識圖譜提取可以獨立執行
- [ ] **部分完成狀態**：支持 `partial_completed` 狀態的正確記錄和處理
- [ ] **重新生成能力**：可以單獨重新生成向量或圖譜
- [ ] **文件授權管理**（2026-01-02 新增）：
  - [ ] 所有系統設計文檔自動設置 SystemSecurity 安全組授權
  - [ ] 訪問級別為 `SECURITY_GROUP`
  - [ ] 授權安全組列表包含 `"SystemSecurity"`
  - [ ] 只有 SystemSecurity 安全組成員可以訪問這些文件
  - [ ] 非 SystemSecurity 成員無法訪問（權限檢查正確）

#### 預期結果

- 文件處理成功率：≥ 95%（包括 `partial_completed` 狀態）
- 向量化成功率：≥ 95%
- 知識圖譜提取成功率：≥ 90%
- 部分完成狀態正確記錄：向量化或圖譜提取其中一個成功時，狀態為 `partial_completed`
- 所有記錄完整存儲
- 數據質量符合預期
- **獨立執行能力**：向量化失敗時，知識圖譜提取仍可執行（反之亦然）

---

## 📊 測試記錄模板

### 第一階段測試記錄

| 項目 | Ollama 模型 | Gemini 模型 | 備註 |
|------|------------|------------|------|
| 測試文件 | | | |
| 文件大小 | | | |
| 上傳狀態 | ✅/❌ | ✅/❌ | |
| 向量化時間 | ___ 秒 | ___ 秒 | |
| 分塊數量 | ___ 個 | ___ 個 | |
| 知識圖譜提取時間 | ___ 秒 | ___ 秒 | |
| 實體數量（NER） | ___ 個 | ___ 個 | |
| 關係數量（RE） | ___ 個 | ___ 個 | |
| 關係類型數量（RT） | ___ 個 | ___ 個 | |
| 實體類型列表 | | | |
| 關係類型列表 | | | |
| 質量評估 | | | |

### 第二階段測試記錄

| 項目 | 數值 | 備註 |
|------|------|------|
| 總文件數 | 20 個 | |
| 成功處理 | ___ 個 | |
| 失敗處理 | ___ 個 | |
| 並發任務數 | 5 個 | |
| 總處理時間 | ___ 秒 | |
| 平均處理時間 | ___ 秒/文件 | |
| 並發效率 | ___ % | 實際時間/順序時間預估 |

### 第三階段測試記錄

| 項目 | 數值 | 備註 |
|------|------|------|
| 總文件數 | 74 個 | 總大小 1.5 MB（2026-01-02 重新盤點） |
| 成功處理 | ___ 個 | |
| 失敗處理 | ___ 個 | |
| 向量化成功率 | ___ % | |
| 知識圖譜提取成功率 | ___ % | |
| 部分完成狀態數量 | ___ 個 | `partial_completed` 狀態的文件數 |
| 總實體數 | ___ 個 | |
| 總關係數 | ___ 個 | |
| 平均處理時間 | ___ 秒/文件 | |
| 總處理時間 | ___ 秒 | |
| 預估處理時間（5並發） | ~ ___ 分鐘 | 假設平均30秒/文件，約需 7.4 分鐘 |
| **文件授權設置**（2026-01-02 新增） | | |
| SystemSecurity 安全組授權文件數 | ___ 個 | 應等於總文件數（74 個） |
| 訪問級別為 SECURITY_GROUP 的文件數 | ___ 個 | 應等於總文件數（74 個） |
| 授權驗證通過率 | ___ % | SystemSecurity 成員可訪問，非成員被拒絕 |

---

## 🔧 測試工具和腳本

### 現有腳本

1. **單一文件測試**
   - `scripts/kg_extract_test_file.py` - 單一文件上傳和知識圖譜提取測試

2. **批量處理**
   - `scripts/kg_extract_batch_test.py` - 批量文件測試（20個文件）
   - `scripts/kg_extract_batch_test_100.py` - 大規模批量測試（100+文件）
   - `scripts/kg_extract_all_with_progress.py` - 批量文件處理，支持進度追蹤（如果存在）

3. **進度監控**
   - `scripts/monitor_batch_test.sh` - 實時監控批量測試進度
   - `scripts/monitor_kg_extract.py` - 實時監控處理進度（如果存在）

4. **數據清理**
   - `scripts/cleanup_phase2_data.py` - 清理階段二測試數據

4. **結果驗證**
   - 需要創建：`scripts/verify_kg_extraction_results.py` - 驗證處理結果

### 需要創建的腳本

1. **Gemini 模型測試腳本**
   - 創建：`scripts/kg_extract_test_file_gemini.py` - 使用 Gemini 模型進行測試

2. **結果驗證腳本**
   - 創建：`scripts/verify_kg_extraction_results.py` - 驗證處理結果完整性

3. **質量對比腳本**
   - 創建：`scripts/compare_model_results.py` - 對比不同模型的結果質量

---

## 📝 測試報告模板

### 測試報告結構

1. **測試概述**
   - 測試日期
   - 測試人員
   - 測試環境
   - 測試範圍

2. **測試結果摘要**
   - 總體成功率
   - 主要問題
   - 性能指標

3. **詳細測試結果**
   - 第一階段結果
   - 第二階段結果
   - 第三階段結果

4. **問題和建議**
   - 發現的問題
   - 問題分析
   - 改進建議

5. **結論**
   - 測試結論
   - 下一步行動

---

## 🎯 成功標準

### 第一階段成功標準

- ✅ 單一文件測試成功（Ollama 和 Gemini 模型）
- ✅ 知識圖譜提取質量符合預期
- ✅ 能夠進行模型質量對比

### 第二階段成功標準

- ✅ 20個文件處理成功率 ≥ 95%
- ✅ 5個任務並發處理正常
- ✅ 沒有任務死鎖或嚴重錯誤

### 第三階段成功標準

- ✅ 所有系統設計文檔處理完成
- ✅ 處理成功率 ≥ 95%
- ✅ 所有記錄完整存儲
- ✅ 數據質量符合預期

---

## 📚 相關文檔

- [文件上傳架構說明](./上傳的功能架構說明-v3.0.md) - 最新架構文檔
- [向量化與圖譜提取獨立執行優化報告](./向量化與圖譜提取獨立執行優化報告.md) - 獨立執行優化詳解
- [批量文件上傳流程優化方案](./批量文件上傳流程優化方案.md) - 並行處理優化方案
- [Ontology 系統](./Ontology系统.md)
- [知識圖譜系統](./知识图谱系统.md)
- [強化 RAG 系統](./强化RAG系统.md)

---

## ⚠️ 重要更新（2026-01-02）

### 系統優化更新

1. **獨立執行能力**
   - 向量化和知識圖譜提取現在可以獨立執行
   - 一個階段失敗不影響另一個階段
   - 支持部分完成狀態（`partial_completed`）

2. **狀態管理增強**
   - 新增 `partial_completed` 狀態
   - 明確標識哪些階段成功，哪些失敗
   - 提供清晰的消息說明

3. **重新生成機制**
   - 重新生成向量前自動清理舊向量
   - 重新生成圖譜前自動清理舊圖譜數據
   - 確保數據一致性

4. **文件存儲配置**
   - 系統支持本地文件系統和 SeaweedFS 兩種存儲後端
   - 根據配置自動選擇（生產環境優先使用 SeaweedFS）
   - 單一存儲後端機制（不是雙重備份）

### 測試注意事項

1. **清理測試數據**
   - 階段二測試後，使用 `scripts/cleanup_phase2_data.py` 清理測試數據
   - 清理內容包括：RQ 任務、Redis 狀態、ArangoDB 數據、ChromaDB 向量、測試日誌

2. **存儲後端檢查**
   - 確認當前使用的存儲後端（本地或 SeaweedFS）
   - 檢查 `config.json` 中的 `file_upload.storage_backend` 配置
   - 或檢查環境變數 `ENV`（生產環境優先使用 SeaweedFS）

3. **狀態記錄**
   - 測試時注意記錄 `partial_completed` 狀態的文件
   - 驗證獨立執行能力（一個階段失敗時，另一個階段是否繼續執行）

---

**最后更新日期**: 2026-01-02 18:50:00 (UTC+8)

---

## ⚠️ 重要更新（2026-01-02 18:50:00 UTC+8）

### 文件授權管理更新

1. **系統文件自動授權**
   - 所有 `docs/系统设计文档/` 目錄下的文件上傳時，自動設置 **SystemSecurity** 安全組授權
   - 訪問級別：`SECURITY_GROUP`
   - 授權安全組：`["SystemSecurity"]`
   - 數據分類：`INTERNAL`
   - 只有屬於 SystemSecurity 安全組的用戶可以訪問這些文件

2. **文件數量重新盤點**
   - 總文件數：**74 個** Markdown 文件（原為 85 個，已重新盤點）
   - 總文件大小：**1.5 MB**（原為 1.46 MB）

3. **測試要求更新**
   - 第三階段測試需驗證所有系統設計文檔的授權設置
   - 驗證 SystemSecurity 安全組成員可以訪問，非成員被拒絕

