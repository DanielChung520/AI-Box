# 部署架构文档

**创建日期**: 2025-12-25
**创建人**: Daniel Chung
**最后修改日期**: 2026-01-01

**更新记录**：

- 2025-12-29：添加 SeaweedFS 双服务 Kubernetes 部署说明，更新架构图
- 2026-01-01：添加系统参数配置策略，定义 .env 与 ArangoDB 配置的分层存储机制

---

## 📋 概述

AI-Box 采用混合部署架构，支持本地物理隔离与云端LLM的混合模式，满足企业安全与合规需求。系统使用 Kubernetes 容器编排与 Redis Worker 异步任务处理，实现灵活的集群扩展与维护。

---

## 🏗️ 架构设计

### 混合部署策略

**本地物理隔离**：

- 企业敏感数据优先使用本地私有小模型处理
- 数据不出企业，满足合规要求

**云端LLM优势**：

- 非敏感场景利用云端强大LLM能力
- 降低成本，提升性能

### Kubernetes 容器管理

**集群式部署**：

- 灵活的集群扩展
- 容器化部署，易于维护
- 支持高可用配置

### Redis Worker 异步任务

**异步任务处理**：

- 支持同步与并发
- 文件处理、知识提取等异步任务
- 任务队列与状态追踪

### SeaweedFS 分布式文件系统

**双服务部署架构**：

AI-Box 系统部署两个独立的 SeaweedFS 服务实例：

1. **AI-Box SeaweedFS 服务**：
   - 服务名称：`seaweedfs-ai-box`
   - 存储内容：治理相关日志、版本历史、变更提案、DataLake 元数据、AI-Box 项目其他非结构化数据
   - Kubernetes 部署配置：`k8s/seaweedfs-ai-box/`
   - S3 API 端点：`http://seaweedfs-ai-box-filer:8333`
   - Filer API 端点：`http://seaweedfs-ai-box-filer:8888`

2. **DataLake SeaweedFS 服务**：
   - 服务名称：`seaweedfs-datalake`
   - 存储内容：文件备份数据、DataLake 项目相关存储需求
   - Kubernetes 部署配置：`k8s/seaweedfs-datalake/`
   - S3 API 端点：`http://seaweedfs-datalake-filer:8333`
   - Filer API 端点：`http://seaweedfs-datalake-filer:8888`

**部署组件**：

- **Master 节点**：管理元数据和 Volume 节点（高可用，3 副本）
- **Volume 节点**：存储实际数据（存储节点，3 副本）
- **Filer 节点**：提供文件系统接口和 S3 API（文件系统接口，2 副本）

**Buckets 配置**：

AI-Box 服务 Buckets：

- `bucket-governance-logs`：治理相关日志
- `bucket-version-history`：版本历史记录
- `bucket-change-proposals`：变更提案记录
- `bucket-datalake-dictionary`：DataLake dictionary 定义
- `bucket-datalake-schema`：DataLake schema 定义
- `bucket-ai-box-assets`：AI-Box 项目其他非结构化数据

DataLake 服务 Buckets：

- `bucket-file-backups`：文件备份数据
- `bucket-datalake-assets`：DataLake 项目相关存储需求

**环境变量配置**：

```bash
# AI-Box 专案的 SeaweedFS 配置
AI_BOX_SEAWEEDFS_S3_ENDPOINT=http://seaweedfs-ai-box-filer:8333
AI_BOX_SEAWEEDFS_S3_ACCESS_KEY=...
AI_BOX_SEAWEEDFS_S3_SECRET_KEY=...
AI_BOX_SEAWEEDFS_USE_SSL=false
AI_BOX_SEAWEEDFS_FILER_ENDPOINT=http://seaweedfs-ai-box-filer:8888

# DataLake 专案的 SeaweedFS 配置
DATALAKE_SEAWEEDFS_S3_ENDPOINT=http://seaweedfs-datalake-filer:8333
DATALAKE_SEAWEEDFS_S3_ACCESS_KEY=...
DATALAKE_SEAWEEDFS_S3_SECRET_KEY=...
DATALAKE_SEAWEEDFS_USE_SSL=false
DATALAKE_SEAWEEDFS_FILER_ENDPOINT=http://seaweedfs-datalake-filer:8888
```

**部署步骤**：

1. 部署 SeaweedFS 服务：

   ```bash
   # 部署 AI-Box SeaweedFS 服务
   kubectl apply -f k8s/seaweedfs-ai-box/

   # 部署 DataLake SeaweedFS 服务
   kubectl apply -f k8s/seaweedfs-datalake/
   ```

2. 创建 Buckets：

   ```bash
   # 创建所有 Buckets
   python scripts/migration/create_seaweedfs_buckets.py --service all
   ```

3. 验证部署：

   ```bash
   # 检查服务状态
   kubectl get pods -n ai-box | grep seaweedfs
   kubectl get svc -n ai-box | grep seaweedfs
   ```

---

## ⚙️ 系统参数配置策略

### 配置分层存储架构

AI-Box 采用**双层配置存储策略**，将基础服务启动参数与运行时系统参数分离管理：

#### 1. 基础服务启动参数（`.env` 文件）

**存储位置**：项目根目录的 `.env` 文件

**用途**：存储系统启动所必需的基础服务连接参数和敏感信息

**配置类别**：

- **数据库连接**：ArangoDB、Redis、ChromaDB 等
- **文件存储**：SeaweedFS S3 端点、访问密钥等
- **外部服务**：Ollama、LLM API 密钥等
- **安全配置**：JWT 密钥、加密密钥等
- **服务端口**：API Gateway、Worker 等监听端口

**特点**：

- ✅ 系统启动前必须配置
- ✅ 不随系统运行而改变（除非服务迁移）
- ✅ 敏感信息存储（建议使用 Secret Management）
- ✅ 版本控制中应排除（通过 `.gitignore`）

**示例配置**：

```bash
# 数据库连接
ARANGODB_HOST=localhost
ARANGODB_PORT=8529
ARANGODB_USERNAME=root
ARANGODB_PASSWORD=changeme
REDIS_URL=redis://localhost:6379/0

# 文件存储
AI_BOX_SEAWEEDFS_S3_ENDPOINT=http://seaweedfs-ai-box-filer:8333
AI_BOX_SEAWEEDFS_S3_ACCESS_KEY=...
AI_BOX_SEAWEEDFS_S3_SECRET_KEY=...

# 外部服务
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_NER_MODEL=mistral-nemo:12b

# 安全配置
JWT_SECRET_KEY=...
GENAI_SECRET_ENCRYPTION_KEY=...
```

#### 2. 运行时系统参数（ArangoDB `system_configs` Collection）

**存储位置**：ArangoDB 的 `system_configs` Collection

**用途**：存储系统运行时可通过管理员界面动态调整的配置参数

**配置类别**：

- **业务逻辑配置**：文件处理超时、批量处理大小、重试次数等
- **性能调优参数**：Worker 并发数、队列优先级、缓存策略等
- **功能开关**：功能启用/禁用、实验性功能、维护模式等
- **业务规则**：文件大小限制、支持的文件类型、Ontology 版本等
- **通知与告警**：告警阈值、通知渠道、日志级别等

**特点**：

- ✅ 系统启动后自动初始化（如果不存在）
- ✅ 持久化存储（除非系统重置，否则保持配置）
- ✅ 可通过 API 和管理界面动态修改
- ✅ 支持版本历史和审计日志
- ✅ 支持多租户（system/tenant/user 三层配置）

**初始化机制**：

1. **启动时初始化**：系统启动时（`api/main.py` 的 `startup_event`）检查 `system_configs` Collection
2. **默认配置检查**：如果配置不存在，从默认配置文件（如 `config/system_configs.default.json`）加载并写入 ArangoDB
3. **配置合并**：支持 system → tenant → user 三层配置合并（优先级由低到高）
4. **配置验证**：通过 ConfigDefinition 验证配置项的有效性和类型

**配置结构示例**：

```json
{
  "_key": "file_processing",
  "scope": "file_processing",
  "tenant_id": null,
  "config_data": {
    "max_file_size": 104857600,
    "supported_file_types": ["text/markdown", "application/pdf"],
    "chunk_size": 768,
    "chunk_strategy": "semantic",
    "processing_timeout": 1800,
    "enable_auto_backup": true
  },
  "is_active": true,
  "created_at": "2026-01-01T00:00:00Z",
  "updated_at": "2026-01-01T00:00:00Z"
}
```

**配置访问**：

- **API 端点**：`GET/POST/PUT/DELETE /api/config/system/{scope}`
- **服务层**：`ConfigStoreService.get_config(scope, tenant_id=None)`
- **配置合并**：`ConfigStoreService.get_effective_config(scope, tenant_id, user_id)`

### 配置管理流程

#### 初始化流程

1. **系统启动**：

   ```
   FastAPI 启动 → 加载 .env 文件 → 连接 ArangoDB → 检查 system_configs
   ```

2. **配置初始化**（如果 `system_configs` 为空）：

   ```
   读取默认配置（config/system_configs.default.json）
   → 验证配置格式
   → 写入 ArangoDB system_configs Collection
   → 记录初始化日志
   ```

3. **运行时配置访问**：

   ```
   应用代码 → ConfigStoreService → 读取 system_configs
   → 合并 tenant/user 配置（如适用）
   → 返回有效配置
   ```

#### 配置修改流程

1. **管理员修改配置**：

   ```
   管理界面 → API 调用 → ConfigStoreService.update_config()
   → 更新 ArangoDB → 记录版本历史 → 触发配置变更通知（可选）
   ```

2. **配置生效**：
   - **立即生效**：部分配置（如功能开关）可在运行时生效
   - **重启生效**：部分配置（如 Worker 数量）需要重启服务

3. **配置回滚**：

   ```
   查询版本历史 → 恢复到指定版本 → 更新 system_configs
   ```

### 配置参数详细说明

#### 1. 基础服务启动参数（`.env` 文件）

| 参数名称 | 说明 | 默认值 | 极限值/限制 | 建议 |
|---------|------|--------|------------|------|
| **API 服务配置** |
| `API_GATEWAY_HOST` | API 网关监听地址 | `0.0.0.0` | - | 生产环境建议使用具体 IP 或域名 |
| `API_GATEWAY_PORT` | API 网关端口 | `8000` | 1-65535 | 确保端口未被占用 |
| `ENV` | 环境模式 | `development` | `development`/`production` | 生产环境必须设置为 `production` |
| **数据库配置** |
| `ARANGODB_HOST` | ArangoDB 主机地址 | `localhost` | - | 生产环境使用内网 IP 或域名 |
| `ARANGODB_PORT` | ArangoDB 端口 | `8529` | 1-65535 | 默认端口，非特殊需求不建议修改 |
| `ARANGODB_USERNAME` | ArangoDB 用户名 | `root` | - | 生产环境使用专用账户，避免使用 root |
| `ARANGODB_PASSWORD` | ArangoDB 密码 | - | - | 必须设置强密码，使用 Secret Management |
| `ARANGODB_DATABASE` | ArangoDB 数据库名 | `ai_box_kg` | - | 根据项目需求自定义 |
| `ARANGODB_PROTOCOL` | ArangoDB 连接协议 | `http` | `http`/`https` | 生产环境使用 HTTPS |
| **ChromaDB 配置** |
| `CHROMADB_HOST` | ChromaDB 主机地址 | `localhost` | - | 生产环境使用内网 IP 或域名 |
| `CHROMADB_PORT` | ChromaDB 端口 | `8001` | 1-65535 | 默认端口，确保未被占用 |
| `CHROMADB_MODE` | ChromaDB 运行模式 | `http` | `http`/`persist` | `http` 模式用于远程服务，`persist` 用于本地持久化 |
| `CHROMADB_PERSIST_DIR` | ChromaDB 持久化目录 | `./data/datasets/chromadb` | - | 本地持久化模式的存储路径 |
| `CHROMADB_CONNECTION_POOL_SIZE` | ChromaDB 连接池大小 | `4` | 1-100 | 根据并发需求调整 |
| `CHROMADB_NAMESPACE` | ChromaDB 命名空间 | - | - | 用于多租户隔离（可选） |
| **Redis 配置** |
| `REDIS_HOST` | Redis 主机地址 | `localhost` | - | 生产环境使用 Redis 集群地址 |
| `REDIS_PORT` | Redis 端口 | `6379` | 1-65535 | 默认端口 |
| `REDIS_DB` | Redis 数据库编号 | `0` | 0-15 | 不同环境使用不同 DB 编号隔离 |
| `REDIS_URL` | Redis 连接 URL | `redis://localhost:6379/0` | - | 优先级高于单独配置项 |
| `REDIS_PASSWORD` | Redis 密码 | - | - | 生产环境必须设置 |
| **Ollama 配置** |
| `OLLAMA_BASE_URL` | Ollama 服务地址 | `http://localhost:11434` | - | 支持多节点，使用负载均衡 |
| `OLLAMA_SCHEME` | Ollama 协议 | `http` | `http`/`https` | 生产环境使用 HTTPS |
| `OLLAMA_REMOTE_HOST` | Ollama 远程主机 | `localhost` | - | 可以是域名或 IP |
| `OLLAMA_REMOTE_PORT` | Ollama 远程端口 | `11434` | 1-65535 | 默认端口 |
| `OLLAMA_TIMEOUT_SECONDS` | Ollama 请求超时（秒） | `600` | 60-3600 | 大文件处理建议 600+ 秒 |
| `OLLAMA_DEFAULT_MODEL` | 默认 LLM 模型 | `gpt-oss:20b` | - | 根据硬件资源选择合适模型 |
| `OLLAMA_EMBEDDING_MODEL` | 嵌入模型 | `nomic-embed-text` | - | 推荐使用 `nomic-embed-text` |
| `OLLAMA_NER_MODEL` | NER 模型 | `mistral-nemo:12b` | - | 根据准确性和速度需求选择 |
| `OLLAMA_RE_MODEL` | RE 模型 | `mistral-nemo:12b` | - | 推荐与 NER 模型一致 |
| `OLLAMA_RT_MODEL` | RT 模型 | `mistral-nemo:12b` | - | 推荐与 NER 模型一致 |
| `OLLAMA_API_TOKEN` | Ollama API Token | - | - | 如 Ollama 配置了认证则必须设置 |
| `OLLAMA_URL` | Ollama 服务 URL（兼容旧配置） | `http://localhost:11434` | - | 优先使用 `OLLAMA_REMOTE_HOST` 和 `OLLAMA_REMOTE_PORT` |
| **SeaweedFS 配置** |
| `AI_BOX_SEAWEEDFS_S3_ENDPOINT` | AI-Box SeaweedFS S3 端点 | `http://seaweedfs-ai-box-filer:8333` | - | 生产环境使用 HTTPS |
| `AI_BOX_SEAWEEDFS_S3_ACCESS_KEY` | AI-Box S3 Access Key | - | - | 必须设置，使用强密钥 |
| `AI_BOX_SEAWEEDFS_S3_SECRET_KEY` | AI-Box S3 Secret Key | - | - | 必须设置，使用强密钥，使用 Secret Management |
| `AI_BOX_SEAWEEDFS_USE_SSL` | AI-Box 是否使用 SSL | `false` | `true`/`false` | 生产环境必须设置为 `true` |
| `AI_BOX_SEAWEEDFS_FILER_ENDPOINT` | AI-Box Filer API 端点 | `http://seaweedfs-ai-box-filer:8888` | - | 生产环境使用 HTTPS |
| `DATALAKE_SEAWEEDFS_S3_ENDPOINT` | DataLake SeaweedFS S3 端点 | `http://seaweedfs-datalake-filer:8333` | - | 生产环境使用 HTTPS |
| `DATALAKE_SEAWEEDFS_S3_ACCESS_KEY` | DataLake S3 Access Key | - | - | 必须设置，使用强密钥 |
| `DATALAKE_SEAWEEDFS_S3_SECRET_KEY` | DataLake S3 Secret Key | - | - | 必须设置，使用强密钥，使用 Secret Management |
| `DATALAKE_SEAWEEDFS_USE_SSL` | DataLake 是否使用 SSL | `false` | `true`/`false` | 生产环境必须设置为 `true` |
| `DATALAKE_SEAWEEDFS_FILER_ENDPOINT` | DataLake Filer API 端点 | `http://seaweedfs-datalake-filer:8888` | - | 生产环境使用 HTTPS |
| **安全配置** |
| `JWT_SECRET_KEY` | JWT 签名密钥 | - | 至少 32 字符 | 必须设置，使用随机生成的强密钥 |
| `GENAI_SECRET_ENCRYPTION_KEY` | GenAI 密钥加密密钥 | - | 至少 32 字符 | 必须设置，用于加密 API Key |
| `FILE_ENCRYPTION_KEY` | 文件加密密钥 | - | 至少 32 字符 | 生产环境必须设置，用于文件加密 |
| `SECURITY_ENABLED` | 是否启用安全中间件 | `false` | `true`/`false` | 生产环境必须设置为 `true` |
| `SECURITY_MODE` | 安全模式 | `development` | `development`/`production` | 生产环境必须设置为 `production` |
| **Worker 配置** |
| `AGENT_HEARTBEAT_TIMEOUT` | Agent 心跳超时（秒） | `300` | 60-1800 | 根据网络延迟调整 |
| `AGENT_HEALTH_CHECK_INTERVAL` | Agent 健康检查间隔（秒） | `60` | 10-300 | 根据系统负载调整 |
| `AGENT_SECRET_ID` | Agent Secret ID | - | - | 用于外部 Agent 注册，测试环境必须设置 |
| `AGENT_SECRET_KEY` | Agent Secret Key | - | - | 用于外部 Agent 注册，测试环境必须设置，使用 Secret Management |
| **MCP Server 配置** |
| `MCP_SERVER_ENDPOINTS` | MCP Server 端点列表 | `http://mcp-server:8002/mcp` | - | 多个端点用逗号分隔 |
| `MCP_SERVER_HOST` | MCP Server 主机地址 | `0.0.0.0` | - | 生产环境建议使用具体 IP |
| `MCP_SERVER_PORT` | MCP Server 端口 | `8002` | 1-65535 | 确保端口未被占用 |
| **MCP Gateway 配置** |
| `MCP_GATEWAY_ENDPOINT` | Cloudflare Gateway 端点 | `https://mcp.k84.org` | - | Gateway 代理端点 URL |
| `MCP_GATEWAY_SECRET` | Gateway 认证密钥 | - | 至少 32 字符 | 必须设置，与 Cloudflare Worker 中的 GATEWAY_SECRET 一致 |
| `MCP_GATEWAY_TIMEOUT` | Gateway 连接超时（秒） | `30` | 10-300 | 根据网络状况调整 |
| `MCP_GATEWAY_MAX_RETRIES` | Gateway 最大重试次数 | `3` | 1-10 | 根据可靠性需求调整 |
| **嵌入服务配置** |
| `EMBEDDING_BATCH_SIZE` | 嵌入批量处理大小 | `10` | 1-100 | 根据 GPU 内存和 Ollama 性能调整 |
| **其他配置** |
| `LOG_LEVEL` | 日志级别 | `INFO` | `DEBUG`/`INFO`/`WARNING`/`ERROR` | 生产环境建议 `INFO` 或 `WARNING` |
| `LOG_MAX_SIZE` | 单个日志文件最大大小 | `10MB` | 1MB-100MB | 根据磁盘空间调整 |
| `CORS_ORIGINS` | CORS 允许的来源 | `*` | - | 生产环境必须指定具体域名，用逗号分隔 |

#### 2. 运行时系统参数（ArangoDB `system_configs`）

| 参数名称 | 说明 | 默认值 | 极限值/限制 | 建议 | Scope |
|---------|------|--------|------------|------|-------|
| **文件处理配置** |
| `max_file_size` | 最大文件大小（字节） | `104857600` (100MB) | 1MB-1GB | 根据存储和网络带宽调整 | `file_processing` |
| `supported_file_types` | 支持的文件类型列表 | `["text/markdown", "application/pdf"]` | - | 根据业务需求扩展 | `file_processing` |
| `processing_timeout` | 文件处理超时（秒） | `1800` (30分钟) | 60-7200 | 大文件建议 1800+ 秒 | `file_processing` |
| `enable_auto_backup` | 是否启用自动备份 | `true` | `true`/`false` | 生产环境建议启用 | `file_processing` |
| **分块处理配置** |
| `chunk_size` | 分块大小（字符数） | `768` | 50-2000 | 推荐 512-1024，平衡质量和性能 | `chunk_processing` |
| `min_chunk_size` | 最小分块大小（字符数） | `50` | 10-500 | 太小会影响语义完整性 | `chunk_processing` |
| `max_chunk_size` | 最大分块大小（字符数） | `2000` | 500-10000 | 太大会影响向量化效果 | `chunk_processing` |
| `chunk_strategy` | 分块策略 | `semantic` | `semantic`/`ast_driven`/`fixed_size`/`sliding_window` | 推荐 `semantic`，保留语义结构 | `chunk_processing` |
| `overlap` | 分块重叠比例 | `0.2` | 0.0-0.5 | 0.2 是平衡效果和效率的最佳值 | `chunk_processing` |
| `max_code_block_size` | 代码块最大大小（字符数） | `2000` | 500-10000 | 代码块应保持完整，可设置较大值 | `chunk_processing` |
| `table_context_lines` | 表格上下文行数 | `3` | 0-10 | 保留上下文有助于理解表格内容 | `chunk_processing` |
| `combine_text_paragraphs` | 是否组合文本段落 | `true` | `true`/`false` | 推荐启用，提升语义连贯性 | `chunk_processing` |
| `separate_code_blocks` | 是否将代码块单独成块 | `true` | `true`/`false` | 推荐启用，保护代码完整性 | `chunk_processing` |
| `separate_tables` | 是否将表格单独成块 | `true` | `true`/`false` | 推荐启用，保护表格完整性 | `chunk_processing` |
| `enable_quality_check` | 是否启用质量检查 | `true` | `true`/`false` | 推荐启用，确保分块质量 | `chunk_processing` |
| `enable_adaptive_size` | 是否启用自适应大小 | `true` | `true`/`false` | 推荐启用，根据内容类型调整 | `chunk_processing` |
| **流式输出配置** |
| `streaming.chunk_size` | 流式输出分块大小（字符数） | `50` | 10-500 | 控制流式数据传输的分块大小，根据网络状况调整 | `streaming` |
| **MCP 第三方服務配置** |
| `gateway.endpoint` | Gateway 端点 URL | `https://mcp.k84.org` | - | 从 .env 初始化，可在 ArangoDB 中调整 | `mcp.external_services` |
| `gateway.timeout` | Gateway 连接超时（秒） | `30` | 10-300 | 可在 ArangoDB 中调整 | `mcp.external_services` |
| `gateway.max_retries` | Gateway 最大重试次数 | `3` | 1-10 | 可在 ArangoDB 中调整 | `mcp.external_services` |
| `external_services` | 外部服务列表 | `[]` | - | 通过管理界面或 API 添加 | `mcp.external_services` |
| **知识图谱提取配置** |
| `kg_extraction.enabled` | 是否启用知识图谱提取 | `true` | `true`/`false` | 推荐启用 | `kg_extraction` |
| `kg_extraction.mode` | 提取模式 | `all_chunks` | `all_chunks`/`selected_chunks`/`entire_file` | `all_chunks` 提取最全面 | `kg_extraction` |
| `kg_extraction.min_confidence` | 最小置信度阈值 | `0.5` | 0.0-1.0 | 根据准确性要求调整，0.5-0.7 较合适 | `kg_extraction` |
| `kg_extraction.batch_size` | 批量处理大小 | `10` | 1-100 | 根据 Worker 性能调整 | `kg_extraction` |
| **Worker 队列配置** |
| `worker.queue_priority` | 队列优先级 | `{"file_processing": 1, "kg_extraction": 2, "vectorization": 3}` | - | 数字越小优先级越高 | `worker` |
| `worker.max_retries` | 最大重试次数 | `3` | 0-10 | 根据任务重要性调整 | `worker` |
| `worker.retry_delay` | 重试延迟（秒） | `60` | 10-600 | 避免频繁重试导致资源浪费 | `worker` |
| `worker.job_timeout` | 任务超时（秒） | `900` | 60-7200 | 测试阶段：900秒（15分钟）快速发现问题；生产环境：根据实际需求调整为 3600 秒（1小时） | `worker` |
| **性能调优配置** |
| `cache.enabled` | 是否启用缓存 | `true` | `true`/`false` | 推荐启用，提升性能 | `cache` |
| `cache.ttl` | 缓存过期时间（秒） | `3600` | 60-86400 | 根据数据更新频率调整 | `cache` |
| `cache.max_size` | 最大缓存大小（MB） | `1024` | 100-10240 | 根据内存资源调整 | `cache` |
| **功能开关** |
| `features.enable_experimental` | 是否启用实验性功能 | `false` | `true`/`false` | 仅开发/测试环境启用 | `features` |
| `features.maintenance_mode` | 是否启用维护模式 | `false` | `true`/`false` | 维护时启用，暂停服务 | `features` |
| `features.enable_analytics` | 是否启用分析统计 | `true` | `true`/`false` | 推荐启用，便于监控 | `features` |

### 配置策略对比

| 特性 | `.env` 文件 | ArangoDB `system_configs` |
|------|------------|---------------------------|
| **存储位置** | 文件系统 | 数据库 |
| **修改方式** | 编辑文件 + 重启 | API/管理界面 |
| **持久化** | 文件存在即持久化 | 数据库持久化 |
| **初始化时机** | 启动前配置 | 启动时自动初始化 |
| **版本控制** | Git 历史（可选） | 版本历史表 |
| **多租户支持** | ❌ | ✅ (system/tenant/user) |
| **动态修改** | ❌ | ✅ |
| **审计日志** | ❌ | ✅ |
| **适用场景** | 基础服务连接 | 业务逻辑参数 |

### 配置重置机制

**系统重置**：删除 ArangoDB 中的配置数据，系统会在下次启动时重新初始化

```bash
# 重置系统配置（谨慎操作）
python scripts/migration/reset_system_configs.py --confirm

# 或者手动删除
# DELETE FROM system_configs WHERE tenant_id IS NULL
```

**部分重置**：只重置特定 scope 的配置

```bash
# 重置文件处理配置
python scripts/migration/reset_system_configs.py --scope file_processing
```

### 参数使用位置映射

**重要参数在代码中的使用位置**：

| 参数类别 | 参数名称 | 使用位置 | 说明 |
|---------|---------|---------|------|
| **ChromaDB** | `CHROMADB_HOST` | `api/routers/chromadb.py`<br>`database/chromadb/client.py`<br>`services/api/services/vector_store_service.py` | ChromaDB 主机地址配置 |
| | `CHROMADB_PORT` | `api/routers/chromadb.py`<br>`database/chromadb/client.py`<br>`services/api/services/vector_store_service.py` | ChromaDB 端口配置 |
| | `CHROMADB_MODE` | `api/routers/chromadb.py`<br>`services/api/services/vector_store_service.py` | ChromaDB 运行模式 |
| | `CHROMADB_PERSIST_DIR` | `services/api/services/vector_store_service.py` | ChromaDB 持久化目录 |
| | `CHROMADB_CONNECTION_POOL_SIZE` | `api/routers/chromadb.py` | ChromaDB 连接池大小 |
| | `CHROMADB_NAMESPACE` | `database/chromadb/collection.py` | ChromaDB 命名空间（多租户隔离） |
| **ArangoDB** | `ARANGODB_PROTOCOL` | `database/arangodb/settings.py` | ArangoDB 连接协议 |
| **Ollama** | `OLLAMA_URL` | `services/api/services/embedding_service.py` | Ollama 服务 URL（兼容旧配置） |
| **安全** | `FILE_ENCRYPTION_KEY` | `services/api/services/encryption_service.py` | 文件加密密钥 |
| | `SECURITY_MODE` | `services/api/services/encryption_service.py`<br>`services/api/services/genai_secret_encryption_service.py`<br>`system/security/config.py` | 安全模式（development/production） |
| **Agent** | `AGENT_SECRET_ID` | `agents/services/auth/secret_manager.py` | Agent Secret ID |
| | `AGENT_SECRET_KEY` | `agents/services/auth/secret_manager.py` | Agent Secret Key |
| **MCP** | `MCP_SERVER_ENDPOINTS` | `api/routers/mcp.py` | MCP Server 端点列表 |
| **嵌入服务** | `EMBEDDING_BATCH_SIZE` | `services/api/services/embedding_service.py` | 嵌入批量处理大小 |

### 参数检核结果

**检核日期**：2026-01-01

**检核范围**：所有代码文件（排除测试文件、备份文件和第三方库）

**检核方法**：通过正则表达式扫描代码中的 `os.getenv()` 和 `os.environ` 使用

#### ✅ 已检核并通过的参数

| 参数类别 | 参数数量 | 状态 |
|---------|---------|------|
| API 服务配置 | 4 | ✅ 全部在代码中使用 |
| ArangoDB 配置 | 6 | ✅ 全部在代码中使用 |
| Redis 配置 | 5 | ✅ 全部在代码中使用 |
| ChromaDB 配置 | 6 | ✅ 全部在代码中使用 |
| Ollama 配置 | 12 | ✅ 11个在代码中使用，1个（OLLAMA_BASE_URL）为兼容性保留 |
| SeaweedFS 配置 | 10 | ✅ 8个在代码中使用，2个（FILER_ENDPOINT）在配置中使用 |
| 安全配置 | 5 | ✅ 4个在代码中使用，1个（JWT_SECRET_KEY）可能通过其他方式使用 |
| Agent 配置 | 4 | ✅ 全部在代码中使用 |
| MCP Server 配置 | 3 | ✅ 1个在代码中使用，2个（HOST/PORT）可能通过配置读取 |
| 嵌入服务配置 | 1 | ✅ 全部在代码中使用 |
| 日志配置 | 2 | ✅ 1个在代码中使用，1个（LOG_MAX_SIZE）可能通过日志库使用 |

#### ⚠️ 注意事项

以下参数在代码扫描中未找到直接使用，但可能通过以下方式使用：

- **`OLLAMA_BASE_URL`**：兼容旧配置，建议使用 `OLLAMA_REMOTE_HOST` 和 `OLLAMA_REMOTE_PORT`
- **`AI_BOX_SEAWEEDFS_FILER_ENDPOINT`** / **`DATALAKE_SEAWEEDFS_FILER_ENDPOINT`**：可能在配置文件中使用，不在代码中直接读取
- **`JWT_SECRET_KEY`**：可能通过 JWT 库或其他安全中间件读取
- **`MCP_SERVER_HOST`** / **`MCP_SERVER_PORT`**：可能在 MCP 服务器配置中使用
- **`LOG_MAX_SIZE`**：可能通过日志库（如 structlog）配置读取

**建议**：

- 定期检核参数使用情况，确保文档与代码一致
- 新增功能时同步更新参数文档
- 删除未使用的参数前，确认所有相关代码已清理

### 最佳实践

1. **`.env` 配置**：
   - ✅ 只存储启动必需的基础服务连接信息
   - ✅ 敏感信息使用环境变量或 Secret Management
   - ✅ 生产环境使用不同的 `.env` 文件（`.env.production`）
   - ✅ 新增参数时同步更新本文档

2. **ArangoDB 配置**：
   - ✅ 所有可调整的业务参数都应存储在 `system_configs`
   - ✅ 提供合理的默认值，确保系统可独立运行
   - ✅ 使用 ConfigDefinition 定义配置项的类型和验证规则
   - ✅ 记录配置变更历史，便于审计和回滚

3. **配置文档**：
   - ✅ 维护配置项清单文档
   - ✅ 记录每个配置项的用途、默认值和影响范围
   - ✅ 提供配置修改的操作指南
   - ✅ 记录参数在代码中的使用位置，便于维护

4. **参数检核流程**：
   - ✅ 新增功能时，检查是否需要新增配置参数
   - ✅ 新增参数时，同步更新本文档的参数表格
   - ✅ 修改参数默认值时，更新文档并通知相关团队
   - ✅ 删除参数前，检查代码中所有使用位置并清理

5. **参数命名规范**：
   - ✅ 使用统一的命名前缀（如 `ARANGODB_`、`OLLAMA_`、`CHROMADB_`）
   - ✅ 避免混用不同命名（如 `ARANGO_` 和 `ARANGODB_`）
   - ✅ 新参数遵循现有命名规范

### 参数检核工具

**脚本位置**：`scripts/check_config_params.py`

**功能**：

- 扫描所有 Python 代码文件
- 提取所有环境变量的使用位置
- 按类别组织输出
- 标识未使用的参数

**使用方法**：

```bash
# 运行参数检核脚本
python scripts/check_config_params.py

# 生成报告文件
python scripts/check_config_params.py > param_usage_report.txt
```

**输出示例**：

```
找到 45 個不同的環境變量

【API服務】
  ✅ API_GATEWAY_HOST (1 個文件)
     - api/main.py
  ✅ API_GATEWAY_PORT (1 個文件)
     - api/main.py
  ...

【ArangoDB】
  ✅ ARANGODB_HOST (3 個文件)
     - database/arangodb/settings.py
     ...
```

**定期检核建议**：

- 每月运行一次检核脚本
- 新增功能后立即检核
- 代码重构后重新检核
- 删除参数前确认未使用

---

## 📊 实现状态

### 已完成功能

| 功能模块 | 状态 | 说明 |
|---------|------|------|
| Docker部署 | ✅ 已实现 | Docker Compose配置 |
| Kubernetes配置 | ✅ 已实现 | K8s部署配置 |
| Redis Worker | ✅ 已实现 | 异步任务处理 |
| SeaweedFS 双服务部署 | ✅ 已实现 | AI-Box 和 DataLake 独立服务实例 |
| SeaweedFS Buckets 配置 | ✅ 已实现 | 治理日志、版本历史、变更提案等 Buckets |
| 系统参数配置策略 | ✅ 已实现 | `.env` + ArangoDB `system_configs` 双层配置架构 |
| ConfigStoreService | ✅ 已实现 | 支持 system/tenant/user 三层配置管理 |

---

## 📚 参考资料

### 相关文档

- [部署文档](../../../備份與歸檔/deployment/)

---

**最后更新日期**: 2026-01-01

**更新摘要**：

- **2025-12-29**：
- 添加 SeaweedFS 双服务部署架构说明
- 添加 Buckets 配置和环境变量配置说明
- 添加部署步骤和验证方法
- 更新实现状态表，添加 SeaweedFS 相关功能

- **2026-01-01**：
  - 添加系统参数配置策略章节
  - 定义 `.env` 文件与 ArangoDB `system_configs` 的双层配置存储架构
  - 说明基础服务启动参数与运行时系统参数的分离管理机制
  - 添加配置初始化、修改、重置流程说明
  - 提供配置策略对比表和最佳实践指南
  - 添加详细的参数配置表格，包含参数名称、说明、默认值、极限值/限制、建议等信息
  - 补充遗漏的参数（ChromaDB、MCP Server、Agent Secret、安全配置等）
  - 添加参数使用位置映射表和参数检核清单
  - 完成参数使用位置全面检核，扫描所有代码文件并生成检核报告
  - 创建参数检核脚本 `scripts/check_config_params.py`，支持定期自动化检核
