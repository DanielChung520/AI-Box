# 向量化邏輯檢查報告

**代碼功能說明**: 向量化邏輯完整流程檢查報告
**創建日期**: 2026-01-21 13:50 UTC+8
**創建人**: Daniel Chung
**最後修改日期**: 2026-01-21 13:50 UTC+8

---

## 1. 向量化流程概述

### 1.1 完整流程

```
文件上傳
  ↓
文件保存到 SeaWeedFS S3
  ↓
創建文件元數據（file_metadata collection）
  ↓
提交 RQ 任務到隊列（process_file_chunking_and_vectorization_task）
  ↓
階段1: 文件解析和分塊 (0-50%)
  - 解析文件內容
  - 分塊處理（chunking）
  ↓
階段2: 向量化 (50-90%)
  - 批量生成 embeddings
  - 更新 processing_status
  ↓
階段3: 存儲到 Qdrant (90-100%)
  - 創建/確保 Collection 存在
  - 存儲 vectors 到 Qdrant
  - 更新 processing_status（包含 collection_name 和 vector_count）
  ↓
階段4: 知識圖譜提取（獨立流程）
```

### 1.2 關鍵組件

- **文件上傳**: `api/routers/file_upload.py` - `upload_files()`
- **處理任務**: `api/routers/file_upload.py` - `process_file_chunking_and_vectorization()`
- **向量存儲**: `services/api/services/qdrant_vector_store_service.py` - `store_vectors()`
- **向量查詢**: `api/routers/file_management.py` - `get_file_vectors()`
- **前端顯示**: `ai-bot/src/components/FilePreview.tsx` - `checkDataAvailability()`

---

## 2. 後端向量化邏輯

### 2.1 文件上傳觸發向量化

**位置**: `api/routers/file_upload.py` - `upload_files()`

**流程**:

1. 文件上傳並保存到 SeaWeedFS S3
2. 創建文件元數據（`file_metadata` collection）
3. 提交 RQ 任務到隊列：

   ```python
   job = queue.enqueue(
       process_file_chunking_and_vectorization_task,
       file_id=file_id,
       file_path=file_path,
       file_type=file_type,
       user_id=current_user.user_id,
       job_timeout=job_timeout,
   )
   ```

### 2.2 向量化處理流程

**位置**: `api/routers/file_upload.py` - `process_file_chunking_and_vectorization()`

#### 階段1: 文件解析和分塊 (0-50%)

1. **文件解析**:
   - 根據 `file_type` 選擇對應的 parser
   - 解析文件內容為文本
   - 圖片文件特殊處理：使用 Vision 模型生成描述文本

2. **分塊處理**:
   - 調用 `chunk_processor.process()` 進行分塊
   - 圖片文件：描述文本作為單個 chunk
   - 文本文件：正常分塊處理

3. **更新狀態**:

   ```python
   _update_processing_status(
       file_id=file_id,
       chunking={
           "status": "completed",
           "progress": 100,
           "message": "分塊處理完成",
           "chunk_count": len(chunks),
       },
       overall_progress=50,
   )
   ```

#### 階段2: 向量化 (50-90%)

1. **生成 Embeddings**:

   ```python
   embedding_service = get_embedding_service()
   chunk_texts = [chunk.get("text", "") for chunk in chunks]
   embeddings = await embedding_service.generate_embeddings_batch(
       chunk_texts, progress_callback=update_vectorization_progress
   )
   ```

2. **進度回調**:
   - 每處理一個 chunk，更新 `processing_status`
   - 進度範圍：50-90%

3. **更新狀態**:

   ```python
   _update_processing_status(
       file_id=file_id,
       vectorization={
           "status": "completed",
           "progress": 100,
           "message": "向量化完成",
           "vector_count": len(embeddings),
       },
       overall_progress=90,
   )
   ```

#### 階段3: 存儲到 Qdrant (90-100%)

1. **存儲向量**:

   ```python
   vector_store_service = get_qdrant_vector_store_service()
   vector_store_service.store_vectors(
       file_id=file_id,
       chunks=chunks,
       embeddings=embeddings,
       user_id=user_id,
   )
   ```

2. **獲取統計信息**:

   ```python
   stats = vector_store_service.get_collection_stats(file_id, user_id)
   # 返回: {
   #   "collection_name": "file_{file_id}",
   #   "vector_count": 100,
   #   "status": "active"
   # }
   ```

3. **更新狀態**:

   ```python
   _update_processing_status(
       file_id=file_id,
       storage={
           "status": "completed",
           "progress": 100,
           "message": "向量存儲完成",
           "collection_name": stats["collection_name"],
           "vector_count": stats["vector_count"],
       },
       overall_progress=90,
   )
   ```

### 2.3 Qdrant 存儲邏輯

**位置**: `services/api/services/qdrant_vector_store_service.py` - `store_vectors()`

**流程**:

1. **Collection 命名**:
   - 格式：`file_{file_id}`（默認）
   - 或：`user_{user_id}`（如果 `collection_naming == "user_based"`）

2. **確保 Collection 存在**:

   ```python
   self._ensure_collection(collection_name, vector_size)
   # 如果不存在，創建新的 Collection
   ```

3. **構建 Points**:

   ```python
   for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
       points.append(
           PointStruct(
               id=i,  # Point ID 是整數索引
               vector=embedding,
               payload={
                   "file_id": file_id,
                   "chunk_index": i,
                   "chunk_text": chunk.get("text", "")[:200],
                   # ... 其他 metadata
               }
           )
       )
   ```

4. **批量插入**:

   ```python
   self.client.upsert(
       collection_name=collection_name,
       points=points,
   )
   ```

### 2.4 Collection 統計信息獲取

**位置**: `services/api/services/qdrant_vector_store_service.py` - `get_collection_stats()`

**邏輯**:

```python
try:
    collection_info = self.client.get_collection(collection_name)
    vector_count = self.client.count(collection_name).count

    return {
        "collection_name": collection_name,
        "vector_count": vector_count,
        "status": str(collection_info.status),
    }
except Exception as e:
    # Collection 不存在或查詢失敗
    return {
        "collection_name": collection_name,
        "vector_count": 0,
        "status": "error",
    }
```

**注意**:

- 如果 Collection 不存在，`get_collection()` 會拋出異常
- 異常時返回 `status: "error"` 和 `vector_count: 0`

---

## 3. 前端向量顯示邏輯

### 3.1 向量可用性檢查

**位置**: `ai-bot/src/components/FilePreview.tsx` - `checkDataAvailability()`

**邏輯**:

```typescript
// 檢查向量數據
try {
  const vectorResponse = await getFileVectors(file.file_id, 1, 0);
  // 只要 collection 存在（有 collection_name），就認為可用，即使 vector_count 為 0
  const hasCollection = vectorResponse.success && vectorResponse.data &&
    (vectorResponse.data.stats?.collection_name ||
     vectorResponse.data.collection_name);
  setVectorAvailable(hasCollection || false);

  // 如果 collection 存在，且當前是向量模式，立即加載數據
  if (hasCollection && mode === 'vector') {
    loadDataForMode('vector');
  }
} catch (e) {
  setVectorAvailable(false);
}
```

**判斷條件**:

- ✅ **可用**: `collection_name` 存在（即使 `vector_count` 為 0）
- ❌ **不可用**: `collection_name` 不存在或 API 調用失敗

### 3.2 文件存在判斷（避免顯示"生成中"）

**位置**: `ai-bot/src/components/FilePreview.tsx` - `renderContent()` - `case 'vector'`

**邏輯**:

```typescript
// 修改時間：2026-01-21 13:00 UTC+8 - 如果 storage_path 有值，表示文件已存在
const hasStoragePath = file.storage_path && file.storage_path.trim().length > 0;
const fileStatusCompleted = file.status === 'completed';
const fileExists = hasStoragePath || fileStatusCompleted;

// 如果文件已存在但 processing_status 為 null，不顯示"生成中"
const shouldShowGenerating = hasProcessingStatus && isVectorRunning && !isVectorFailed && !fileExists;
```

**判斷條件**:

- **文件已存在**: `file.storage_path` 有值 或 `file.status === 'completed'`
- **正在生成**: `processing_status` 存在且狀態為 `processing/in_progress/pending` 且文件不存在
- **未成功生成**: 文件已存在但 `processing_status` 為 `null`（可能 TTL 過期）

### 3.3 向量數據獲取

**位置**: `api/routers/file_management.py` - `get_file_vectors()`

**邏輯**:

1. **先獲取統計信息**:

   ```python
   stats = vector_store_service.get_collection_stats(file_id, user_id)
   ```

2. **判斷是否有數據**:

   ```python
   if stats.get("vector_count", 0) == 0 or stats.get("status") == "error":
       return APIResponse.success(
           data={
               "file_id": file_id,
               "vectors": [],
               "total": 0,
               "stats": stats,
               "collection_name": stats.get("collection_name"),
           },
           message="向量資料查詢成功（無數據）",
       )
   ```

3. **獲取分頁向量數據**:

   ```python
   paginated_vectors = vector_store_service.get_vectors_by_file_id(
       file_id=file_id,
       user_id=user_id,
       limit=limit,
       with_vector=False,  # 不包含向量數據本身（太大）
   )
   ```

4. **返回結果**:

   ```python
   return APIResponse.success(
       data={
           "file_id": file_id,
           "vectors": paginated_vectors,
           "total": stats.get("vector_count", 0),
           "stats": stats,
       },
   )
   ```

**關鍵點**:

- 即使 `vector_count` 為 0，只要 `collection_name` 存在，也會返回 `stats` 信息
- 前端根據 `collection_name` 判斷向量是否可用

---

## 4. 潛在問題分析

### 4.1 Collection 存在但 vector_count 為 0

**可能原因**:

1. **向量化失敗但 Collection 已創建**:
   - 在 `store_vectors()` 中，如果 `_ensure_collection()` 成功但 `upsert()` 失敗
   - Collection 已創建但沒有 points

2. **向量被刪除**:
   - 調用 `delete_vectors_by_file_id()` 刪除了所有 points
   - Collection 仍然存在但為空

3. **部分失敗**:
   - 某些 embeddings 生成失敗，被過濾掉
   - 如果所有 embeddings 都失敗，`store_vectors()` 返回 `False`，但 Collection 可能已創建

**當前處理**:

- ✅ 前端：只要 `collection_name` 存在就認為可用（即使 `vector_count` 為 0）
- ✅ 前端：顯示 Collection Info 和 "沒有找到 Points" 提示

### 4.2 processing_status 為 null 但文件已存在

**可能原因**:

1. **TTL 過期**:
   - `processing_status` collection 有 TTL 索引（24小時）
   - 文件處理完成後，24小時後 `processing_status` 記錄被自動刪除

2. **從未創建**:
   - 舊文件在添加 `processing_status` 功能之前上傳
   - 沒有對應的 `processing_status` 記錄

**當前處理**:

- ✅ 檢查 `file.storage_path` 或 `file.status === 'completed'` 判斷文件已存在
- ✅ 如果文件已存在但 `processing_status` 為 `null`，不顯示"生成中"，而是顯示"未成功生成"並提供"重新生成"按鈕

### 4.3 Point ID 類型問題

**問題**:

- Qdrant 的 Point ID 必須是整數或 UUID
- 從 API 返回的 `point.id` 可能是字符串（如 `"3"`）

**當前處理**:

- ✅ 在 `get_similar_vectors()` API 中，將 `point_id` 字符串轉換為整數
- ✅ 如果無法轉換為整數，嘗試作為 UUID
- ✅ 如果都不是，返回明確的錯誤信息

---

## 5. 向量化邏輯檢查清單

### 5.1 後端檢查

- [x] 文件上傳後是否正確提交 RQ 任務
- [x] 分塊處理是否正確執行
- [x] 向量生成是否正確（批量處理）
- [x] 向量存儲是否正確（Qdrant upsert）
- [x] `processing_status` 是否正確更新（包含 `collection_name` 和 `vector_count`）
- [x] `get_collection_stats()` 是否正確處理 Collection 不存在的情況
- [x] Point ID 是否正確（整數索引）

### 5.2 前端檢查

- [x] `checkDataAvailability()` 是否正確判斷向量可用性（基於 `collection_name`）
- [x] 文件存在判斷是否正確（基於 `storage_path` 或 `status`）
- [x] 顯示邏輯是否正確（三種情況：有數據、生成中、未成功生成）
- [x] 向量數據加載是否正確（`loadDataForMode('vector')`）
- [x] Point 列表顯示是否正確（ID + Chunk Text 預覽）

### 5.3 API 檢查

- [x] `GET /files/{file_id}/vectors` 是否正確返回統計信息（即使 `vector_count` 為 0）
- [x] `GET /files/{file_id}/vectors/{point_id}/similar` 是否正確處理 Point ID 類型轉換

---

## 6. 建議改進

### 6.1 後端改進

1. **Collection 創建時機**:
   - 建議：只在成功生成 embeddings 後才創建 Collection
   - 當前：`_ensure_collection()` 在 `store_vectors()` 開始時就創建

2. **錯誤處理**:
   - 建議：如果 `store_vectors()` 失敗，刪除已創建的 Collection（如果為空）
   - 當前：如果失敗，Collection 可能已創建但為空

3. **統計信息**:
   - 建議：`get_collection_stats()` 在 Collection 不存在時，明確返回 `status: "not_found"` 而不是 `"error"`
   - 當前：返回 `status: "error"`，可能與真正的錯誤混淆

### 6.2 前端改進

1. **向量可用性判斷**:
   - 當前：只要 `collection_name` 存在就認為可用
   - 建議：同時檢查 `vector_count > 0` 或 `status !== "error"`

2. **錯誤處理**:
   - 當前：`vector_count: 0` 時顯示"沒有找到 Points"
   - 建議：區分"Collection 存在但無數據"和"Collection 不存在"兩種情況

---

## 7. 相關代碼位置

### 7.1 後端

- **文件上傳**: `api/routers/file_upload.py` - `upload_files()` (line 2095)
- **向量化處理**: `api/routers/file_upload.py` - `process_file_chunking_and_vectorization()` (line 585)
- **向量存儲**: `services/api/services/qdrant_vector_store_service.py` - `store_vectors()` (line 138)
- **統計信息**: `services/api/services/qdrant_vector_store_service.py` - `get_collection_stats()` (line 410)
- **向量查詢**: `api/routers/file_management.py` - `get_file_vectors()` (line 2820)
- **相似搜索**: `api/routers/file_management.py` - `get_similar_vectors()` (line 2901)

### 7.2 前端

- **向量可用性檢查**: `ai-bot/src/components/FilePreview.tsx` - `checkDataAvailability()` (line 1004)
- **向量數據加載**: `ai-bot/src/components/FilePreview.tsx` - `loadDataForMode()` (line 1048)
- **向量顯示**: `ai-bot/src/components/FilePreview.tsx` - `renderContent()` - `case 'vector'` (line 816)
- **Point 卡片**: `ai-bot/src/components/FilePreview.tsx` - `VectorPointCard()` (line 29)

---

**文件版本**: v1.0
**最後更新日期**: 2026-01-21 13:50 UTC+8
**維護人**: Daniel Chung
