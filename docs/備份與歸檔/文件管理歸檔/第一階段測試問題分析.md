# 第一階段測試問題分析

**創建日期**: 2026-01-01
**創建人**: Daniel Chung
**最後修改日期**: 2026-01-01

---

## 📋 問題概述

在執行第一階段單一文件測試時，發現處理時間較長（約2.5分鐘），且測試腳本無法正確檢測處理完成狀態。

---

## 🔍 問題分析

### 1. 測試腳本字段名錯誤（已修復）

**問題**：
- 測試腳本檢查的是 `overall_status` 和 `overall_progress`
- 但API返回的字段是 `status` 和 `progress`

**影響**：
- 測試腳本無法正確檢測處理完成狀態
- 導致一直輪詢，無法獲取結果

**修復**：
- ✅ 已修復：將 `overall_status` 改為 `status`
- ✅ 已修復：將 `overall_progress` 改為 `progress`

### 2. 處理時間分析

**實際處理時間**（從日誌分析）：
- **文件上傳**: 21:10:48
- **處理開始**: 21:10:50（上傳後2秒）
- **KG提取開始**: 21:12:28（處理開始後98秒）
- **KG提取完成**: 21:13:15（KG提取耗時47秒）
- **總處理時間**: 147秒（2.5分鐘）

**各階段時間分解**：
- **分塊+向量化+存儲**: 98秒
- **KG提取（15個chunks）**: 47秒
- **平均每個chunk**: 3.1秒

### 3. 性能瓶頸分析

#### 3.1 分塊+向量化+存儲階段（98秒）

**可能原因**：
1. **向量化耗時**：
   - 15個chunks需要生成15個向量嵌入
   - 每個向量生成可能需要調用embedding模型
   - 如果使用遠程embedding服務，網絡延遲會增加

2. **ChromaDB存儲**：
   - 15個向量需要存儲到ChromaDB
   - 如果ChromaDB是遠程服務，網絡延遲會增加

**優化建議**：
- 檢查embedding服務的響應時間
- 考慮使用批量向量化（如果支持）
- 檢查ChromaDB連接性能

#### 3.2 KG提取階段（47秒，15個chunks）

**處理流程**：
1. **NER（命名實體識別）**: 每個chunk需要調用Ollama模型
2. **RE（關係抽取）**: 每個chunk需要調用Ollama模型
3. **RT（關係分類）**: 每個chunk可能需要調用Ollama模型

**並發設置**：
- 當前並發數：`concurrency=3`
- 15個chunks需要5批處理
- 每批約10秒（3個chunks並發）

**每個chunk的處理時間**：
- 平均每個chunk: 3.1秒
- 包括：NER + RE + RT + 圖譜構建

**性能分析**：
- ✅ **正常範圍**：每個chunk 3-5秒是合理的（需要3次LLM調用）
- ✅ **並發有效**：3個並發可以同時處理3個chunks
- ⚠️ **可優化**：如果增加並發數，可以縮短總時間

### 4. 模型配置分析

**當前配置**（從日誌）：
- NER模型: `mistral-nemo:12b`
- RE模型: `mistral-nemo:12b`
- RT模型: `mistral-nemo:12b`

**模型性能**：
- `mistral-nemo:12b` 是12B參數的模型
- 每個LLM調用需要幾秒時間
- 3次調用（NER + RE + RT）約3-5秒是正常的

**優化建議**：
1. **使用更小的模型**（如果質量可接受）：
   - `llama3.1:8b`（8B參數，更快）
   - `qwen3-vl:8b`（8B參數）

2. **增加並發數**：
   - 當前：`concurrency=3`
   - 建議：`concurrency=5`（如果資源允許）

3. **優化RT處理**：
   - 如果RE已輸出標準關係類型，跳過RT（已實現）
   - 使用RT batch處理（已實現）

---

## 📊 性能基準

### 當前性能（3KB文件，15個chunks）

| 階段 | 時間 | 說明 |
|------|------|------|
| 文件上傳 | 2秒 | 正常 |
| 分塊+向量化+存儲 | 98秒 | ⚠️ 較慢，需要優化 |
| KG提取 | 47秒 | ✅ 正常（15個chunks × 3.1秒/chunk） |
| **總計** | **147秒（2.5分鐘）** | |

### 預期性能（優化後）

| 階段 | 當前時間 | 優化後預期 | 優化方法 |
|------|---------|-----------|---------|
| 分塊+向量化+存儲 | 98秒 | 30-50秒 | 批量向量化、優化ChromaDB連接 |
| KG提取 | 47秒 | 30-40秒 | 增加並發數到5、使用更小模型 |
| **總計** | **147秒** | **60-90秒** | |

---

## 🔧 優化建議

### 短期優化（立即實施）

1. **修復測試腳本字段名**（已完成）
   - ✅ 將 `overall_status` 改為 `status`
   - ✅ 將 `overall_progress` 改為 `progress`

2. **增加KG提取並發數**
   - 修改 `api/routers/file_upload.py` 第1283行
   - 將 `concurrency=3` 改為 `concurrency=5`

3. **檢查向量化性能**
   - 檢查embedding服務響應時間
   - 考慮使用批量向量化

### 中期優化（1-2週）

1. **優化向量化流程**
   - 實現批量向量化（如果支持）
   - 優化ChromaDB連接池

2. **模型選擇優化**
   - 測試更小的模型（如 `llama3.1:8b`）
   - 評估質量vs速度的平衡

3. **緩存機制**
   - 緩存NER/RE/RT結果（如果chunk內容相同）
   - 減少重複LLM調用

### 長期優化（1-2個月）

1. **異步處理優化**
   - 實現更細粒度的進度追蹤
   - 支持部分結果返回

2. **資源管理**
   - 動態調整並發數（根據系統負載）
   - 實現任務優先級

---

## ✅ 已修復問題

1. ✅ **測試腳本字段名錯誤**：已修復 `overall_status` → `status`

---

## 📝 測試建議

### 重新執行測試

修復後，重新執行測試：

```bash
python3 scripts/kg_extract_test_file.py \
  --file "docs/系统设计文档/统一服务指南.md" \
  --model ollama \
  --user-id "test-user" \
  --output "test_results_ollama.json"
```

### 預期結果

- ✅ 測試腳本能夠正確檢測處理完成狀態
- ✅ 能夠獲取完整的測試結果
- ✅ 處理時間約2-3分鐘（正常範圍）

---

## 📚 相關文檔

- [文件上傳向量圖譜化測試計劃](./文件上傳向量圖譜化測試計劃.md)
- [上傳的功能架構說明-v2.0](./上傳的功能架構說明-v2.0.md)
- [NER_RE_RT模型配置问题分析](./NER_RE_RT模型配置问题分析.md)

---

**最後更新日期**: 2026-01-01
