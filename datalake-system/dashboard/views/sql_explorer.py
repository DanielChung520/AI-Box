# -*- coding: utf-8 -*-
"""
ä»£ç¢¼åŠŸèƒ½èªªæ˜: SQL Explorer - JP TiTop è³‡æ–™åº«æŸ¥è©¢ç•Œé¢
å‰µå»ºæ—¥æœŸ: 2026-02-18
å‰µå»ºäºº: AI Assistant
æœ€å¾Œä¿®æ”¹æ—¥æœŸ: 2026-02-18

å°ˆæ³¨æ–¼ JP TiTop ERP è³‡æ–™ï¼ˆ/jp/execute ç«¯é»å°æ‡‰çš„è³‡æ–™ï¼‰
S3 è·¯å¾‘: s3://tiptop-raw/raw/v1/tiptop_jp/{TABLE}/year=*/month=*/data.parquet
"""

import streamlit as st
import duckdb
import pandas as pd
from typing import Optional, Dict, List, Any

# é…ç½®è·¯å¾‘ï¼ˆä¾†è‡ª /jp/execute bindings.jsonï¼‰
JP_DUCKDB_PATH = "/home/daniel/ai-box/datalake-system/data/warehouse/tiptop_jp.duckdb"
S3_BUCKET = "tiptop-raw"
S3_BASE_PATH = "raw/v1/tiptop_jp"

# JP è¡¨æ ¼å®šç¾©ï¼ˆä¾†è‡ª tiptop_jp/bindings.jsonï¼‰
# Mart è¡¨æ ¼ä¾†è‡ª DuckDBæœ¬åœ°å€‰åº«
JP_TABLES: Dict[str, Dict[str, Any]] = {
    # ========== S3 Parquet è¡¨æ ¼ ==========
    "INAG_T": {
        "name": "INAG_T",
        "name_cn": "åœ¨åº«æ˜ç´°",
        "description": "æ—¥æœ¬ TiTop åœ¨åº«æ˜ç´°è¡¨",
        "source": "S3 Parquet",
        "columns": [
            {"id": "INAGENT", "name": "ä¼æ¥­ç·¨è™Ÿ", "type": "NUMBER"},
            {"id": "INAGSITE", "name": "ç‡Ÿé‹æ“šé»", "type": "VARCHAR2"},
            {"id": "INAG001", "name": "æ–™ä»¶ç·¨è™Ÿ", "type": "VARCHAR2"},
            {"id": "INAG004", "name": "å€‰åº«ç·¨è™Ÿ", "type": "VARCHAR2"},
            {"id": "INAG005", "name": "å„²ä½ç·¨è™Ÿ", "type": "VARCHAR2"},
            {"id": "INAG007", "name": "å–®ä½", "type": "VARCHAR2"},
            {"id": "INAG008", "name": "ç¾æœ‰åº«å­˜", "type": "NUMBER(15,3)"},
        ],
    },
    "SFAA_T": {
        "name": "SFAA_T",
        "name_cn": "å·¥å–®é ­æª”",
        "description": "æ—¥æœ¬ TiTop å·¥å–®é ­æª”",
        "source": "S3 Parquet",
        "columns": [
            {"id": "SFAAENT", "name": "ä¼æ¥­ç·¨è™Ÿ", "type": "NUMBER"},
            {"id": "SFAASITE", "name": "ç‡Ÿé‹æ“šé»", "type": "VARCHAR2"},
            {"id": "SFAA010", "name": "æ–™ä»¶ç·¨è™Ÿ", "type": "VARCHAR2"},
            {"id": "SFAA056", "name": "å ±å»¢æ•¸é‡", "type": "NUMBER(15,3)"},
            {"id": "SFAA022", "name": "è¨‚å–®ç·¨è™Ÿ", "type": "VARCHAR2"},
            {"id": "SFAA023", "name": "è¨‚å–®é …æ¬¡", "type": "VARCHAR2"},
            {"id": "SFAA009", "name": "å®¢æˆ¶ç·¨è™Ÿ", "type": "VARCHAR2"},
            {"id": "SFAASTUS", "name": "ç‹€æ…‹", "type": "VARCHAR2"},
        ],
    },
    "SFCA_T": {
        "name": "SFCA_T",
        "name_cn": "å·¥å–®è£½é€ é ­æª”",
        "description": "æ—¥æœ¬ TiTop å·¥å–®è£½é€ é ­æª”",
        "source": "S3 Parquet",
        "columns": [
            {"id": "SFCAENT", "name": "ä¼æ¥­ç·¨è™Ÿ", "type": "NUMBER"},
            {"id": "SFCADocNo", "name": "å·¥å–®ç·¨è™Ÿ", "type": "VARCHAR2"},
            {"id": "SFCA002", "name": "é …æ¬¡", "type": "VARCHAR2"},
            {"id": "SFCA001", "name": "åºå·", "type": "NUMBER"},
            {"id": "SFCA003", "name": "è¨ˆåŠƒæ•¸é‡", "type": "NUMBER"},
            {"id": "SFCA004", "name": "å®Œå·¥æ•¸é‡", "type": "NUMBER"},
            {"id": "month", "name": "æœˆä»½", "type": "VARCHAR"},
            {"id": "year", "name": "å¹´ä»½", "type": "NUMBER"},
        ],
    },
    "SFCB_T": {
        "name": "SFCB_T",
        "name_cn": "å·¥å–®è£½é€ æ˜ç´°æª”",
        "description": "æ—¥æœ¬ TiTop å·¥å–®è£½é€ æ˜ç´°æª”",
        "source": "S3 Parquet",
        "columns": [
            {"id": "SFCBENT", "name": "ä¼æ¥­ç·¨è™Ÿ", "type": "NUMBER"},
            {"id": "SFCBDocNo", "name": "å·¥å–®ç·¨è™Ÿ", "type": "VARCHAR2"},
            {"id": "SFCBSeq", "name": "é …æ¬¡", "type": "VARCHAR2"},
            {"id": "SFCBItem", "name": "æ–™ä»¶", "type": "VARCHAR2"},
            {"id": "SFCBQty", "name": "æ•¸é‡", "type": "NUMBER"},
            {"id": "SFCBWIPQty", "name": "WIPæ•¸é‡", "type": "NUMBER"},
            {"id": "SFCBStatus", "name": "ç‹€æ…‹", "type": "VARCHAR2"},
        ],
    },
    "XMDG_T": {
        "name": "XMDG_T",
        "name_cn": "å‡ºè²¨é€šçŸ¥é ­æª”",
        "description": "æ—¥æœ¬ TiTop å‡ºè²¨é€šçŸ¥é ­æª”",
        "source": "S3 Parquet",
        "columns": [
            {"id": "XMDGENT", "name": "ä¼æ¥­ç·¨è™Ÿ", "type": "NUMBER"},
            {"id": "XMDGDOCNO", "name": "å‡ºè²¨é€šçŸ¥å–®è™Ÿ", "type": "VARCHAR2"},
            {"id": "XMDGDOCDT", "name": "å‡ºè²¨æ—¥æœŸ", "type": "DATE"},
            {"id": "XMDGCustID", "name": "å®¢æˆ¶ç·¨è™Ÿ", "type": "VARCHAR2"},
            {"id": "XMDG005", "name": "æ¥­å‹™äººå“¡", "type": "VARCHAR2"},
            {"id": "XMDGSTUS", "name": "ç‹€æ…‹", "type": "VARCHAR2"},
            {"id": "XMDGTotalAmt", "name": "ç¸½é‡‘é¡", "type": "NUMBER"},
        ],
    },
    "XMDH_T": {
        "name": "XMDH_T",
        "name_cn": "å‡ºè²¨é€šçŸ¥æ˜ç´°æª”",
        "description": "æ—¥æœ¬ TiTop å‡ºè²¨é€šçŸ¥æ˜ç´°æª”",
        "source": "S3 Parquet",
        "columns": [
            {"id": "XMDHENT", "name": "ä¼æ¥­ç·¨è™Ÿ", "type": "NUMBER"},
            {"id": "XMDHDOCNO", "name": "å‡ºè²¨é€šçŸ¥å–®è™Ÿ", "type": "VARCHAR2"},
            {"id": "XMDHSEQ", "name": "é …æ¬¡", "type": "VARCHAR2"},
            {"id": "XMDH006", "name": "æ–™è™Ÿ", "type": "VARCHAR2"},
            {"id": "XMDH016", "name": "é äº¤æ•¸é‡", "type": "NUMBER"},
            {"id": "XMDH017", "name": "å¯¦éš›æ•¸é‡", "type": "NUMBER"},
            {"id": "XMDH023", "name": "å–®åƒ¹", "type": "NUMBER"},
        ],
    },
    # ========== Mart å¯¬è¡¨ (DuckDB æœ¬åœ°) ==========
    "mart_work_order_wide": {
        "name": "mart_work_order_wide",
        "name_cn": "å·¥å–®å¯¬è¡¨",
        "description": "å·¥å–®æ•¸æ“šå¯¬è¡¨ï¼ˆå·²æ•´åˆï¼‰",
        "source": "DuckDB æœ¬åœ°",
        "columns": [
            {"id": "item_no", "name": "æ–™ä»¶ç·¨è™Ÿ", "type": "VARCHAR"},
            {"id": "customer_no", "name": "å®¢æˆ¶ç·¨è™Ÿ", "type": "VARCHAR"},
            {"id": "status", "name": "ç‹€æ…‹", "type": "VARCHAR"},
            {"id": "scrap_qty", "name": "å ±å»¢æ•¸é‡", "type": "DOUBLE"},
            {"id": "workstation", "name": "å·¥ä½œç«™", "type": "VARCHAR"},
        ],
    },
    "mart_inventory_wide": {
        "name": "mart_inventory_wide",
        "name_cn": "åº«å­˜å¯¬è¡¨",
        "description": "åº«å­˜æ•¸æ“šå¯¬è¡¨ï¼ˆå·²æ•´åˆï¼‰",
        "source": "DuckDB æœ¬åœ°",
        "columns": [
            {"id": "item_no", "name": "æ–™ä»¶ç·¨è™Ÿ", "type": "VARCHAR"},
            {"id": "warehouse_no", "name": "å€‰åº«ç·¨è™Ÿ", "type": "VARCHAR"},
            {"id": "location_no", "name": "å„²ä½ç·¨è™Ÿ", "type": "VARCHAR"},
            {"id": "unit", "name": "å–®ä½", "type": "VARCHAR"},
            {"id": "existing_stocks", "name": "ç¾æœ‰åº«å­˜", "type": "DOUBLE"},
        ],
    },
    "mart_shipping_wide": {
        "name": "mart_shipping_wide",
        "name_cn": "å‡ºè²¨å¯¬è¡¨",
        "description": "å‡ºè²¨æ•¸æ“šå¯¬è¡¨ï¼ˆå·²æ•´åˆï¼‰",
        "source": "DuckDB æœ¬åœ°",
        "columns": [
            {"id": "doc_no", "name": "å‡ºè²¨å–®è™Ÿ", "type": "VARCHAR"},
            {"id": "doc_date", "name": "å‡ºè²¨æ—¥æœŸ", "type": "VARCHAR"},
            {"id": "status", "name": "ç‹€æ…‹", "type": "VARCHAR"},
            {"id": "customer_no", "name": "å®¢æˆ¶ç·¨è™Ÿ", "type": "VARCHAR"},
            {"id": "seq", "name": "é …æ¬¡", "type": "DOUBLE"},
            {"id": "item_no", "name": "æ–™ä»¶ç·¨è™Ÿ", "type": "VARCHAR"},
            {"id": "actual_qty", "name": "å¯¦éš›æ•¸é‡", "type": "DOUBLE"},
            {"id": "unit_price", "name": "å–®åƒ¹", "type": "DOUBLE"},
        ],
    },
}


def get_s3_path(table_name: str) -> str:
    """å–å¾— S3 Parquet è·¯å¾‘"""
    return f"s3://{S3_BUCKET}/{S3_BASE_PATH}/{table_name}/year=*/month=*/data.parquet"


def is_mart_table(table_name: str) -> bool:
    """æª¢æŸ¥æ˜¯å¦ç‚ºæœ¬åœ° DuckDB Mart è¡¨æ ¼"""
    return table_name in ["mart_work_order_wide", "mart_inventory_wide", "mart_shipping_wide"]


def execute_query_local(query: str, max_rows: int = 100) -> dict:
    """åŸ·è¡Œæœ¬åœ° DuckDB æŸ¥è©¢ï¼ˆMart è¡¨æ ¼ï¼‰"""
    conn = duckdb.connect(JP_DUCKDB_PATH, read_only=True)
    try:
        query_with_limit = query.strip()
        if query_with_limit.upper().startswith("SELECT") and "LIMIT" not in query.upper():
            query_with_limit = f"{query_with_limit} LIMIT {max_rows}"

        result = conn.execute(query_with_limit)

        if query.strip().upper().startswith("SELECT"):
            columns = [desc[0] for desc in conn.description]
            rows = result.fetchall()
            row_count = len(rows)
            error = None
        else:
            columns = []
            rows = []
            row_count = result.rowcount
            error = None

        conn.close()
        return {"columns": columns, "rows": rows, "row_count": row_count, "error": error}
    except Exception as e:
        conn.close()
        return {"columns": None, "rows": None, "row_count": 0, "error": str(e)}


def execute_query_s3(query: str, max_rows: int = 100) -> dict:
    """åŸ·è¡Œ S3 Parquet æŸ¥è©¢"""
    conn = duckdb.connect(JP_DUCKDB_PATH, read_only=True)

    try:
        # é…ç½® S3 é€£æ¥ï¼ˆä½¿ç”¨ path-style addressingï¼‰
        conn.execute("SET s3_endpoint='localhost:8334';")
        conn.execute("SET s3_access_key_id='admin';")
        conn.execute("SET s3_secret_access_key='admin123';")
        conn.execute("SET s3_use_ssl=false;")
        conn.execute("SET s3_region='us-east-1';")
        conn.execute("SET s3_url_style='path';")

        # æ·»åŠ  LIMIT
        query_with_limit = query.strip()
        if query_with_limit.upper().startswith("SELECT") and "LIMIT" not in query.upper():
            query_with_limit = f"{query_with_limit} LIMIT {max_rows}"

        result = conn.execute(query_with_limit)

        # ç²å–çµæœ
        if query.strip().upper().startswith("SELECT"):
            columns = [desc[0] for desc in conn.description]
            rows = result.fetchall()
            row_count = len(rows)
            error = None
        else:
            columns = []
            rows = []
            row_count = result.rowcount
            error = None

        conn.close()
        return {"columns": columns, "rows": rows, "row_count": row_count, "error": error}
    except Exception as e:
        conn.close()
        return {"columns": None, "rows": None, "row_count": 0, "error": str(e)}


def preview_s3_table(
    table_name: str, max_rows: int = 100
) -> tuple[Optional[List[str]], Optional[List[tuple]]]:
    """é è¦½è¡¨æ ¼æ•¸æ“šï¼ˆæ”¯æŒ S3 Parquet å’Œæœ¬åœ° DuckDBï¼‰"""
    if table_name not in JP_TABLES:
        return None, None

    table_info = JP_TABLES[table_name]
    source = table_info.get("source", "S3 Parquet")

    if is_mart_table(table_name):
        query = f"SELECT * FROM {table_name} LIMIT {max_rows}"
        result = execute_query_local(query, max_rows)
    else:
        s3_path = get_s3_path(table_name)
        query = f"SELECT * FROM read_parquet('{s3_path}') LIMIT {max_rows}"
        result = execute_query_s3(query, max_rows)

    if result["error"]:
        st.error(f"æŸ¥è©¢éŒ¯èª¤: {result['error']}")
        return None, None

    return result["columns"], result["rows"]


def get_table_list() -> List[str]:
    """å–å¾—å¯ç”¨è¡¨æ ¼åˆ—è¡¨"""
    return list(JP_TABLES.keys())


def generate_sql_template(table_name: str, template_type: str) -> str:
    """ç”Ÿæˆ SQL æ¨¡æ¿"""
    if is_mart_table(table_name):
        templates = {
            "basic": f"-- æŸ¥è©¢ {JP_TABLES[table_name]['name_cn']} åŸºæœ¬è³‡æ–™\nSELECT * FROM {table_name} LIMIT 100",
            "count": f"-- çµ±è¨ˆ {JP_TABLES[table_name]['name_cn']} ç­†æ•¸\nSELECT COUNT(*) as total FROM {table_name}",
            "aggregate": f"-- èšåˆæŸ¥è©¢ç¯„ä¾‹\nSELECT item_no, COUNT(*) as cnt FROM {table_name} GROUP BY item_no LIMIT 100",
            "join": f"-- JOIN æŸ¥è©¢ç¯„ä¾‹\nSELECT a.*, b.* FROM {table_name} a\nLEFT JOIN mart_inventory_wide b ON a.item_no = b.item_no LIMIT 100",
        }
    else:
        s3_path = get_s3_path(table_name)
        templates = {
            "basic": f"-- æŸ¥è©¢ {JP_TABLES[table_name]['name_cn']} åŸºæœ¬è³‡æ–™\nSELECT * FROM read_parquet('{s3_path}') LIMIT 100",
            "count": f"-- çµ±è¨ˆ {JP_TABLES[table_name]['name_cn']} ç­†æ•¸\nSELECT COUNT(*) as total FROM read_parquet('{s3_path}')",
            "aggregate": f"-- èšåˆæŸ¥è©¢ç¯„ä¾‹\nSELECT COUNT(*) as cnt, SUM(column) as total FROM read_parquet('{s3_path}') GROUP BY column",
            "join": f"-- JOIN æŸ¥è©¢ç¯„ä¾‹\nSELECT a.*, b.* FROM read_parquet('{s3_path}') a\nLEFT JOIN read_parquet('s3://{S3_BUCKET}/{S3_BASE_PATH}/other_table/year=*/month=*/data.parquet') b ON a.key = b.key",
        }

    return templates.get(template_type, templates["basic"])


def render_sql_explorer() -> None:
    """æ¸²æŸ“ SQL Explorer é é¢"""
    st.markdown("### ğŸ—ƒï¸ SQL Explorer - JP Tiptop æ•¸æ“šåº«")

    # åˆå§‹åŒ– session state
    if "sql_query" not in st.session_state:
        st.session_state.sql_query = "-- è¼¸å…¥æ‚¨çš„ SQL æŸ¥è©¢\nSELECT * FROM read_parquet('s3://tiptop-raw/raw/v1/tiptop_jp/INAG_T/year=*/month=*/data.parquet') LIMIT 100"
    if "query_result" not in st.session_state:
        st.session_state.query_result = None

    # å…©æ¬„å¸ƒå±€
    col1, col2 = st.columns([1, 2], gap="medium")

    with col1:
        st.markdown("#### ğŸ“‹ è¡¨æ ¼ç€è¦½")

        # è¡¨æ ¼é¸æ“‡å™¨
        selected_table = st.selectbox(
            "é¸æ“‡è¡¨æ ¼",
            options=get_table_list(),
            index=0,
            format_func=lambda x: f"{x} - {JP_TABLES[x]['name_cn']}",
        )

        if selected_table:
            table_info = JP_TABLES[selected_table]

            # é¡¯ç¤ºè¡¨æ ¼è³‡è¨Š
            with st.expander("ğŸ“Š è¡¨æ ¼è³‡è¨Š", expanded=True):
                st.markdown(f"**è¡¨æ ¼åç¨±**: {table_info['name']}")
                st.markdown(f"**ä¸­æ–‡åç¨±**: {table_info['name_cn']}")
                st.markdown(f"**æè¿°**: {table_info['description']}")
                st.markdown(f"**æ•¸æ“šæº**: {table_info.get('source', 'S3 Parquet')}")

            # é¡¯ç¤ºæ¬„ä½
            st.markdown("**æ¬„ä½æ¸…å–®**:")
            columns = table_info.get("columns", [])
            for col in columns:
                st.markdown(f"- `{col['id']}` - {col['name']}")

            # é è¦½æŒ‰éˆ•
            if st.button("ğŸ‘ï¸ é è¦½æ•¸æ“š", use_container_width=True):
                with st.spinner("æ­£åœ¨è¼‰å…¥é è¦½æ•¸æ“š..."):
                    cols, rows = preview_s3_table(selected_table)
                    if cols and rows:
                        st.success(f"æˆåŠŸè¼‰å…¥ {len(rows)} ç­†è³‡æ–™")
                        # é¡¯ç¤ºé è¦½è³‡æ–™ - ç¢ºä¿ columns å’Œ data é•·åº¦ä¸€è‡´
                        display_cols = cols[: len(rows[0])] if len(cols) > len(rows[0]) else cols
                        preview_df = pd.DataFrame(list(rows), columns=display_cols)
                        st.dataframe(preview_df, height=200, use_container_width=True)
                    else:
                        st.warning("ç„¡æ³•è¼‰å…¥é è¦½è³‡æ–™")

            # SQL æ¨¡æ¿
            st.markdown("**SQL æ¨¡æ¿**:")
            template_type = st.selectbox(
                "é¸æ“‡æ¨¡æ¿",
                options=["basic", "count", "aggregate", "join"],
                format_func=lambda x: {
                    "basic": "åŸºæœ¬æŸ¥è©¢",
                    "count": "çµ±è¨ˆç­†æ•¸",
                    "aggregate": "èšåˆæŸ¥è©¢",
                    "join": "JOIN æŸ¥è©¢",
                }[x],
            )

            template_sql = generate_sql_template(selected_table, template_type)
            if st.button("ğŸ“ å¥—ç”¨æ¨¡æ¿", use_container_width=True):
                st.session_state.sql_query = template_sql
                st.rerun()

    with col2:
        st.markdown("#### ğŸ“ SQL ç·¨è¼¯å™¨")

        # SQL è¼¸å…¥å€åŸŸ
        sql_query = st.text_area(
            "è¼¸å…¥ SQL æŸ¥è©¢",
            value=st.session_state.sql_query,
            height=200,
            help="æ”¯æ´ DuckDB SQL èªæ³•ï¼Œå¯ä½¿ç”¨ read_parquet() è®€å– S3 Parquet æª”æ¡ˆ",
        )

        # æŸ¥è©¢é¸é …
        col_opts1, col_opts2 = st.columns(2)
        with col_opts1:
            max_rows = st.number_input(
                "æœ€å¤§ç­†æ•¸", min_value=10, max_value=10000, value=100, step=10
            )
        with col_opts2:
            show_sql_path = st.checkbox("é¡¯ç¤º S3 è·¯å¾‘ç¯„ä¾‹", value=True)

        if show_sql_path:
            st.markdown("**S3 è·¯å¾‘æ ¼å¼**:")
            st.code(
                f"s3://{S3_BUCKET}/{S3_BASE_PATH}/{{TABLE}}/year=*/month=*/data.parquet",
                language="sql",
            )

        # åŸ·è¡ŒæŒ‰éˆ•
        col_btn1, col_btn2, col_btn3 = st.columns([1, 1, 3])
        with col_btn1:
            execute_btn = st.button("â–¶ï¸ åŸ·è¡ŒæŸ¥è©¢", type="primary", use_container_width=True)
        with col_btn2:
            clear_btn = st.button("ğŸ—‘ï¸ æ¸…é™¤", use_container_width=True)

        if clear_btn:
            st.session_state.sql_query = "-- æ¸…é™¤\nSELECT 1"
            st.session_state.query_result = None
            st.rerun()

        if execute_btn:
            if not sql_query.strip():
                st.warning("è«‹è¼¸å…¥ SQL æŸ¥è©¢")
            else:
                with st.spinner("æ­£åœ¨åŸ·è¡ŒæŸ¥è©¢..."):
                    query_lower = sql_query.lower()
                    is_local_query = any(
                        mart in query_lower
                        for mart in [
                            "mart_work_order_wide",
                            "mart_inventory_wide",
                            "mart_shipping_wide",
                        ]
                    )

                    if is_local_query:
                        result = execute_query_local(sql_query, max_rows)
                    else:
                        result = execute_query_s3(sql_query, max_rows)

                    if result["error"]:
                        st.error(f"âŒ æŸ¥è©¢éŒ¯èª¤: {result['error']}")
                        st.session_state.query_result = None
                    else:
                        st.success(f"âœ… æŸ¥è©¢æˆåŠŸï¼Œè¿”å› {result['row_count']} ç­†è³‡æ–™")
                        st.session_state.query_result = result

        # é¡¯ç¤ºæŸ¥è©¢çµæœ
        if st.session_state.query_result:
            result = st.session_state.query_result

            if result["columns"] and result["rows"]:
                st.markdown("**æŸ¥è©¢çµæœ**:")
                try:
                    df = pd.DataFrame(result["rows"], columns=result["columns"])
                    st.dataframe(df, use_container_width=True, height=400)

                    # åŒ¯å‡ºé¸é …
                    col_exp1, col_exp2 = st.columns(2)
                    with col_exp1:
                        csv = df.to_csv(index=False).encode("utf-8")
                        st.download_button(
                            "ğŸ“¥ ä¸‹è¼‰ CSV",
                            data=csv,
                            file_name="query_result.csv",
                            mime="text/csv",
                            use_container_width=True,
                        )
                except Exception as e:
                    st.error(f"é¡¯ç¤ºçµæœéŒ¯èª¤: {e}")
            elif result["row_count"] is not None:
                st.markdown(f"**åŸ·è¡Œçµæœ**: å½±éŸ¿ {result['row_count']} ç­†è³‡æ–™")
            else:
                st.info("æŸ¥è©¢å·²åŸ·è¡Œï¼Œç„¡è¿”å›è³‡æ–™")

    # åº•éƒ¨èªªæ˜
    st.markdown("---")
    with st.expander("ğŸ“– SQL æŸ¥è©¢èªªæ˜"):
        st.markdown("""
        **æ”¯æ´çš„æŸ¥è©¢æ–¹å¼**:

        1. **ç›´æ¥æŸ¥è©¢æœ¬åœ° Mart å¯¬è¡¨**:
        ```sql
        SELECT * FROM mart_work_order_wide LIMIT 100
        ```

        2. **ç›´æ¥æŸ¥è©¢ S3 Parquet**:
        ```sql
        SELECT * FROM read_parquet('s3://tiptop-raw/raw/v1/tiptop_jp/INAG_T/year=*/month=*/data.parquet') LIMIT 100
        ```

        3. **èšåˆæŸ¥è©¢**:
        ```sql
        SELECT INAG001, COUNT(*) as cnt
        FROM read_parquet('s3://tiptop-raw/raw/v1/tiptop_jp/INAG_T/year=*/month=*/data.parquet')
        GROUP BY INAG001
        LIMIT 100
        ```

        4. **JOIN æŸ¥è©¢ (Mart + S3)**:
        ```sql
        SELECT a.*, b.*
        FROM mart_work_order_wide a
        LEFT JOIN mart_inventory_wide b ON a.item_no = b.item_no
        LIMIT 100
        ```

        **æ³¨æ„äº‹é …**:
        - æŸ¥è©¢è‡ªå‹•æ·»åŠ  LIMIT é™åˆ¶
        - S3 è·¯å¾‘ä½¿ç”¨ path-style æ ¼å¼
        - æ”¯æ´æ¨™æº– DuckDB SQL èªæ³•
        - Mart å¯¬è¡¨å¯ç›´æ¥æŸ¥è©¢æœ¬åœ° DuckDB
        """)
